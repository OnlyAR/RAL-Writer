[
    {
        "paper": "arXiv-2104.01112v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the average number of references per example in the \\\\textsc{NaturalProofs} dataset for the ProofWiki and Stacks data sources, according to the paper \\\"NaturalProofs: Mathematical Theorem Proving in Natural Language\\\"?",
        "answer": "The average number of references per example in the \\\\textsc{NaturalProofs} dataset is 7.4 for ProofWiki and 2.9 for Stacks.",
        "reference": "NaturalProofs: Mathematical Theorem Proving in Natural Language, Table 2: \\\"Refs/Ex test 7.4 ... Stacks 2.9\\\""
    },
    {
        "paper": "arXiv-2104.01112v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the BERT-pair retrieval model perform on the Real Analysis textbook dataset in the zero-shot setting according to the paper \\\"NaturalProofs: Mathematical Theorem Proving in Natural Language\\\"?",
        "answer": "On the Real Analysis dataset in the zero-shot setting, the BERT-pair (ProofWiki-trained) retrieval model has a mean average precision (mAP) of 13.24, recall at 10 (R@10) of 24.01, and full recovery within the top 10 (Full@10) of 19.16.",
        "reference": "NaturalProofs: Mathematical Theorem Proving in Natural Language, Table 4 \\\"Zero-shot retrieval performance\\\" ProofWiki model: \\\"Real Analysis, mAP 13.24, R@10 24.01, Full@10 19.16\\\""
    },
    {
        "paper": "arXiv-2310.06786v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What are the main categories of documents in the OpenWebMath dataset, and what percentages do they represent?",
        "answer": "The main categories of documents in the OpenWebMath dataset include mathematics (majority), physics, computer science, statistics, chemistry, economics, and others. Mathematics is the largest category, while the sum of physics, computer science, statistics, chemistry, and economics comprise together a significant portion. 12% of documents do not fall into any of these categories.",
        "reference": "OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text, Dataset Analysis, \\\"The majority of the documents in the dataset are directly related to mathematics, while the rest are spread out throughout physics, computer science, statistics, chemistry, and economics, with 12% of documents not falling neatly into any of these categories.\\\""
    },
    {
        "paper": "arXiv-2310.06786v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the performance of models trained on OpenWebMath compare to those trained on The Pile, both using 14.7B tokens, on the MATH benchmark in the category Geometry?",
        "answer": "Models trained on OpenWebMath achieve a perplexity score of 1.5748 in the Geometry category of the MATH benchmark, which is better than models trained on The Pile, which achieve a perplexity score of 1.9499.",
        "reference": "OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text, Downstream Performance, Table \\\"\\\\nWe trained 1.4B parameter models for 14.7B tokens on various datasets and measured their perplexity on different mathematics benchmarks.\\\""
    },
    {
        "paper": "arXiv-2312.17120v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the total number of tokens in the \\\\mathpile corpus as described in the paper \\\"\\\\mathpile: A Billion-Token-Scale Pre-training Corpus for Math\\\"?",
        "answer": "The total number of tokens in the \\\\mathpile corpus is approximately 9.5 billion tokens.",
        "reference": "\\\\mathpile: A Billion-Token-Scale Pre-training Corpus for Math, Section 2: The Collection of Corpora, \\\"we introduce \\\\mathpile, a diverse and high-quality math-centric corpus comprising about 9.5 billion tokens.\\\""
    },
    {
        "paper": "arXiv-2312.17120v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "In the paper \\\"\\\\mathpile: A Billion-Token-Scale Pre-training Corpus for Math\\\", how many documents from the Wikipedia subset are included in the \\\\mathpile corpus after deduplication and cleaning?",
        "answer": "The \\\\mathpile corpus includes 22,795 documents from the Wikipedia subset after deduplication and cleaning.",
        "reference": "\\\\mathpile: A Billion-Token-Scale Pre-training Corpus for Math, Section 6: Data Analysis, Table 3, \\\"Wikipedia: 22,795 documents\\\"."
    }
]