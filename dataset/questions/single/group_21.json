[
    {
        "paper": "arXiv-2112.01801v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the classification accuracy of PicassoNet++ on the ShapeNetCore dataset, as reported in the paper \\\"Mesh Convolution with Continuous Filters for 3D Surface Parsing\\\"?",
        "answer": "The classification accuracy of PicassoNet++ on the ShapeNetCore dataset is reported as 87.3%.",
        "reference": "Reference: \\\"Mesh Convolution with Continuous Filters for 3D Surface Parsing\\\", Section 5.2 (Table 1): \\\"PicassoNet++ (Prop.) & 87.3\\\""
    },
    {
        "paper": "arXiv-2112.01801v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does PicassoNet++ perform on the HUMAN dataset for semantic labelling compared to PD-MeshNet, according to the paper \\\"Mesh Convolution with Continuous Filters for 3D Surface Parsing\\\"?",
        "answer": "On the HUMAN dataset for semantic labelling, PicassoNet++ achieved an accuracy of 91.5%, whereas PD-MeshNet achieved an accuracy of 85.6%.",
        "reference": "Reference: \\\"Mesh Convolution with Continuous Filters for 3D Surface Parsing\\\", Section 5.2 (Table 1): \\\"PicassoNet++ (Prop.) & 91.5\\\" compared to \\\"PD-MeshNet & 85.6\\\""
    },
    {
        "paper": "arXiv-2304.02643v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the size of the Segment Anything Dataset (SAM), and how does it compare to previous segmentation datasets?",
        "answer": "The Segment Anything Dataset (SAM) consists of 11 million images and 1.1 billion segmentation masks. It is significantly larger than previous segmentation datasets, as noted in the paper: \\\"\\\\nOur final dataset, \\\\\\\\textbf{\\\\\\\\sad}, includes more than \\\\\\\\emph{1B} masks from \\\\\\\\emph{11M} licensed and privacy-preserving images (see \\\\\\\\fig{fig:sa1bvisuals}). \\\\\\\\sad, collected fully automatically using the final stage of our data engine, has 400$\\\\\\\\x$ more masks than any existing segmentation dataset~\\\\\\\\cite{Lin2014,Gupta2019,Zhou2019,OpenImages}.\\\"",
        "reference": "Segment Anything, Section 'Dataset', \\\"Our final dataset, \\\\\\\\textbf{\\\\\\\\sad}, includes more than \\\\\\\\emph{1B} masks from \\\\\\\\emph{11M} licensed and privacy-preserving images...\\\""
    },
    {
        "paper": "arXiv-2304.02643v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the Segment Anything Model (SAM) perform in the zero-shot segmentation task compared to the RITM model in terms of human quality ratings?",
        "answer": "The Segment Anything Model (SAM) receives significantly higher human quality ratings compared to the RITM model across several datasets. In the human quality rating study: \\\"we observe that the annotators consistently rate the quality of \\\\\\\\textbf{\\\\\\\\sam}'s masks substantially higher than the strongest baseline, RITM.\\\"",
        "reference": "Segment Anything, Section 'Zero-Shot Single Point Valid Mask Evaluation', \\\"we observe that the annotators consistently rate the quality of \\\\\\\\textbf{\\\\\\\\sam}'s masks substantially higher than the strongest baseline, RITM.\\\""
    },
    {
        "paper": "arXiv-2306.11737v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the prediction accuracy of the Neural ShDF method compared to state-of-the-art methods on the Autodesk Character Generator (ACG) and TurboSquid (TS) datasets?",
        "answer": "The prediction accuracy of the Neural ShDF method is 92.4% on the Autodesk Character Generator (ACG) dataset and 86.6% on the TurboSquid (TS) dataset, outperforming state-of-the-art methods PointNet, PointNet++, and MeshCNN.",
        "reference": "Neural ShDF: Reviving an Efficient and Consistent Mesh Segmentation Method - Section: Performance analysis - \\\"we compared the precision of our approach on the segmentation task with PointNet, PointNet++, and MeshCNN.\\\" - Table: Evaluations comparing our approach with state-of-the-art methods on multiple datasets."
    },
    {
        "paper": "arXiv-2306.11737v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the Neural ShDF method perform in terms of computation time compared to the baseline Shape Diameter Function (ShDF) method on the Mayabot mesh?",
        "answer": "The Neural ShDF method takes 1,555 milliseconds for generating ShDF values and 70 milliseconds for partitioning, with a total computation time of 1,624 milliseconds. This is significantly faster compared to the baseline Shape Diameter Function (ShDF) method, which takes 23,239 milliseconds for generating ShDF values and 132 milliseconds for partitioning, with a total time of 23,371 milliseconds.",
        "reference": "Neural ShDF: Reviving an Efficient and Consistent Mesh Segmentation Method - Section: Performance analysis - Table: The timing results are expressed in milliseconds."
    }
]