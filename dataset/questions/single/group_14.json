[
    {
        "paper": "arXiv-2301.12503v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the peak performance of AudioLDM-L on the AudioCaps dataset in terms of Frechet Distance (FD)?",
        "answer": "The peak performance of AudioLDM-L on the AudioCaps dataset, as measured by Frechet Distance, is 23.31 when fine-tuned on the full dataset.",
        "reference": "AudioLDM: Text-to-Audio Generation with Latent Diffusion Models - Table 1: 'AudioLDM-L-Full achieves an FD of 23.31.'"
    },
    {
        "paper": "arXiv-2301.12503v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does AudioLDM-S perform compared to DiffSound on the AudioSet evaluation set in terms of Inception Score (IS) and Frechet Distance (FD)?",
        "answer": "On the AudioSet evaluation set, AudioLDM-S achieves an Inception Score (IS) of 6.78 and a Frechet Distance (FD) of 28.08, both significantly better than DiffSound, which scores an IS of 4.19 and FD of 50.40.",
        "reference": "AudioLDM: Text-to-Audio Generation with Latent Diffusion Models - Table 3: 'DiffSound: FD 50.40 IS 4.19 KL 3.63; AudioLDM-S: FD 28.08 IS 6.78 KL 2.51.'"
    },
    {
        "paper": "arXiv-2404.09956v4.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What are the Average Winner Score and Average Loser Score for the preference dataset \\\\dataset{} used in the paper 'Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization'?",
        "answer": "The Average Winner Score for the preference dataset \\\\dataset{} is 0.645 and the Average Loser Score is 0.452.",
        "reference": "Title: 'Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization', Table 2: 'Statistics of \\\\dataset{}.'"
    },
    {
        "paper": "arXiv-2404.09956v4.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How many samples are included in the preference dataset \\\\dataset{} described in the paper 'Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization'?",
        "answer": "The preference dataset \\\\dataset{} described in the paper contains 15,025 samples.",
        "reference": "Title: 'Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization', Table 2: 'Statistics of \\\\dataset{}.'"
    },
    {
        "paper": "arXiv-2412.15922v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What are the new evaluation metrics proposed in the RiTTA paper, and what are their components?",
        "answer": "The RiTTA paper proposes a new evaluation metric framework called MSR-RiTTA, which includes three components: Target Audio Events Presence (Pre), Relation Correctness (Rel), and Audio Parsimony (Par). MSR-RiTTA offers a multi-stage evaluation strategy by measuring the presence of target audio events, ensuring the correctness of relations specified in the text, and penalizing deviations in the number of events generated compared to what was specified.",
        "reference": "Paper title: 'RiTTA: Modeling Event Relations in Text-to-Audio Generation', Section: Relation aware Evaluation Metric MSR-RiTTA\\\\n'In relation aware evaluation, we base on the individual audio event to compute the metrics, which allows us to measure the relation between audio events...(equations and descriptions for f_1, f_2, and audio parsimony follow).'"
    },
    {
        "paper": "arXiv-2412.15922v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the performance of Tango 2 compare to other models in terms of relation-aware evaluation metrics on the RiTTA benchmark dataset?",
        "answer": "Tango 2 outperforms other models in terms of relation-aware evaluation metrics on the RiTTA benchmark dataset. Specifically, Tango 2 achieves the highest scores in metrics including mAPre (16.63), mARel (4.40), mAPar (12.53), and mAMSR (11.55).",
        "reference": "Paper title: 'RiTTA: Modeling Event Relations in Text-to-Audio Generation', Table: Benchmark quantitative result across all relations. \\\\n'mAPre, mARel and mAPar are in $10^{-2}$. mAPre and mARel can be treated as presence, relation correctness percentage ratio...Tango~2~(ghosal2023tango2) & 866M...'"
    }
]