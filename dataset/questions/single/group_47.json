[
    {
        "paper": "arXiv-2106.07447v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the word error rate (WER) reduction achieved by the HuBERT X-Large model on the test-other subset compared to the wav2vec 2.0 Large model in the 10-minute labeled data setup?",
        "answer": "The HuBERT X-Large model achieves a WER reduction from 8.2% to 6.8% on the test-other subset, which corresponds to a reduction of 1.4 percentage points.",
        "reference": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units, Section \\\"Main Results: Low- and High-Resource Setups\\\", Table \\\"Results and comparison with the literature on low resource setups (10-min, 1-hour, 10-hour, and 100-hour of labeled data).\\\""
    },
    {
        "paper": "arXiv-2106.07447v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the HuBERT Base model perform in terms of dev-other word error rate (WER) when using the masked prediction only ($\\\\alpha = 1.0$) with k-means clustering on MFCC with 100 clusters?",
        "answer": "The HuBERT Base model achieves a dev-other WER of 17.86% when using masked prediction only ($\\\\alpha = 1.0$) with k-means clustering on MFCC with 100 clusters.",
        "reference": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units, Section \\\"The Importance of Predicting Masked Frames\\\", Table \\\"The effect of the training objective and clustering quality on performance. $\\\\alpha$ is the weight for masked frames.\\\""
    },
    {
        "paper": "arXiv-2201.10207v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the relative reduction in training cost for the SPIRAL \\\\tscbase{} model compared to wav2vec 2.0 \\\\tscbase{} as proposed in the paper \\\"SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training\\\"?",
        "answer": "The SPIRAL \\\\tscbase{} model achieves an 80% reduction in training cost compared to wav2vec 2.0 \\\\tscbase{}.",
        "reference": "\\\"SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training\\\" - Section: Abstract, \\\"SPIRAL achieves competitive or better results compared to state-of-the-art speech pre-training method wav2vec 2.0, with significant reduction of training cost (80\\\\% for \\\\tscbase{} model, 65\\\\% for \\\\tscbig{} model).\\\""
    },
    {
        "paper": "arXiv-2201.10207v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the SPIRAL method perform on the LibriSpeech test-clean and test-other datasets compared to the wav2vec 2.0 \\\\tscbase{} with a Transformer LM as described in the paper \\\"SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training\\\"?",
        "answer": "The SPIRAL \\\\tscbase{} model with a Transformer LM achieves a WER of 2.7% on test-clean and 6.1% on test-other. In comparison, wav2vec 2.0 \\\\tscbase{} achieves 2.6% on test-clean and 6.3% on test-other.",
        "reference": "\\\"SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training\\\" - Table: Table 3, \\\"SPIRAL \\\\tscbase{} (ours) \\\\... Transf. \\\\... 2.7 & 5.8 && 3.3 & 7.0\\\" compared to \\\"wav2vec 2.0 \\\\tscbase{} \\\\... Transf. \\\\... 2.2 & 6.3 && 2.6 & 6.3\\\"."
    },
    {
        "paper": "arXiv-2212.04356v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the size of the dataset used in the \\\"Robust Speech Recognition via Large-Scale Weak Supervision\\\" study, and how is it composed in terms of language diversity?",
        "answer": "The dataset used in the \\\"Robust Speech Recognition via Large-Scale Weak Supervision\\\" study is 680,000 hours of labeled audio data. It is composed of 117,000 hours covering 96 non-English languages, and includes 125,000 hours of translation data from other languages to English (X→en).",
        "reference": "\\\"Robust Speech Recognition via Large-Scale Weak Supervision\\\", Section 1: Introduction: \\\"Of those 680,000 hours of audio, 117,000 hours cover 96 other languages. The dataset also includes 125,000 hours of X→en translation data.\\\""
    },
    {
        "paper": "arXiv-2212.04356v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the word error rate (WER) of the Whisper model compare to human performance and other machine learning models on the LibriSpeech Clean dataset?",
        "answer": "The Whisper model achieves a word error rate (WER) of 2.5 on the LibriSpeech clean-test dataset, which aligns with the performance of modern supervised baselines from mid-2019. This performance is relatively unremarkable compared to human benchmarks but more robust across various datasets compared to these models.",
        "reference": "\\\"Robust Speech Recognition via Large-Scale Weak Supervision\\\", Section 3: Experiments, English Speech Recognition: \\\"Although the best zero-shot Whisper model has a relatively unremarkable LibriSpeech clean-test WER of 2.5, which is roughly the performance of modern supervised baseline or the mid-2019 state of the art...\\\""
    }
]