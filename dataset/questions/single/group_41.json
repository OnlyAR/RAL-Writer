[
    {
        "paper": "arXiv-2202.04200v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the FID score achieved by Masked Generative Image Transformer (MaskGIT) on ImageNet 256x256 resolution?",
        "answer": "The FID score achieved by Masked Generative Image Transformer (MaskGIT) on ImageNet 256x256 resolution is 6.18.",
        "reference": "(Title: Masked Generative Image Transformer, Section: Class-conditional Image Synthesis, \\\"On ImageNet 256$\\\\times$256, without any special sampling strategies such as beam-search, top-k or nucleus sampling heuristics~\\\\cite{holtzman2019nucleus} or classifier guidance~\\\\cite{Razavi19vqvae2}, we significantly outperform VQGAN~\\\\cite{Esser21vqgan} in both Fr√©chet Inception Distance (FID)~\\\\cite{FID} ($\\\\bestfid$ vs $15.78$) and Inception Score (IS) ($\\\\bestis$ vs $78.3$).\\\")"
    },
    {
        "paper": "arXiv-2202.04200v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How many iterations does the MaskGIT iterative decoding process take to generate an image, and how does it compare to the sequential method?",
        "answer": "The MaskGIT iterative decoding process takes 8 iterations to generate an image. In comparison, the sequential method takes 256 rounds.",
        "reference": "(Title: Masked Generative Image Transformer, Section: Introduction, \\\"Examples shown here have resolutions 512$\\\\times$512, 512$\\\\times$512, and 512$\\\\times$2560 in the three columns, respectively.\\\" and \\\"\\\\model finishes its decoding in 8 iterations compared to the 256 rounds the sequential method takes.\\\")"
    },
    {
        "paper": "arXiv-2301.11093v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the impact of the noise schedule on model performance in the 'simple diffusion: End-to-end diffusion for high resolution images' research?",
        "answer": "In the 'simple diffusion: End-to-end diffusion for high resolution images' research, shifting the noise schedule significantly improved performance. For instance, on ImageNet at 256x256 resolution, the cosine schedule shifted to 32 improved the FID from 7.65 (original at 256) to 3.76 on the train data. Similarly, for 128x128 resolution, the shift to 32 improved the FID from 2.96 to 2.26.",
        "reference": "From the paper 'simple diffusion: End-to-end diffusion for high resolution images', Section: 'Effects of the proposed modifications', Table 1: \\\"Noise Schedule on ImageNet 128 and 256.\\\""
    },
    {
        "paper": "arXiv-2301.11093v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does dropout affect training performance in the 'simple diffusion: End-to-end diffusion for high resolution images' model?",
        "answer": "In the 'simple diffusion' model, dropout applied starting from lower resolution layers improves performance. Applying dropout starting from 64x64 resolution results in FID train and evaluation scores of 2.27 and 2.85, significantly better than having no dropout, which resulted in FID scores of 3.74 and 3.91.",
        "reference": "From the paper 'simple diffusion: End-to-end diffusion for high resolution images', Section: 'Effects of the proposed modifications', Table 2: \\\"Dropout Ablation on ImageNet 128.\\\""
    },
    {
        "paper": "arXiv-2310.05737v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the improvement in the Frechet Video Distance (FVD) score of the proposed model compared to MAGVIT on the Kinetics-600 dataset?",
        "answer": "The proposed model achieves an FVD score of 4.3 on the Kinetics-600 dataset, compared to MAGVIT's FVD score of 9.9, which means an improvement of 5.6 points in FVD score.",
        "reference": "\\\"Language Model Beats Diffusion---  Tokenizer is Key to Visual Generation\\\", \\\\nSection \\\"Visual Generation\\\", Table 2: \\\"our model surpasses all prior arts in both benchmarks. Specifically, it outperforms the previous best model MAGVIT by a large margin...\\\""
    },
    {
        "paper": "arXiv-2310.05737v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the proposed model's performance on the ImageNet 512x512 image generation task compare with the best diffusion model in terms of Frechet Inception Distance (FID)?",
        "answer": "The proposed model achieves an FID score of 1.91 on the ImageNet 512x512 image generation task, which is better than the best diffusion model's FID score of 2.65, showing an improvement of 0.74 points in FID score.",
        "reference": "\\\"Language Model Beats Diffusion---  Tokenizer is Key to Visual Generation\\\", \\\\nSection \\\"Visual Generation\\\", Table 3: \\\"Our model surpasses the best performing diffusion models both in sampling quality (FID and IS) and inference-time efficiency (sampling steps).\\\""
    }
]