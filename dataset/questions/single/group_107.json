[
    {
        "paper": "arXiv-2007.08270v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the reported improvement in segmentation performance of the Kernelized Memory Network (KMN) compared to existing methods on the DAVIS 2017 test-dev set?",
        "answer": "The Kernelized Memory Network (KMN) surpasses the state-of-the-art methods by a significant margin, achieving a +5% improvement in the General Mean ($\\\\mathcal{G_M}$) score on the DAVIS 2017 test-dev set.",
        "reference": "Kernelized Memory Network for Video Object Segmentation, Section 5.2.2: \\\"We find that our approach surpasses the state-of-the-art method by a significant margin (+5\\\\% $\\\\mathcal{G_M}$ score).\\\""
    },
    {
        "paper": "arXiv-2007.08270v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the runtime per frame of the Kernelized Memory Network (KMN) on the DAVIS 2016 validation set?",
        "answer": "The runtime per frame of the Kernelized Memory Network (KMN) on the DAVIS 2016 validation set is 0.12 seconds.",
        "reference": "Kernelized Memory Network for Video Object Segmentation, Abstract: \\\"In addition, the runtime of KMN is 0.12 seconds per frame on the DAVIS 2016 validation set.\\\""
    },
    {
        "paper": "arXiv-2109.11404v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What are the performance metrics of the HMMN model on the DAVIS 2016 validation set compared to other methods, as reported in the paper \\\"Hierarchical Memory Matching Network for Video Object Segmentation\\\"?",
        "answer": "The HMMN model achieves a $\\\\n\\\\mathcal{J\\\\&F}$ score of 89.4 without YouTube-VOS (YV) training data and 90.8 with YV. \\\\n\\\\mathcal{J}$ and $\\\\n\\\\mathcal{F}$ scores are 88.2 and 90.6 without YV, and 89.6 and 92.0 with YV, respectively. It outperforms methods like STM (+YV) which has $\\\\n\\\\mathcal{J\\\\&F}$ score of 89.3.",
        "reference": "\\\"Hierarchical Memory Matching Network for Video Object Segmentation\\\", Section: More Quantitative Results, Table: Full comparison on DAVIS 2016 validation set."
    },
    {
        "paper": "arXiv-2109.11404v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the HMMN model perform on the DAVIS 2017 test-dev set relative to other methods, as documented in the paper \\\"Hierarchical Memory Matching Network for Video Object Segmentation\\\"?",
        "answer": "The HMMN model achieves a $\\\\n\\\\mathcal{J\\\\&F}$ score of 78.6, with $\\\\n\\\\mathcal{J}$ and $\\\\n\\\\mathcal{F}$ scores of 74.7 and 82.5, respectively. This ranks it higher than the KMN (+YV) method which has a $\\\\n\\\\mathcal{J\\\\&F}$ score of 77.2.",
        "reference": "\\\"Hierarchical Memory Matching Network for Video Object Segmentation\\\", Section: More Quantitative Results, Table: Full comparison on DAVIS 2017 test-dev set."
    },
    {
        "paper": "arXiv-2208.10128v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the performance of the SWEM method on the DAVIS 2017 validation dataset in terms of the mean $\\\\nabla J$ \\\\\\\\nabla&F}$ measure, and how does it compare to its inference speed?",
        "answer": "The SWEM method achieves a performance of 84.3% in terms of the mean $\\\\nabla J$\\\\\\\\nabla&F}$ measure on the DAVIS 2017 validation dataset. It has an inference speed of 36 FPS (Frames Per Second).",
        "reference": "Reference: \\\"SWEM: Towards Real-Time Video Object Segmentation with Sequential Weighted Expectation-Maximization, Abstract.\\\"\\\\n\\\"... high efficiency (36 FPS) and high performance (84.3% $\\\\nabla J\\\\\\\\nabla&F$ on DAVIS 2017 validation dataset) of SWEM.\\\""
    },
    {
        "paper": "arXiv-2208.10128v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How did SWEM perform in comparison to STM and STCN on the DAVIS 2017 validation dataset when trained only on video data (DAVIS and YouTube-VOS)?",
        "answer": "When trained only on video data (DAVIS and YouTube-VOS), SWEM achieved an overall $\\\\nabla J&F$ score of 81.9% on the DAVIS 2017 validation dataset, outperforming STM which scored 80.0% but falling behind STCN which achieved 81.1%.",
        "reference": "Reference: \\\"SWEM: Towards Real-Time Video Object Segmentation with Sequential Weighted Expectation-Maximization, Appendix A.\\\"\\\\nTable in described content: \\\"Training on video datasets.\\\""
    }
]