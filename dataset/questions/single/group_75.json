[
    {
        "paper": "arXiv-2110.11571v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the attack success rate (ASR) of the Dynamic backdoor attack on the CIFAR-10 dataset when no defense is applied?",
        "answer": "The attack success rate (ASR) of the Dynamic backdoor attack on the CIFAR-10 dataset is 100% when no defense is applied.",
        "reference": "Title: Anti-Backdoor Learning: Training Clean Models on Poisoned Data, Section: Experiments, Table 1. \\\"No Defense\\\" ASR for Dynamic is reported as 100%."
    },
    {
        "paper": "arXiv-2110.11571v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the Anti-Backdoor Learning (ABL) method perform in terms of clean accuracy (CA) on CIFAR-10 compared to the NAD method?",
        "answer": "The Anti-Backdoor Learning (ABL) method achieves a clean accuracy (CA) of 84.76% on CIFAR-10, while the NAD method achieves a CA of 80.37%.",
        "reference": "Title: Anti-Backdoor Learning: Training Clean Models on Poisoned Data, Section: Experiments, Table 1. ABL CA reported as 84.76% and NAD CA as 80.37% on CIFAR-10."
    },
    {
        "paper": "arXiv-2202.03423v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the attack success rate (ASR) and benign accuracy (BA) of the proposed Decoupling-based Backdoor Defense (DBD) when defending against the BadNets attack on the CIFAR-10 dataset?",
        "answer": "The attack success rate (ASR) of the proposed Decoupling-based Backdoor Defense (DBD) when defending against the BadNets attack on the CIFAR-10 dataset is 0.96%, and the benign accuracy (BA) is 92.41%.",
        "reference": "Title: Backdoor Defense via Decoupling the Training Process, Section: Main Results, \\\"As shown in Table 3, DBD ... the attack success rate of models with DBD is less than 2% in all cases (mostly < 0.5%), which verifies that our method can successfully prevent the creation of hidden backdoors...\\\""
    },
    {
        "paper": "arXiv-2202.03423v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the benign accuracy of the Decoupling-based Backdoor Defense (DBD) compare to the Neural Cleanse (NC) defense when defending against the WaNet attack on the ImageNet dataset?",
        "answer": "When defending against the WaNet attack on the ImageNet dataset, the benign accuracy of the Decoupling-based Backdoor Defense (DBD) is 82.05%, which is higher compared to the Neural Cleanse (NC) defense, which has a benign accuracy of 80.32%.",
        "reference": "Title: Backdoor Defense via Decoupling the Training Process, Section: Main Results, Table 3 \\\"... DBD (ours) ... 82.05... NC ... 80.32 ... \\\"."
    },
    {
        "paper": "arXiv-2303.06818v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the clean accuracy (CA) achieved by the Causality-inspired Backdoor Defense (CBD) on the CIFAR-10 dataset when there is no attack?",
        "answer": "The clean accuracy (CA) achieved by the Causality-inspired Backdoor Defense (CBD) on the CIFAR-10 dataset when there is no attack is 88.95%.",
        "reference": "Title: Backdoor Defense via Deconfounded Representation Learning, Section: Effectiveness of CBD, Table 1."
    },
    {
        "paper": "arXiv-2303.06818v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the Causality-inspired Backdoor Defense (CBD) perform in terms of average attack success rate (ASR) on the ImageNet Subset dataset when compared to DBD and ABL methods?",
        "answer": "On the ImageNet Subset dataset, the Causality-inspired Backdoor Defense (CBD) achieves an average attack success rate (ASR) of 0.91%, which is lower than DBD's 2.36% and ABL's 5.93%.",
        "reference": "Title: Backdoor Defense via Deconfounded Representation Learning, Section: Effectiveness of CBD, Table 1."
    }
]