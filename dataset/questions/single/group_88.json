[
    {
        "paper": "arXiv-2104.06064v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the composition of the KolektorSDD2 dataset, as introduced in the paper \\\"Mixed supervision for surface-defect detection: from weakly to fully supervised learning\\\"?",
        "answer": "The KolektorSDD2 dataset consists of a total of 3335 images, with 246 positive samples (defective) in the training subset and 110 positive samples in the test subset. Additionally, there are 2085 negative samples in the training set and 894 negative samples in the test set. The defects vary greatly in shape, size, and color, ranging from small scratches to large surface imperfections.",
        "reference": "\\\"Mixed supervision for surface-defect detection: from weakly to fully supervised learning\\\", Section 'KolektorSDD2', paragraph 4: \\\"The dataset is split into the train and the test subsets, with 2085 negative and 246 positive samples in the train, and 894 negative and 110 positive samples in the test subset.\\\""
    },
    {
        "paper": "arXiv-2104.06064v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What are the average precision (AP) results of the proposed method in weakly, mixed, and fully supervised modes for the DAGM dataset, according to the paper \\\"Mixed supervision for surface-defect detection: from weakly to fully supervised learning\\\"?",
        "answer": "For the DAGM dataset, the proposed method achieves an average precision (AP) of 74.0% in the weakly supervised mode (N=0). In mixed supervision mode with 5 fully labeled samples (N=5), the AP is 91.5%, and with 15 fully labeled samples (N=15), the AP reaches 100%. In the fully supervised mode (N=N_all), the AP is also 100%.",
        "reference": "\\\"Mixed supervision for surface-defect detection: from weakly to fully supervised learning\\\", Table 1: \\\"Ours (N=0), AP: 74.0\\\", \\\"Ours (N=5), AP: 91.5\\\", \\\"Ours (N=15), AP: 100.0\\\", \\\"Ours (N=$N_{all}$), AP: 100.0\\\"."
    },
    {
        "paper": "arXiv-2104.08391v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the size and composition of the FSC-147 dataset introduced in the paper \\\"Learning to Count Everything\\\"?",
        "answer": "The FSC-147 dataset consists of 6135 images from 147 object categories. The dataset comes with dot and bounding box annotations, making it suitable for the few-shot counting task.",
        "reference": "\\\"Learning to Count Everything\\\", Section: The FSC-147 Dataset, \\\"Our dataset consists of 6135 images across a diverse set of 147 object categories...\\\""
    },
    {
        "paper": "arXiv-2104.08391v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the FamNet method perform on the test set compared to the MAML method in the paper \\\"Learning to Count Everything\\\"?",
        "answer": "FamNet achieves a lower Mean Absolute Error (MAE) of 22.08 and a lower Root Mean Squared Error (RMSE) of 99.54 on the test set compared to MAML, which has an MAE of 24.90 and an RMSE of 112.68.",
        "reference": "\\\"Learning to Count Everything\\\", Section: Comparison with Few-Shot Approaches, Table 2: \\\"FamNet (Proposed) & 22.08 & 99.54...MAML & 24.90 & 112.68...\\\""
    },
    {
        "paper": "arXiv-2207.14315v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the composition of the VisA dataset proposed in the paper 'SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and Segmentation'?",
        "answer": "The VisA dataset consists of 10,821 high-resolution color images, out of which 9,621 are normal samples and 1,200 are anomalous samples. It covers 12 different objects in 3 domains and includes both image and pixel-level labels.",
        "reference": "Reference: 'SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and Segmentation', Section Abstract, 'We release the Visual Anomaly (VisA) Dataset consisting of 10,821 high-resolution color images (9,621 normal and 1,200 anomalous samples) covering 12 objects in 3 domains, making it the largest industrial anomaly detection dataset to date. Both image and pixel-level labels are provided.'"
    },
    {
        "paper": "arXiv-2207.14315v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How much does the SPot-the-Difference (SPD) method improve the Area Under the Precision-Recall curve (AU-PR) for anomaly segmentation in the 2-class high-shot setup, according to the paper 'SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and Segmentation'?",
        "answer": "The SPot-the-Difference (SPD) method improves the Area Under the Precision-Recall curve (AU-PR) for anomaly segmentation by 5.9% over SimSiam and by 6.8% over supervised pre-training in the 2-class high-shot setup.",
        "reference": "Reference: 'SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and Segmentation', Section Abstract, 'For example, SPD improves Area Under the Precision-Recall curve (AU-PR) for anomaly segmentation by 5.9% and 6.8% over SimSiam and supervised pre-training respectively in the 2-class high-shot regime.'"
    }
]