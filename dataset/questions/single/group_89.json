[
    {
        "paper": "arXiv-1908.07442v5.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does TabNet perform compared to other feature selection-based DNN models on the Syn2 dataset?",
        "answer": "TabNet achieves a test AUC of 0.892 with a standard deviation of 0.004 on the Syn2 dataset, which is the best performance among the models compared in the study.",
        "reference": "\\\"TabNet: Attentive Interpretable Tabular Learning,\\\" Table 1: \\\"TabNet & .682 $\\\\pm$ .005 & \\\\textbf{.892 $\\\\pm$ .004} & .897 $\\\\pm$ .003 & .776 $\\\\pm$ .017 & \\\\textbf{.789 $\\\\pm$ .009} & \\\\textbf{.878 $\\\\pm$ .004}\\\""
    },
    {
        "paper": "arXiv-1908.07442v5.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What are the test accuracy percentages for TabNet and AutoML Tables on the Forest Cover Type dataset, and how do they compare?",
        "answer": "TabNet achieves a test accuracy of 96.99%, while AutoML Tables achieves 94.95% test accuracy on the Forest Cover Type dataset. Therefore, TabNet outperforms AutoML Tables by 2.04%.",
        "reference": "\\\"TabNet: Attentive Interpretable Tabular Learning,\\\" Table 2: \\\"AutoML Tables  & 94.95\\\" and \\\"TabNet  &  \\\\textbf{96.99}\\\""
    },
    {
        "paper": "arXiv-2012.06678v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the average AUC gain of TabTransformer over baseline MLP in supervised learning as reported in the paper \\\"TabTransformer: Tabular Data Modeling Using Contextual Embeddings\\\"?",
        "answer": "The TabTransformer model shows an average AUC gain of 1.0% over the baseline MLP in supervised learning.",
        "reference": "\\\"TabTransformer: Tabular Data Modeling Using Contextual Embeddings\\\", Section 3.1, Table 1: \\\"The TabTransformer with the Transformer layers outperforms the baseline MLP on 14 out of 15 datasets with an average 1.0% gain in AUC.\\\""
    },
    {
        "paper": "arXiv-2012.06678v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does TabTransformer perform in semi-supervised learning compared to other models when there are 200 labeled data points available, according to the paper \\\"TabTransformer: Tabular Data Modeling Using Contextual Embeddings\\\"?",
        "answer": "In semi-supervised learning with 200 labeled data points, TabTransformer-RTD achieves a mean AUC score of 70.9% which is the best among all models listed for datasets with more than 30K data points. TabTransformer-MLM also performs well with a mean AUC of 71.0%.",
        "reference": "\\\"TabTransformer: Tabular Data Modeling Using Contextual Embeddings\\\", Section 5.4, Table 10: \\\"With 200 labeled data points, TabTransformer-RTD achieves a mean AUC score of 70.9%, and TabTransformer-MLM yields 71.0% for datasets with more than 30K data points.\\\""
    },
    {
        "paper": "arXiv-2304.10946v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What was the overall accuracy of CancerGPT and other models for predicting drug pair synergy in rare tissues, and how were the results influenced by the number of shots (k)?",
        "answer": "The LLM-based models (CancerGPT, GPT-2, GPT-3) achieved comparable or better accuracy in most cases compared to the baselines. In the zero-shot scenario, LLM-based models generally had higher accuracy than baseline models, except in stomach and bone tissues. As the number of shots increased, mixed patterns were observed across tissues. TabTransformer consistently increased in accuracy with more shots, CancerGPT showed improved accuracy with more shots in endometrium and soft tissue, and GPT-3 showed improvements in liver, soft tissue, and bone, indicating complementary information from few-shot training. However, additional training data did not always improve performance, as observed in stomach and urinary tract tissues. With 128 shots, GPT-3 achieved the highest accuracy in pancreas, liver, soft tissue, and bone tissues, while TabTransformer performed best in endometrium, stomach, and urinary tract.",
        "reference": "\\\"CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models\\\" - Section 'Accuracy' and experimental results shown in tables 4 and 5."
    },
    {
        "paper": "arXiv-2304.10946v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "For which tissue types did GPT-3 achieve higher accuracy than other LLM-based models, and how does this compare to CancerGPT's performance across different tissues?",
        "answer": "GPT-3 achieved higher accuracy than CancerGPT in tissues with limited data or unique characteristics, such as the pancreas, endometrium, liver, soft tissue, and bone. On the other hand, CancerGPT performed better than GPT-3 in tissues with less distinctive characteristics like stomach and urinary tract. This indicates GPT-3's advantage in generalizability for challenging tissues beyond common ones.",
        "reference": "\\\"CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models\\\" - Section 'Tissue types and accuracy' and discussion about comparisons of LLM-based models."
    }
]