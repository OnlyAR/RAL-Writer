[
    {
        "paper": "arXiv-1909.06956v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the composition of the Makeup-Wild dataset introduced in the paper 'PSGAN: Pose and Expression Robust Spatial-Aware GAN for Customizable Makeup Transfer'?",
        "answer": "The Makeup-Wild dataset consists of 403 with-makeup images and 369 non-makeup images, making a total of 772 images collected from the Internet and manually filtered to avoid frontal faces or neutral expressions.",
        "reference": "PSGAN: Pose and Expression Robust Spatial-Aware GAN for Customizable Makeup Transfer - Section: Data Collection: 'Finally, 403 with-makeup images and 369 non-makeup images are collected to form the Makeup-Wild dataset.'"
    },
    {
        "paper": "arXiv-1909.06956v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What are the results of the user study comparing the PSGAN method to other methods on the MT and Makeup-Wild datasets?",
        "answer": "In the user study, PSGAN was selected as the best by 61.5% on the MT dataset, compared to BeautyGAN (32.5%), DIA (3.25%), CycleGAN (2.5%), and LADN (0.25%). On the Makeup-Wild dataset, PSGAN was selected as the best by 83.5% compared to BeautyGAN (13.5%), DIA (1.75%), CycleGAN (1.25%), and LADN (0.0%).",
        "reference": "PSGAN: Pose and Expression Robust Spatial-Aware GAN for Customizable Makeup Transfer - Section: Comparison: Quantitative Comparison: 'Table 2 shows the human evaluation results. Our PSGAN outperforms other methods by a large margin, especially on the M-Wild test set.'"
    },
    {
        "paper": "arXiv-2207.09840v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What percentage of participants in the user study selected EleGANt as the best method for visual quality of generated makeup transfer images?",
        "answer": "59.00% of participants selected EleGANt as the best method for visual quality of generated makeup transfer images.",
        "reference": "Title: EleGANt: Exquisite and Locally Editable GAN for Makeup Transfer. Section: Quantitative Comparison. Quote: \\\"Table 5 demonstrates the results of the user study. Our EleGAnt outperforms other methods in all aspects, especially in synthesizing makeup details.\\\" (visual quality: 59.00%)"
    },
    {
        "paper": "arXiv-2207.09840v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How many non-makeup and makeup images are in the MT dataset used for training EleGANt?",
        "answer": "The MT dataset used for training EleGANt contains 1115 non-makeup images and 2719 makeup images.",
        "reference": "Title: EleGANt: Exquisite and Locally Editable GAN for Makeup Transfer. Section: Experiment Settings. Quote: \\\"We use the MT (Makeup Transfer) dataset which contains 1115 non-makeup images and 2719 makeup images to train our model.\\\""
    },
    {
        "paper": "arXiv-2209.03444v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the significance of the percentage of predicted superconductors generated by the ScGAN model?",
        "answer": "The ScGAN model achieved a predicted superconductivity percentage of 74.50% for the entirety of the SuperCon, with an estimated true percentage of superconductivity being 70.42%. This is significantly higher compared to the 3% discovery rate from manual search methods reported in earlier studies, indicating a 23-fold increase in discovery rate using the ScGAN model.",
        "reference": "Paper Title: ScGAN: A Generative Adversarial Network to Predict Hypothetical Superconductors; Section: Results - Superconductivity, Table 6 & \\\"Compared to manual search methods, this is once again a significant improvement, as trials have shown that only about 3% of synthesized compounds, even among seemingly promising candidates, turn out to be superconductors.\\\""
    },
    {
        "paper": "arXiv-2209.03444v1.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the composition of the filtered SuperCon dataset contribute to training the GAN model?",
        "answer": "The filtered SuperCon dataset comprises approximately 16,489 superconductors categorized into three classes: 7,304 (44.4%) are cuprates, 1,436 (8.7%) are pnictides, and 7,749 (47.0%) are categorized as others. The model's ability to learn different classes of superconductors, especially cuprates and pnictides, is tested by training with these specific subsets.",
        "reference": "Paper Title: ScGAN: A Generative Adversarial Network to Predict Hypothetical Superconductors; Section: Data Collection, Table 1 & \\\"Lastly, the SuperCon dataset was split into three different groups (classes): cuprates, pnictides (iron-based) and others... \\\" the quantitative counts of these different groups.\\\" Table 1."
    }
]