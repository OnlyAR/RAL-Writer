[
    {
        "paper": "arXiv-1810.01398v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the Word Error Rate (WER) achieved by the Optimal Completion Distillation (OCD) method on the Wall Street Journal dataset?",
        "answer": "The Optimal Completion Distillation (OCD) method achieves a Word Error Rate (WER) of 9.3% on the Wall Street Journal dataset.",
        "reference": "\\\"Optimal Completion Distillation for Sequence Learning\\\" - Abstract: \\\"OCD achieves the state-of-the-art performance on end-to-end speech recognition, on both Wall Street Journal and Librispeech datasets, achieving $9.3\\\\%$...\\\""
    },
    {
        "paper": "arXiv-1810.01398v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the Character Error Rate (CER) and Word Error Rate (WER) achieved by the OCD method compare to other approaches on the Wall Street Journal dataset?",
        "answer": "The OCD method achieves a Character Error Rate (CER) of 3.1% and a Word Error Rate (WER) of 9.3% on the Wall Street Journal dataset. This performance is better than other approaches such as seq2seq + MLE (CER of 3.6%, WER of 10.6%) and seq2seq + SS (CER of 3.6%, WER of 10.2%).",
        "reference": "\\\"Optimal Completion Distillation for Sequence Learning\\\" - Section Experiments, Table \\\"Character Error Rate (CER) and Word Error Rate (WER) results on the end-to-end speech recognition WSJ task.\\\""
    },
    {
        "paper": "arXiv-1902.01955v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the performance improvement percentage when rescoring N-best lists with grapheme and phoneme models, as reported in the paper \\\"On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition\\\"?",
        "answer": "In the paper \\\"On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition\\\", rescoring the N-best lists with grapheme and phoneme models results in an improvement of 9% relative in both cases for the test-clean set. On the test-other set, the rescoring leads to an 8% improvement with the phonemic model and a 9% improvement with the graphemic model.",
        "reference": "\\\"On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition\\\" - Rescoring Experiments (Table 7)"
    },
    {
        "paper": "arXiv-1902.01955v2.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the Out-of-Vocabulary (OOV) rate for the 100hr dataset in the paper \\\"On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition\\\"?",
        "answer": "The Out-of-Vocabulary (OOV) rate for the 100hr dataset is 2.5% for both the dev-clean and dev-other subsets, and 2.4% and 2.8% for the test-clean and test-other subsets, respectively.",
        "reference": "\\\"On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition\\\" - Table 1: Dataset Section."
    },
    {
        "paper": "arXiv-1904.08779v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the WER improvement on the LibriSpeech 960h test-other set when using SpecAugment with a language model compared to the previous state-of-the-art hybrid system?",
        "answer": "Using SpecAugment with a language model on the LibriSpeech 960h test-other set achieves a WER of 5.8%, compared to the previous state-of-the-art hybrid system which had a WER of 7.5%. This represents an improvement of 1.7% in WER.",
        "reference": "Title: SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition. Section: Abstract. \\\"On LibriSpeech, we achieve... 5.8% WER with shallow fusion with a language model. This compares to the previous state-of-the-art hybrid system of 7.5% WER.\\\""
    },
    {
        "paper": "arXiv-1904.08779v3.tex",
        "topic": "data",
        "subtopic": "data-related content",
        "question": "For the Switchboard/CallHome portion of the Hub5'00 test set, how does SpecAugment perform without a language model compared to the previous state-of-the-art hybrid system?",
        "answer": "Without a language model, SpecAugment achieves a WER of 7.2% for Switchboard and 14.6% for CallHome, compared to the previous state-of-the-art hybrid system WER of 8.3% for Switchboard and 17.3% for CallHome. This shows an improvement of 1.1% for Switchboard and 2.7% for CallHome.",
        "reference": "Title: SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition. Section: Abstract. \\\"For Switchboard, we achieve 7.2%/14.6%... which compares to the previous state-of-the-art hybrid system at 8.3%/17.3% WER.\\\""
    }
]