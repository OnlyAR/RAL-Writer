[
    {
        "paper": [
            "arXiv-2203.02385v1.tex",
            "arXiv-2203.13504v1.tex",
            "arXiv-2306.17799v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How do the accuracies of MM-DFN and EmoCaps compare on the IEMOCAP dataset?",
        "answer": "On the IEMOCAP dataset, MM-DFN achieves an accuracy of 68.21%, while EmoCaps achieves an accuracy of 71.77%.",
        "reference": "MM-DFN: Multimodal Dynamic Fusion Network For Emotion Recognition in Conversations; EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition"
    },
    {
        "paper": [
            "arXiv-2203.02385v1.tex",
            "arXiv-2203.13504v1.tex",
            "arXiv-2306.17799v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the weighted F1 score performance of MM-DFN and LMAM when plugged into MM-DFN on the MELD dataset?",
        "answer": "On the MELD dataset, MM-DFN achieves a weighted F1 score of 59.46%. When LMAM is plugged into MM-DFN, it achieves a slightly improved weighted F1 score of 59.62%.",
        "reference": "MM-DFN: Multimodal Dynamic Fusion Network For Emotion Recognition in Conversations; A Low-rank Matching Attention based Cross-modal Feature Fusion Method for Conversational Emotion Recognition"
    },
    {
        "paper": [
            "arXiv-2203.02385v1.tex",
            "arXiv-2203.13504v1.tex",
            "arXiv-2306.17799v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "Comparing MM-DFN and EmoCaps, which model performs better in terms of average F1 score on the MELD dataset?",
        "answer": "On the MELD dataset, EmoCaps achieves a higher average F1 score of 64.00% compared to MM-DFN, which achieves an average F1 score of 59.46%.",
        "reference": "MM-DFN: Multimodal Dynamic Fusion Network For Emotion Recognition in Conversations; EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition"
    },
    {
        "paper": [
            "arXiv-2203.02385v1.tex",
            "arXiv-2203.13504v1.tex",
            "arXiv-2306.17799v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the accuracy of LMAM when applied to EmoCaps compare to when applied to M2FNet on the IEMOCAP dataset?",
        "answer": "When LMAM is applied to EmoCaps, the accuracy on the IEMOCAP dataset is 73.67%. When LMAM is applied to M2FNet, the accuracy is 70.31%.",
        "reference": "EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition; A Low-rank Matching Attention based Cross-modal Feature Fusion Method for Conversational Emotion Recognition"
    },
    {
        "paper": [
            "arXiv-2203.02385v1.tex",
            "arXiv-2203.13504v1.tex",
            "arXiv-2306.17799v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the impact on weighted F1 score when LMAM is incorporated into bc-LSTM compared to when incorporated into DialogueGCN on the IEMOCAP dataset?",
        "answer": "Incorporating LMAM into bc-LSTM increases the weighted F1 score to 60.29%, while incorporating LMAM into DialogueGCN increases the weighted F1 score to 66.12% on the IEMOCAP dataset.",
        "reference": "A Low-rank Matching Attention based Cross-modal Feature Fusion Method for Conversational Emotion Recognition; EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition"
    },
    {
        "paper": [
            "arXiv-2203.02385v1.tex",
            "arXiv-2203.13504v1.tex",
            "arXiv-2306.17799v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "Which model, MM-DFN or LMAM applied to MM-DFN, has a higher accuracy on the IEMOCAP dataset, and what are those accuracies?",
        "answer": "On the IEMOCAP dataset, LMAM applied to MM-DFN has a higher accuracy of 69.94%, compared to MM-DFN's accuracy of 68.21%.",
        "reference": "MM-DFN: Multimodal Dynamic Fusion Network For Emotion Recognition in Conversations; A Low-rank Matching Attention based Cross-modal Feature Fusion Method for Conversational Emotion Recognition"
    }
]