[
    {
        "paper": [
            "arXiv-2106.07447v1.tex",
            "arXiv-2201.10207v3.tex",
            "arXiv-2212.04356v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the amount of unlabeled data used in the HuBERT method compare to the data used in Whisper for training, and what are the performance implications?",
        "answer": "HuBERT utilizes either 960 hours from LibriSpeech or 60,000 hours from Libri-Light in its training. In contrast, Whisper is trained on a much larger scale, using 680,000 hours of multilingual and multitask supervision. As a result, Whisper achieves zero-shot generalization across various datasets and performs robustly compared to supervised models, demonstrating large-scale datasets' effectiveness with a relative error reduction of 55.2% compared to a similar Wav2vec 2.0 model.",
        "reference": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units; Robust Speech Recognition via Large-Scale Weak Supervision."
    },
    {
        "paper": [
            "arXiv-2106.07447v1.tex",
            "arXiv-2201.10207v3.tex",
            "arXiv-2212.04356v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "Compare the performance of HuBERT and SPIRAL on low-resource ASR tasks with 100 hours of labeled data.",
        "answer": "HuBERT shows impressive performance in low-resource setups with 100 hours of labeled data, achieving a WER of 2.1 on test-clean and 3.0 on test-other for its X-Large model. SPIRAL's \\\\tscbig{} model with a similar amount of labeled data (\\\\texttt{train-clean-100}) achieves a WER of 2.2% on test-clean and 4.3% on test-other with a Transformer language model employed in decoding, which is comparable to the HuBERT's performance.",
        "reference": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units; SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training."
    },
    {
        "paper": [
            "arXiv-2106.07447v1.tex",
            "arXiv-2201.10207v3.tex",
            "arXiv-2212.04356v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "In multilingual setups, compare the performance and language variety of Whisper and HuBERT models.",
        "answer": "Whisper's dataset encompasses 680,000 hours with significant amounts of multilingual data, covering speech recognition in 75 languages. In contrast, HuBERT primarily discusses its performance on English datasets like LibriSpeech, focusing less on multilingual variances. Whisper's performance in multilingual ASR tasks, such as on MLS, shows strong results as a zero-shot model, indicating its superior inherent multilingual capabilities compared to HuBERT, which is more focused on achieving state-of-the-art results in a largely English-focused setup.",
        "reference": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units; Robust Speech Recognition via Large-Scale Weak Supervision."
    },
    {
        "paper": [
            "arXiv-2106.07447v1.tex",
            "arXiv-2201.10207v3.tex",
            "arXiv-2212.04356v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "Compare HuBERT and Whisper models in terms of their handling and impact on ASR benchmarks like LibriSpeech and CHiME6.",
        "answer": "HuBERT achieves state-of-the-art performance on LibriSpeech benchmarks, particularly with its X-Large model yielding a WER as low as 2.1 on test-clean. Whisper, on the other hand, demonstrates robustness across diverse datasets by achieving a relative WER reduction of 61.2% on CHiME6 compared to wav2vec 2.0, indicating its strong performance in more challenging noisy environments. Whisper's zero-shot robustness stands out against HuBERT's fine-tuning on specific datasets like LibriSpeech.",
        "reference": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units; Robust Speech Recognition via Large-Scale Weak Supervision."
    },
    {
        "paper": [
            "arXiv-2106.07447v1.tex",
            "arXiv-2201.10207v3.tex",
            "arXiv-2212.04356v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How do SPIRAL and Whisper methods perform in terms of robustness across noisy environments, specifically considering real noisy test data?",
        "answer": "SPIRAL demonstrates improved robustness with multi-condition training, achieving a 9.0% to 13.3% relative WER reduction on real noisy data from CHiME-3 compared to baseline models. Whisper shows robustness to noise by achieving lower degradation in WER when exposed to different levels of noise such as pub noise, performing better than other models under high-noise conditions. Whisper thus demonstrates more consistent robustness across a wider range of noise conditions than SPIRAL focused multi-condition fine-tuning.",
        "reference": "SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training; Robust Speech Recognition via Large-Scale Weak Supervision."
    },
    {
        "paper": [
            "arXiv-2106.07447v1.tex",
            "arXiv-2201.10207v3.tex",
            "arXiv-2212.04356v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "Examine dataset scaling effects in the Whisper approach compared to HuBERT's iterative refinement strategy. How do these strategies affect performance gains?",
        "answer": "Whisper's approach, using 680,000 hours of labeled data, shows a strong correlation between dataset size and performance, achieving an average word error rate that halves with every 16Ã— increase in training data amount. This large scale ensures robust performance gains across tasks. On the other hand, HuBERT's iterative clustering manageable within a 60,000-hour dataset achieves state-of-the-art results efficiently on specific English benchmarks like LibriSpeech but doesn't exhibit comparable dataset scaling gains outside this focused evaluation.",
        "reference": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units; Robust Speech Recognition via Large-Scale Weak Supervision."
    }
]