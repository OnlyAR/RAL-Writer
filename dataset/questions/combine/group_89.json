[
    {
        "paper": [
            "arXiv-1908.07442v5.tex",
            "arXiv-2012.06678v1.tex",
            "arXiv-2304.10946v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the TabNet model's performance on the Mushroom dataset for feature importance compare with the TabTransformer model on the same dataset type?",
        "answer": "In the TabNet model, the Mushroom dataset showed the feature importance ratio for 'Odor' as 43%, while no specific feature importance scores were provided for this dataset type using the TabTransformer model. The comparison between methods is not directly given for feature importance in the TabTransformer results.",
        "reference": "TabNet: Attentive Interpretable Tabular Learning; TabTransformer: Tabular Data Modeling Using Contextual Embeddings"
    },
    {
        "paper": [
            "arXiv-1908.07442v5.tex",
            "arXiv-2012.06678v1.tex",
            "arXiv-2304.10946v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the reported average AUC for TabNet and TabTransformer models when benchmarked across multiple datasets?",
        "answer": "For the TabNet model, the average performance was not specified across all datasets, while the TabTransformer model reported an average AUC of 82.8% across 15 datasets. It outperformed MLP with an average 1.0% gain and was comparable with GBDT.",
        "reference": "TabNet: Attentive Interpretable Tabular Learning; TabTransformer: Tabular Data Modeling Using Contextual Embeddings"
    },
    {
        "paper": [
            "arXiv-1908.07442v5.tex",
            "arXiv-2012.06678v1.tex",
            "arXiv-2304.10946v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How do TabNet and TabTransformer models compare in terms of interpretability using feature importance and missing data imputation, respectively?",
        "answer": "The TabNet model emphasizes interpretability through feature importance by using instance-wise feature selection, showing a 43% importance score for 'Odor'. In contrast, the TabTransformer model shows robustness to missing data through contextual embeddings, demonstrating that average embeddings can stabilize performance on incomplete datasets without specific numerical importance scores.",
        "reference": "TabNet: Attentive Interpretable Tabular Learning; TabTransformer: Tabular Data Modeling Using Contextual Embeddings"
    },
    {
        "paper": [
            "arXiv-1908.07442v5.tex",
            "arXiv-2012.06678v1.tex",
            "arXiv-2304.10946v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "In terms of semi-supervised learning performance with 50 labeled data points, how do the TabNet and TabTransformer-RTD models compare across datasets with more than 30K data points?",
        "answer": "The TabNet model's semi-supervised learning performance for 50 labeled data points isn't specifically provided in the details, but TabTransformer-RTD achieves a test accuracy of 66.6% in AUC for datasets with more than 30K data points, indicating significant superiority especially with limited labeled samples available.",
        "reference": "TabNet: Attentive Interpretable Tabular Learning; TabTransformer: Tabular Data Modeling Using Contextual Embeddings"
    },
    {
        "paper": [
            "arXiv-1908.07442v5.tex",
            "arXiv-2012.06678v1.tex",
            "arXiv-2304.10946v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does TabNet perform in terms of mean squared error (MSE) on the Sarcos dataset compared to the CancerGPT model's performance in terms of data size requirements for rare tissues?",
        "answer": "TabNet achieves a performance with a mean squared error (MSE) of 0.14 when given 1.75M model parameters on the Sarcos dataset, showcasing strong regression capabilities. In contrast, CancerGPT focuses on few-shot learning without the need for large data sizes. Specifically, it aims to achieve high performance with limited samples, a task not directly comparable to MSE as it's more about classification capability with unknown large parameter counts in the study.",
        "reference": "TabNet: Attentive Interpretable Tabular Learning; [CancerGPT]{CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models"
    },
    {
        "paper": [
            "arXiv-1908.07442v5.tex",
            "arXiv-2012.06678v1.tex",
            "arXiv-2304.10946v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "For dealing with noisy data, how do the robustness strategies between the TabNet model and the TabTransformer model differ numerically?",
        "answer": "TabNet focuses on feature selection which potentially stabilizes performance by restricting learning to the most relevant features, quantified by different feature importance metrics; whereas TabTransformer demonstrated better robustness against noisy data by showing a slower degradation in performance, as it used contextual embeddings and was shown to outperform MLP by maintaining greater accuracy under increasing noise levels, up to 80% noise where the degradation compared to baseline was less severe.",
        "reference": "TabNet: Attentive Interpretable Tabular Learning; TabTransformer: Tabular Data Modeling Using Contextual Embeddings"
    }
]