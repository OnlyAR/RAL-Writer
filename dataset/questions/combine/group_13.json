[
    {
        "paper": [
            "arXiv-2402.08178v1.tex",
            "arXiv-2403.18760v2.tex",
            "arXiv-2412.13178v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How many high-level action types does the 'LoTa-Bench: Benchmarking Language-orien-ted Task Planners for Embodied Agents' benchmark support compared to the 'SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents' benchmark?",
        "answer": "The 'LoTa-Bench: Benchmarking Language-orien-ted Task Planners for Embodied Agents' benchmark supports 8 high-level action types, while the 'SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents' benchmark supports 17 high-level action types.",
        "reference": "LoTa-Bench: Benchmarking Language-orien-ted Task Planners for Embodied Agents; SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents"
    },
    {
        "paper": [
            "arXiv-2402.08178v1.tex",
            "arXiv-2403.18760v2.tex",
            "arXiv-2412.13178v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the dataset size of ALFRED dataset used in LoTa-Bench compare to the number of tasks in the SafeAgentBench dataset?",
        "answer": "The ALFRED dataset used in LoTa-Bench has a total of 4,703 tasks, while the SafeAgentBench dataset has a total of 750 tasks.",
        "reference": "LoTa-Bench: Benchmarking Language-orien-ted Task Planners for Embodied Agents; SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents"
    },
    {
        "paper": [
            "arXiv-2402.08178v1.tex",
            "arXiv-2403.18760v2.tex",
            "arXiv-2412.13178v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "In terms of task success rate, how does GPT-4 perform in SafeAgentBench compared to GPT-3 in the LoTa-Bench when executing detailed tasks?",
        "answer": "In the SafeAgentBench, GPT-4 empowered embodied LLM agents exhibit a success rate of up to 69% in detailed tasks. In contrast, the GPT-3 in LoTa-Bench exhibits a success rate of 21.36% in the ALFRED dataset.",
        "reference": "LoTa-Bench: Benchmarking Language-orien-ted Task Planners for Embodied Agents; SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents"
    },
    {
        "paper": [
            "arXiv-2402.08178v1.tex",
            "arXiv-2403.18760v2.tex",
            "arXiv-2412.13178v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the success rate improvement of MLDT over ReAct on the NovelTasks dataset when using the Llama (13B) model for task planning?",
        "answer": "MLDT achieves a success rate of 94.25% on the NovelTasks dataset with the Llama (13B) model, while ReAct has a success rate of 71.00%. This results in an improvement of 23.25%.",
        "reference": "MLDT: Multi-Level Decomposition for Complex Long-Horizon Robotic Task Planning with Open-Source Large Language Model; ReAct: Synergizing Reasoning and Acting in Language Models for Interactive Scriptive Task Planning."
    },
    {
        "paper": [
            "arXiv-2402.08178v1.tex",
            "arXiv-2403.18760v2.tex",
            "arXiv-2412.13178v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the number of tasks in the LongTasks dataset in MLDT compare to the task number in the ALFRED dataset used in LoTa-Bench?",
        "answer": "The LongTasks dataset used in MLDT comprises 1,154 samples, whereas the ALFRED dataset used in LoTa-Bench has 4,703 tasks.",
        "reference": "MLDT: Multi-Level Decomposition for Complex Long-Horizon Robotic Task Planning with Open-Source Large Language Model; LoTa-Bench: Benchmarking Language-orien-ted Task Planners for Embodied Agents."
    },
    {
        "paper": [
            "arXiv-2402.08178v1.tex",
            "arXiv-2403.18760v2.tex",
            "arXiv-2412.13178v2.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "For Bloom (7B), what is the difference in task success rate between the MLDT method and the Embodied planning method across all datasets?",
        "answer": "For Bloom (7B), the MLDT method achieves a success rate of 90.75%, whereas the Embodied planning method achieves a success rate of 67.50%. The difference in task success rate is 23.25%.",
        "reference": "MLDT: Multi-Level Decomposition for Complex Long-Horizon Robotic Task Planning with Open-Source Large Language Model; LoTa-Bench: Benchmarking Language-orien-ted Task Planners for Embodied Agents."
    }
]