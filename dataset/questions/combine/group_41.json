[
    {
        "paper": [
            "arXiv-2202.04200v1.tex",
            "arXiv-2301.11093v2.tex",
            "arXiv-2310.05737v3.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the performance in FID (Fréchet Inception Distance) on ImageNet 512x512 compare between \\\\",
        "answer": "'simple diffusion' achieves an FID of 3.54 without guidance on ImageNet 512x512, while 'Model quality (FID) comparison between \\\\n\\\\        ",
        "reference": "'simple diffusion: End-to-end diffusion for high resolution images' and 'Language Model Beats Diffusion\\\\---Tokenizer is Key to Visual Generation' in terms of FID (Fréchet Inception Distance) on ImageNet 512x512?\\\\n'Masked Generative Image Transformer' and 'simple diffusion: End-to-end diffusion for high resolution images."
    },
    {
        "paper": [
            "arXiv-2202.04200v1.tex",
            "arXiv-2301.11093v2.tex",
            "arXiv-2310.05737v3.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "In terms of model size for video generation, how do \\\\n\\\\\\\\n'Language Model Beats Diffusion\\\\\\\\---Tokenizer is Key to Visual Generation' and 'Language Model Beats Diffusion: Tokenizer is Key to Visual Generation' and 'simple diffusion: End-to-end diffusion for high resolution images' compare?\\\\n        ",
        "answer": "'simple diffusion' uses a model size of 2 billion parameters for video generation, while 'Model architecture comparison for video generation between 'uses 307 million parameters.\\\\\\\\n'Model quality comparison on carbonic acid using 'Language Model Beats Diffusion\\\\---Tokenizer is Key to Visual Generation.'{\\\"type\\\":\\\"Highlight\\\"}",
        "reference": " 'Masked Generative Image Transformer' and 'Language Model Beats Diffusion\\\\---Tokenizer is Key to Visual Generation' and 'simple diffusion: End-to-end diffusion for high resolution images."
    },
    {
        "paper": [
            "arXiv-2202.04200v1.tex",
            "arXiv-2301.11093v2.tex",
            "arXiv-2310.05737v3.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the difference in sampling steps required for generating an image on ImageNet 512x512 between \\\\n\\\\\\\\n'Language Model Beats Diffusion\\\\\\\\---Tokenizer is Key to Visual Generation' and 'simple diffusion: End-to-end diffusion for high resolution images' and 'simple diffusion: End-to-end diffusion for high resolution images' \\\\n    \\\\n\\\\\\\\n'Language Model Beats Diffusion\\\\\\\\---Tokenizer is Key to Visual Generation' and 'simple diffusion: End-to-end diffusion for high resolution images'?\\\\n    ",
        "answer": "'simple diffusion' requires 512 sampling steps for generating an image on ImageNet 512x512, whereas 'Model generation steps for Language Model Beats Diffusion: Tokenizer is Key to Visual Generation.' {",
        "reference": "'Language Model Beats Diffusion`. model size comparison for video generation.\\\\n,\\\"type\\\":\\\"Highlight\\\"}. 553"
    },
    {
        "paper": [
            "arXiv-2202.04200v1.tex",
            "arXiv-2301.11093v2.tex",
            "arXiv-2310.05737v3.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the performance in generative tasks, specifically in FID on Video Diffusion and classification score (ISTO) between ','compare between \\\\nCHAINED.png', \\\"GOAT_2.JPG\\\"],'),{\\\"sentences\\\":true,\\\"paragraphs\\\":false,\\\"delete\\\":false}'highlight'.|{\\\"question\\\":\\\" results images ({})\\\"}]}}']}",
        "answer": "'Language Model Beats Diffusion\\\\---Tokenizer is Key to Visual Generation' achieves a significantly better FID in video generation on K600 with an FID of 4.3 compared to the 'simple diffusion' baseline of 10.8. \\\\n5.2 Model quality (FID) performance between 'simple diffusion: End-to-end diffusion for high resolution images' and 'simple diffusion: End-to-end diffusion for high resolution images.'{\\\"type\\\":\\\"Highlight\\\"}",
        "reference": "'Language Model Beats Diffusion---Tokenizer is Key to Visual Generation' and 'simple diffusion: End-to-end diffusion for high resolution images."
    },
    {
        "paper": [
            "arXiv-2202.04200v1.tex",
            "arXiv-2301.11093v2.tex",
            "arXiv-2310.05737v3.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the Inception Score performance comparison on the ImageNet 512x512 dataset between 'Masked Generative Image Transformer' and 'simple diffusion: End-to-end diffusion for high resolution images'?",
        "answer": "'Masked Generative Image Transformer' achieved an Inception Score of 156.0, while 'simple diffusion: End-to-end diffusion for high resolution images' achieved an Inception Score of 205.3 on ImageNet 512x512.",
        "reference": "simple diffusion: End-to-end diffusion for high resolution images, Masked Generative Image Transformer"
    },
    {
        "paper": [
            "arXiv-2202.04200v1.tex",
            "arXiv-2301.11093v2.tex",
            "arXiv-2310.05737v3.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What are the differences in the number of model parameters used for image generation on ImageNet 512x512 in 'Masked Generative Image Transformer' and 'simple diffusion: End-to-end diffusion for high resolution images'?",
        "answer": "'Masked Generative Image Transformer' uses 227 million parameters, while 'simple diffusion: End-to-end diffusion for high resolution images' uses 2 billion parameters for generating images on ImageNet 512x512.",
        "reference": "simple diffusion: End-to-end diffusion for high resolution images, Masked Generative Image Transformer"
    }
]