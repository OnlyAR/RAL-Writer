[
    {
        "paper": [
            "arXiv-2010.00526v1.tex",
            "arXiv-2110.05750v1.tex",
            "arXiv-2111.12535v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How many documents are included in the SportsSum2.0 dataset compared to the LiveQA dataset?",
        "answer": "The SportsSum2.0 dataset contains 5,402 documents after manual cleaning, whereas the LiveQA dataset contains 1,670 documents, making SportsSum2.0 significantly larger in terms of the number of documents.",
        "reference": "LiveQA: A Question Answering Dataset over Sports Live; SportsSum2.0: Generating High-Quality Sports News from Live Text Commentary."
    },
    {
        "paper": [
            "arXiv-2010.00526v1.tex",
            "arXiv-2110.05750v1.tex",
            "arXiv-2111.12535v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the average number of questions per document in the LiveQA dataset compared to the average length of news articles in SportsSum2.0?",
        "answer": "In the LiveQA dataset, there is an average of 70.09 questions per document. In comparison, SportsSum2.0 has an average news article length of 771.93 characters, or 406.81 words per document.",
        "reference": "LiveQA: A Question Answering Dataset over Sports Live; SportsSum2.0: Generating High-Quality Sports News from Live Text Commentary."
    },
    {
        "paper": [
            "arXiv-2010.00526v1.tex",
            "arXiv-2110.05750v1.tex",
            "arXiv-2111.12535v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What differences are there in the types of information provided in the SportsSum2.0 dataset and the K-SportsSum dataset?",
        "answer": "While both datasets involve the summarization of sports content, SportsSum2.0 focuses on improving the quality of text commentary and news articles through manual cleaning, while K-SportsSum provides additional knowledge resources, including the knowledge of 523 sports teams and 14,724 sports players, to bridge the knowledge gap between commentaries and news.",
        "reference": "SportsSum2.0: Generating High-Quality Sports News from Live Text Commentary; Knowledge Enhanced Sports Game Summarization."
    },
    {
        "paper": [
            "arXiv-2010.00526v1.tex",
            "arXiv-2110.05750v1.tex",
            "arXiv-2111.12535v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the length distribution of commentary documents differ between the SportsSum2.0 and K-SportsSum datasets?",
        "answer": "In SportsSum2.0, the average length of commentary documents is 3,459.97 characters, whereas in K-SportsSum, the average is significantly shorter at 2,251.62 tokens. This indicates a compression or selection of relevant content in K-SportsSum compared to a larger capture of commentary in SportsSum2.0.",
        "reference": "SportsSum2.0: Generating High-Quality Sports News from Live Text Commentary; Knowledge Enhanced Sports Game Summarization."
    },
    {
        "paper": [
            "arXiv-2010.00526v1.tex",
            "arXiv-2110.05750v1.tex",
            "arXiv-2111.12535v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the main difference in the number of entities contained in the knowledge corpus between the LiveQA and K-SportsSum datasets?",
        "answer": "The LiveQA dataset does not focus on providing an external knowledge corpus, while the K-SportsSum dataset includes a knowledge corpus with details about 523 sports teams and 14,724 players to enhance its summarization tasks.",
        "reference": "LiveQA: A Question Answering Dataset over Sports Live; Knowledge Enhanced Sports Game Summarization."
    },
    {
        "paper": [
            "arXiv-2010.00526v1.tex",
            "arXiv-2110.05750v1.tex",
            "arXiv-2111.12535v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "Compare the availability of multilingual or language-specific tools or models employed between SportsSum2.0 and K-SportsSum.",
        "answer": "SportsSum2.0 utilizes models like BART and mBART for generating sports news which are multilingual tools. K-SportsSum employs mT5, a multilingual T5 model, for rewriting commentary sentences to news sentences, considering it as a viable tool for multilingual processing.",
        "reference": "SportsSum2.0: Generating High-Quality Sports News from Live Text Commentary; Knowledge Enhanced Sports Game Summarization."
    }
]