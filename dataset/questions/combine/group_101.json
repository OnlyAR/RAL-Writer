[
    {
        "paper": [
            "arXiv-1903.10318v2.tex",
            "arXiv-1909.08089v1.tex",
            "arXiv-2004.08795v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "When comparing the datasets used in \\\\\\\"Extractive Summarization of Long Documents by Combining Global and Local Context\\\\\\\" and \\\\\\\"Extractive Summarization as Text Matching,\\\\\\\" which dataset has the longest average document length, and what is this length?",
        "answer": "The arXiv dataset used in \\\\\\\"Extractive Summarization of Long Documents by Combining Global and Local Context\\\\\\\" has the longest average document length, with 4938 words per document.",
        "reference": "Extractive Summarization of Long Documents by Combining Global and Local Context; Extractive Summarization as Text Matching"
    },
    {
        "paper": [
            "arXiv-1903.10318v2.tex",
            "arXiv-1909.08089v1.tex",
            "arXiv-2004.08795v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "Among the papers, which one reports results from the most number of datasets, and how many datasets are used in that paper?",
        "answer": "The paper \\\\\\\"Extractive Summarization as Text Matching\\\\\\\" reports results from the most number of datasets, using a total of six datasets: Reddit, XSum, CNN/DM, WikiHow, PubMed, and Multi-News.",
        "reference": "Fine-tune BERT for Extractive Summarization; Extractive Summarization of Long Documents by Combining Global and Local Context; Extractive Summarization as Text Matching"
    },
    {
        "paper": [
            "arXiv-1903.10318v2.tex",
            "arXiv-1909.08089v1.tex",
            "arXiv-2004.08795v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the ROUGE-1 score of the state-of-the-art extractive summarization model in 'Fine-tune BERT for Extractive Summarization' on the CNN/DailyMail dataset compare to the best reported ROUGE-1 score in 'Extractive Summarization as Text Matching' on the same dataset?",
        "answer": "In 'Fine-tune BERT for Extractive Summarization,' the state-of-the-art extractive summarization model, BERTSUM with Transformer, achieves a ROUGE-1 score of 43.25 on the CNN/DailyMail dataset. In 'Extractive Summarization as Text Matching,' the best reported ROUGE-1 score on the CNN/DailyMail dataset is 44.41 using the MatchSum (RoBERTa-base) model.",
        "reference": "Fine-tune BERT for Extractive Summarization; Extractive Summarization as Text Matching"
    },
    {
        "paper": [
            "arXiv-1903.10318v2.tex",
            "arXiv-1909.08089v1.tex",
            "arXiv-2004.08795v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What is the average summary length in terms of words for the datasets arXiv and CNN/DailyMail, and how do these lengths compare across the datasets?",
        "answer": "The average summary length for the arXiv dataset in 'Extractive Summarization of Long Documents by Combining Global and Local Context' is 220 words. For the CNN/DailyMail dataset in both 'Fine-tune BERT for Extractive Summarization' and 'Extractive Summarization as Text Matching,' the average summary length is 58.2 words. The arXiv dataset has an average summary length significantly longer than the CNN/DailyMail dataset.",
        "reference": "Fine-tune BERT for Extractive Summarization; Extractive Summarization of Long Documents by Combining Global and Local Context; Extractive Summarization as Text Matching"
    },
    {
        "paper": [
            "arXiv-1903.10318v2.tex",
            "arXiv-1909.08089v1.tex",
            "arXiv-2004.08795v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How does the ROUGE-L score of the oracle summaries compare across the PubMed and CNN/DailyMail datasets as reported in the respective papers?",
        "answer": "For the PubMed dataset, 'Extractive Summarization of Long Documents by Combining Global and Local Context' reports an oracle ROUGE-L score of 40.19. Meanwhile, for the CNN/DailyMail dataset, 'Fine-tune BERT for Extractive Summarization' reports an oracle ROUGE-L score of 48.87. The oracle summaries have a higher ROUGE-L score on the CNN/DailyMail dataset compared to the PubMed dataset.",
        "reference": "Fine-tune BERT for Extractive Summarization; Extractive Summarization of Long Documents by Combining Global and Local Context; Extractive Summarization as Text Matching"
    },
    {
        "paper": [
            "arXiv-1903.10318v2.tex",
            "arXiv-1909.08089v1.tex",
            "arXiv-2004.08795v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "According to \\\"Extractive Summarization of Long Documents by Combining Global and Local Context,\\\" what is the average document length in the PubMed dataset, and how does this length compare numerically with the document length of the NYT dataset mentioned in \\\"Fine-tune BERT for Extractive Summarization\\\"?",
        "answer": "In \\\"Extractive Summarization of Long Documents by Combining Global and Local Context,\\\" the average document length in the PubMed dataset is 3016 words. According to \\\"Fine-tune BERT for Extractive Summarization,\\\" the average document length for the NYT dataset is 530 words. Thus, the average document length in the PubMed dataset is numerically significantly longer than in the NYT dataset.",
        "reference": "Fine-tune BERT for Extractive Summarization; Extractive Summarization of Long Documents by Combining Global and Local Context"
    }
]