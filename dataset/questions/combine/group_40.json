[
    {
        "paper": [
            "arXiv-2404.14397v2.tex",
            "arXiv-2405.09373v3.tex",
            "arXiv-2412.15035v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How many languages are included in the benchmarks introduced by the papers 'RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?' and 'PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models', and how do they compare?",
        "answer": "The paper 'RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?' includes a dataset that supports 28 languages. In comparison, the 'PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models' introduces a dataset covering 17 languages.",
        "reference": "RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?, PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models"
    },
    {
        "paper": [
            "arXiv-2404.14397v2.tex",
            "arXiv-2405.09373v3.tex",
            "arXiv-2412.15035v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "Compare the model evaluation sizes in the 'RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?' and 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps' papers with respect to the number of models benchmarked.",
        "answer": "The paper 'RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?' evaluates 10 S/LLMs. In comparison, the 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps' paper evaluates 10 state-of-the-art LLMs as well.",
        "reference": "RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?, LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps"
    },
    {
        "paper": [
            "arXiv-2404.14397v2.tex",
            "arXiv-2405.09373v3.tex",
            "arXiv-2412.15035v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "What are the sizes of the datasets introduced in 'PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models' and 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps', and how do they compare?",
        "answer": "The 'PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models' introduces a dataset containing 425,000 prompts. In contrast, 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps' introduces a dataset of 75,000 prompts.",
        "reference": "PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models, LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps"
    },
    {
        "paper": [
            "arXiv-2404.14397v2.tex",
            "arXiv-2405.09373v3.tex",
            "arXiv-2412.15035v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "Between 'RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?' and 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps', how do they differ in terms of the languages analyzed for safety or toxicity evaluation in models?",
        "answer": "The 'RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?' analyzes 28 languages. The 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps' paper evaluates model safety across 5 languages: English, French, German, Italian, and Spanish, focusing more on major European languages.",
        "reference": "RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?, LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps"
    },
    {
        "paper": [
            "arXiv-2404.14397v2.tex",
            "arXiv-2405.09373v3.tex",
            "arXiv-2412.15035v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "In terms of benchmark datasets, how do 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps' and 'PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models' compare regarding naturally occurring prompts?",
        "answer": "'PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models' includes 425,000 naturally occurring prompts in its benchmark. In contrast, 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps' consists of 75,000 prompts, which are also derived from naturally occurring sources but are not specified to be directly equivalent to the use of web corpora as in the PolygloToxicityPrompts benchmark.",
        "reference": "LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps, PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models"
    },
    {
        "paper": [
            "arXiv-2404.14397v2.tex",
            "arXiv-2405.09373v3.tex",
            "arXiv-2412.15035v1.tex"
        ],
        "topic": "data",
        "subtopic": "data-related content",
        "question": "How do the methods employed for safety and toxicity detection across languages differ between 'RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?' and 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps'?",
        "answer": "'RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?' employs ten different S/LLMs for detecting toxicity, additionally using Azure Content Safety and the FLORES Toxicity-200 block list for comparative purposes. 'LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps' uses the automated multilingual model Llama-Guard-3 and others for safety detection across several prompts, focusing not only on toxicity but broader categories of safety concerns.",
        "reference": "RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?, LLMs Lost in Translation: \\\\texttt{M-ALERT} uncovers Cross-Linguistic Safety Gaps"
    }
]