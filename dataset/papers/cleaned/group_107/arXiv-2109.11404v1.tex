\title{Supplementary Material:\\
Hierarchical Memory Matching Network for Video Object Segmentation}

\begin{document}

\title{Supplementary Material:\\
Hierarchical Memory Matching Network for Video Object Segmentation}

\author{Hongje Seong\textsuperscript{1} \quad\quad Seoung Wug Oh\textsuperscript{2} \quad\quad Joon-Young Lee\textsuperscript{2} \\ Seongwon Lee\textsuperscript{1} \quad\quad Suhyeon Lee\textsuperscript{1} \quad\quad Euntai Kim\textsuperscript{1,}\thanks{Corresponding author.}\vspace*{0.2cm}\\
{\textsuperscript{1}Yonsei University \quad\quad\quad \textsuperscript{2}Adobe Research}}

\maketitle
\ificcvfinal\thispagestyle{empty}\fi

\vspace{-5mm}
\section{Network Structure Details}
\label{sec:1.Network_Structure_Details}
\paragraph{Top-$k$ guided memory matching module at \texttt{res2} stage.}~Fig.~\ref{fig:topk_memory_read_detail_supp} shows a detailed implementation of the top-$k$ guided memory matching module at the \texttt{res2} stage.
Compare to the top-$k$ guided memory matching module at the \texttt{res3} stage, we reduce the number of $k$ to $k/4$.
We also take the reduced channel dimensions of \textbf{key} and \textbf{value}, except for the query \textbf{value}.

\paragraph{Detailed implementation of decoder.}~We follow the decoder architecture of STM \cite{Oh_2019_ICCV}, and a detailed implementation is provided in Fig.~\ref{fig:decoder}.
Note that, in the refinement modules of STM \cite{Oh_2019_ICCV}, the skip-connected features ($\textbf{Z}_3$, $\textbf{Z}_2$) are encoded via convolutional layers before fed to residual block.
We replace the convolutional layers with \textbf{value} embedding layers in top-$k$ guided memory matching modules.

\begin{figure}[t]
\centering
\includegraphics[width=1.\linewidth]{figures/topk_memory_read_detail_supp.pdf}
\caption{
A detailed implementation of the top-$k$ guided memory matching module at the \texttt{res2} stage.
Memory and query dimensions are indicated using \textcolor{blue}{blue} and \textcolor{red}{red}.
}
\label{fig:topk_memory_read_detail_supp}
\end{figure}

\begin{figure*}[t]
\centering
\includegraphics[width=0.8\linewidth]{figures/decoder.pdf}
\caption{
A detailed implementation of decoder.
We notated the output scale and channel dimension next to each block in the decoder.
}
\label{fig:decoder}
\end{figure*}

\section{More Quantitative Results}
\label{sec:2.More_Quantitative_Results}
Tables~\ref{tab:davis2016_val_supp}, \ref{tab:davis2017_val_supp}, and \ref{tab:davis2017_test_dev_supp} provide full comparisons on DAVIS 2016 val, 2017 val, and 2017 test-dev sets, respectively.
As shown in the tables, recent offline-learning methods such as KMN~\cite{seong2020kernelized}, CFBI~\cite{yang2020collaborative}, LWL~\cite{bhat2020learning}, and STM~\cite{Oh_2019_ICCV} surpassed online-learning methods such as PReMVOS~\cite{luiten2018premvos}, RaNet~\cite{Wang_2019_ICCV}, e-OSVOS~\cite{meinhardt2020make}, and DyeNet~\cite{li2018video} by additionally using YouTube-VOS~\cite{xu2018youtube} training data.
However, we surpass all online-learning methods, which need additional run-time for fine-tuning during inference, even if we do not use additional YouTube-VOS training data.
Therefore, the superiority of our HMMN has not relied on additional YouTube-VOS training data.

\begin{table}[t]
\begin{center}
\footnotesize
\begin{tabular}{lccccc}
\toprule
Method                                                  & OL         & $\mathcal{J\&F}$      & $\mathcal{J}$         & $\mathcal{F}$         & Time     \\
\midrule
OSVOS \cite{caelles2017one}                             & \checkmark & 80.2                  & 79.8                  & 80.6                  & 9$s$     \\
MaskRNN \cite{hu2017maskrnn}                            & \checkmark & 80.8                  & 80.7                  & 80.9                  & -        \\
VidMatch   \cite{hu2018videomatch}                      &            & -                     & 81.0                  & -                     & 0.32$s$  \\
FAVOS \cite{cheng2018fast}                              &            & 81.0                  & 82.4                  & 79.5                  & 1.8$s$   \\
LSE \cite{ci2018video}                                  & \checkmark & 81.6                  & 82.9                  & 80.3                  & -        \\
FEELVOS   \cite{voigtlaender2019feelvos}                &            & 81.7                  & 80.3                  & 83.1                  & 0.45$s$  \\
FEELVOS \textbf{(+YV)}   \cite{voigtlaender2019feelvos} &            & 81.7                  & 81.1                  & 82.2                  & 0.45$s$  \\
FRTM   \cite{robinson2020learning}                      & \checkmark           & 81.7                  & -                     & -                     & 0.05$s$  \\
RGMP \cite{wug2018fast}                                 &            & 81.8                  & 81.5                  & 82.0                  & 0.13$s$  \\
A-GAME \textbf{(+YV)}   \cite{johnander2019generative}  &            & -                     & 82.0                  & -                     & 0.07$s$  \\
SAT \cite{chen2020state}                                &            & 83.1                  & 82.6                  & 83.6                  & 0.03$s$  \\
FRTM \textbf{(+YV)}   \cite{robinson2020learning}       & \checkmark           & 83.5                  & -                     & -                     & 0.05$s$  \\
DTN \cite{Zhang_2019_ICCV}                              &            & 83.6                  & 83.7                  & 83.5                  & 0.07$s$  \\
CINN \cite{bao2018cnn}                                  & \checkmark & 84.2                  & 83.4                  & 85.0                  & $>$30$s$ \\
DyeNet \cite{li2018video}                               &            & -                     & 84.7                  & -                     & 0.42$s$  \\
RaNet \cite{Wang_2019_ICCV}                             &            & 85.5                  & 85.5                  & 85.4                  & 0.03$s$  \\
OnAVOS   \cite{voigtlaender2017online}                  & \checkmark & 85.5                  & 86.1                  & 84.9                  & 13$s$    \\
STG-Net   \cite{liu2020spatiotemporal}                  &            & 85.7                  & 85.4                  & 86.0                  & 0.16$s$  \\
OSVOS$^S$   \cite{maninis2018video}                     & \checkmark & 86.0                  & 85.6                  & 86.4                  & 4.5$s$   \\
DIPNet \cite{hu2020dipnet}                              & \checkmark & 86.1                  & 85.8                  & 86.4                  & 1.09$s$  \\
CFBI   \cite{yang2020collaborative}                     &            & 86.1                  & 85.3                  & 86.9                  & 0.18$s$  \\
STM \cite{Oh_2019_ICCV}                                 &            & 86.5                  & 84.8                  & 88.1                  & 0.16$s$  \\
PReMVOS   \cite{luiten2018premvos}                      & \checkmark & 86.8                  & 84.9                  & 88.6                  & 32.8$s$  \\
e-OSVOS   \cite{meinhardt2020make}                      & \checkmark & 86.8                  & 86.6                  & 87.0                  & 3.4$s$   \\
DyeNet \cite{li2018video}                               & \checkmark & -                     & 86.2                  & -                     & 2.32$s$  \\
RaNet \cite{Wang_2019_ICCV}                             & \checkmark & 87.1                  & 86.6                  & 87.6                  & 4$s$     \\
KMN \cite{seong2020kernelized}                          &            & 87.6                  & 87.1                  & 88.1                  & 0.12$s$  \\
STM \textbf{(+YV)}   \cite{Oh_2019_ICCV}                &            & 89.3                  & 88.7                  & 89.9                  & 0.16$s$  \\
CFBI \textbf{(+YV)}   \cite{yang2020collaborative}      &            & 89.4                  & 88.3                  & 90.5                  & 0.18$s$  \\
KMN \textbf{(+YV)}   \cite{seong2020kernelized}         &            & 90.5                  & 89.5                  & 91.5                  & 0.12$s$  \\
\midrule
HMMN                                                    &            & 89.4 & 88.2 & 90.6  & 0.10$s$  \\
HMMN \textbf{(+YV)}                                     &            & \textbf{90.8}         & \textbf{89.6}         & \textbf{92.0}         & 0.10$s$ \\
\bottomrule
\end{tabular}
\end{center}
\caption{Full comparison on DAVIS 2016 validation set.
(\textbf{+YV}) indicates YouTube-VOS is additionally used for training, and OL denotes the use of online-learning strategies during test-time. Time measurements reported in this table are directly from the corresponding papers. 
}
\label{tab:davis2016_val_supp}
\end{table}

\begin{table}[t]
\begin{center}
\footnotesize
\begin{tabular}{lcccc}
\toprule
Method                                                  & OL         & $\mathcal{J\&F}$ & $\mathcal{J}$ & $\mathcal{F}$ \\
\midrule
OSVOS \cite{caelles2017one}                             & \checkmark & 60.3             & 56.6          & 63.9          \\
VidMatch   \cite{hu2018videomatch}                      &            & 62.4             & 56.5          & 68.2          \\
MaskRNN \cite{hu2017maskrnn}                            & \checkmark & -                & 60.5          & -             \\
RaNet \cite{Wang_2019_ICCV}                             &            & 65.7             & 63.2          & 68.2          \\
AGSS-VOS \cite{Lin_2019_ICCV}                           &            & 66.6             & 63.4          & 69.8          \\
RGMP \cite{wug2018fast}                                 &            & 66.7             & 64.8          & 68.6          \\
DTN \cite{Zhang_2019_ICCV}                              &            & 67.4             & 64.2          & 70.6          \\
AGSS-VOS \textbf{(+YV)}   \cite{Lin_2019_ICCV}          &            & 67.4             & 64.9          & 69.9          \\
OnAVOS   \cite{voigtlaender2017online}                  & \checkmark & 67.9             & 64.5          & 71.2          \\
OSVOS$^S$   \cite{maninis2018video}                     & \checkmark & 68.0             & 64.7          & 71.3          \\
DIPNet \cite{hu2020dipnet}                              & \checkmark & 68.5             & 65.3          & 71.6          \\
FRTM   \cite{robinson2020learning}                      & \checkmark           & 68.8             & -             & -             \\
FEELVOS   \cite{voigtlaender2019feelvos}                &            & 69.1             & 65.9          & 72.3          \\
DyeNet \cite{li2018video}                               &            & 69.1             & 67.3          & 71.0          \\
A-GAME \textbf{(+YV)}   \cite{johnander2019generative}  &            & 70.0             & 67.2          & 72.7          \\
CINN \cite{bao2018cnn}                                  & \checkmark & 70.7             & 67.2          & 74.2          \\
DMM-Net \cite{Zeng_2019_ICCV}                           &            & 70.7             & 68.1          & 73.3          \\
GC \cite{li2020fast}                                    &            & 71.4             & 69.3          & 73.5          \\
STM \cite{Oh_2019_ICCV}                                 &            & 71.6             & 69.2          & 74.0          \\
FEELVOS \textbf{(+YV)}   \cite{voigtlaender2019feelvos} &            & 72.0             & 69.1          & 74.0          \\
SAT \cite{chen2020state}                                &            & 72.3             & 68.6          & 76.0          \\
TVOS   \cite{zhang2020transductive}                     &            & 72.3             & 69.9          & 74.7          \\
LWL \cite{bhat2020learning}                             &            & 74.3             & 72.2          & 76.3          \\
AFB+URR \cite{liang2020video}                           &            & 74.6             & 73.0          & 76.1          \\
STG-Net   \cite{liu2020spatiotemporal}                  &            & 74.7             & 71.5          & 77.9          \\
CFBI   \cite{yang2020collaborative}                     &            & 74.9             & 72.1          & 77.7          \\
DTTM-TAN \cite{huang2020fast}                           &            & 75.9             & 72.3          & 79.4          \\
KMN \cite{seong2020kernelized}                          &            & 76.0             & 74.2          & 77.8          \\
FRTM \textbf{(+YV)}   \cite{robinson2020learning}       & \checkmark           & 76.7             & -             & -             \\
e-OSVOS   \cite{meinhardt2020make}                      & \checkmark & 77.2             & 74.4          & 80.0          \\
PReMVOS   \cite{luiten2018premvos}                      & \checkmark & 77.8             & 73.9          & 81.7          \\
LWL \textbf{(+YV)}   \cite{bhat2020learning}            &            & 81.6             & 79.1          & 84.1          \\
STM \textbf{(+YV)}   \cite{Oh_2019_ICCV}                &            & 81.8             & 79.2          & 84.3          \\
CFBI \textbf{(+YV)}   \cite{yang2020collaborative}      &            & 81.9             & 79.1          & 84.6          \\
EGMN \textbf{(+YV)}   \cite{lu2020video}                &            & 82.8             & 80.2          & 85.2          \\
KMN \textbf{(+YV)}   \cite{seong2020kernelized}         &            & 82.8             & 80.0          & 85.6          \\
\midrule
HMMN                                                    &            & 80.4             & 77.7          & 83.1          \\
HMMN \textbf{(+YV)}                                     &            & \textbf{84.7}    & \textbf{81.9} & \textbf{87.5}\\
\bottomrule
\end{tabular}
\end{center}
\caption{Full comparison on DAVIS 2017 validation set.
}
\label{tab:davis2017_val_supp}
\end{table}

\begin{table}[t]
\begin{center}
\footnotesize
\centering
\begin{tabular}{lcccc}
\toprule
Method                                                  & OL         & $\mathcal{J\&F}$ & $\mathcal{J}$ & $\mathcal{F}$ \\
\midrule
OSMN \cite{yang2018efficient}                           &            & 39.3             & 33.7          & 44.9          \\
FAVOS \cite{cheng2018fast}                              &            & 43.6             & 42.9          & 44.2          \\
OSVOS \cite{caelles2017one}                             & \checkmark & 50.9             & 47.0          & 54.8          \\
CapsuleVOS   \cite{Duarte_2019_ICCV}                    &            & 51.3             & 47.4          & 55.2          \\
OnAVOS   \cite{voigtlaender2017online}                  & \checkmark & 52.8             & 49.9          & 55.7          \\
RGMP \cite{wug2018fast}                                 &            & 52.9             & 51.3          & 54.4          \\
RaNet \cite{Wang_2019_ICCV}                             &            & 53.4             & 55.3          & 57.2          \\
OSVOS$^S$   \cite{maninis2018video}                     & \checkmark & 57.5             & 52.9          & 62.1          \\
FEELVOS \textbf{(+YV)}   \cite{voigtlaender2019feelvos} &            & 57.8             & 55.1          & 60.4          \\
TVOS   \cite{zhang2020transductive}                     &            & 63.1             & 58.8          & 67.4          \\
STG-Net   \cite{liu2020spatiotemporal}                  &            & 63.1             & 59.7          & 66.5          \\
e-OSVOS   \cite{meinhardt2020make}                      & \checkmark & 64.8             & 60.9          & 68.6          \\
DTTM-TAN \cite{huang2020fast}                           &            & 65.4             & 61.3          & 70.3          \\
Lucid \cite{khoreva2019lucid}                           & \checkmark & 66.7             & 63.4          & 69.9          \\
CINN \cite{bao2018cnn}                                  & \checkmark & 67.5             & 64.5          & 70.5          \\
DyeNet \cite{li2018video}                               & \checkmark & 68.2             & 65.8          & 70.5          \\
PReMVOS   \cite{luiten2018premvos}                      & \checkmark & 71.6             & 67.5          & 75.7          \\
STM \textbf{(+YV)}   \cite{Oh_2019_ICCV}                &            & 72.2             & 69.3          & 75.2          \\
CFBI \textbf{(+YV)}   \cite{yang2020collaborative}      &            & 74.8             & 71.1          & 78.5          \\
KMN \textbf{(+YV)}   \cite{seong2020kernelized}         &            & 77.2             & 74.1          & 80.3          \\
\midrule
HMMN \textbf{(+YV)}                                     &            & \textbf{78.6}    & \textbf{74.7} & \textbf{82.5}\\
\bottomrule
\end{tabular}
\end{center}
\caption{Full comparison on DAVIS 2017 test-dev set.
}
\label{tab:davis2017_test_dev_supp}
\end{table}

\section{More Qualitative Results}
\label{sec:3.More_Qualitative_Results}
We show more qualitative results on DAVIS~\cite{pont20172017} in Fig.~\ref{fig:qualitative_results_1} and results on YouTube-VOS~\cite{xu2018youtube} in Figs.~\ref{fig:qualitative_results_2} and~\ref{fig:qualitative_results_3}.
In the figures, we additionally show the results of STM\footnote{results are taken from \url{https://github.com/seoungwugoh/STM}.}~\cite{Oh_2019_ICCV}, KMN\footnote{results are extracted from our reproduced model.}~\cite{seong2020kernelized}, and CFBI\footnote{results are taken from \url{https://github.com/z-x-yang/CFBI}.}~\cite{yang2020collaborative}.
Sine some frames are omitted in the figures, we further provide a comparison video:  \url{https://youtu.be/zSofRzPImQY}.

\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth]{figures/qualitative_results_supp_1.pdf}
\caption{More qualitative results on DAVIS 2017 validation and test-dev sets.
We marked significant improvements from STM \cite{Oh_2019_ICCV}, KMN \cite{seong2020kernelized}, and CFBI \cite{yang2020collaborative} using red boxes.
\vspace{-1cm}
}
\label{fig:qualitative_results_1}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth]{figures/qualitative_results_supp_2.pdf}
\caption{More qualitative results on YouTube-VOS 2019 validation set.
}
\label{fig:qualitative_results_2}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth]{figures/qualitative_results_supp_3.pdf}
\caption{More qualitative results on YouTube-VOS 2019 validation set.
}
\label{fig:qualitative_results_3}
\end{figure*}

{\small
}

\end{document}