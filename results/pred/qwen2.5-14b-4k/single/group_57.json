{
    "instruction": "You are an experienced researcher, I will give you some scientific research papers in the same field. Please read them carefully and write a summary about them.\n\nHere are the papers:\n\n<paper 1>\n\\title{ESCORT: Ethereum Smart COntRacTs Vulnerability Detection using Deep Neural Network and Transfer Learning}\n\n\\begin{document}\n\n\\title{\\sys{}: Ethereum Smart COntRacTs Vulnerability Detection using Deep Neural Network and Transfer Learning}\n\n\\ifanonymous\n\\author{}\n\\else\n\\author{Oliver Lutz}\n\\affiliation{% (\n\t\\country{}\n\\institution{University of Würzburg}\n}\n\n\\author{Huili Chen}\n\\affiliation{%\n\t\\country{}\n\\institution{University of California, San-Diego}\n}\n\n\\author{Hossein Fereidooni}\n\\affiliation{%\n\t\\country{}\n\\institution{Technical University of Darmstadt}\n}\n\n\\author{Christoph Sendner}\n\\affiliation{%\n\t\\country{}\n\\institution{University of Würzburg}\n}\n\n\\author{Alexandra Dmitrienko}\n\\affiliation{%\n\t\\country{}\n\\institution{University of Würzburg}\n}\n\n\\author{Ahmad Reza Sadeghi}\n\\affiliation{%\n\\country{}\n\\institution{Technical University of Darmstadt}\n}\n\n\\author{Farinaz Koushanfar}\n\\affiliation{%\n\t\\country{}\n\\institution{University of California, San Diego}\n}\n\n\\thispagestyle{plain}\n\\pagestyle{plain}\n\n\\begin{abstract} \nEthereum smart contracts are automated decentralized applications on the blockchain that describe the terms of the agreement between buyers and sellers, reducing the need for trusted intermediaries and arbitration. However, the deployment of smart contracts introduces new attack vectors into the cryptocurrency systems. In particular, programming flaws in smart contracts can be and have already been exploited to gain enormous financial profits. It is thus an emerging yet crucial issue to detect vulnerabilities of different classes (e.g., reentrancy or multiple send bugs) in contracts in an effective and efficient manner.\nExisting machine learning-based vulnerability detection methods are limited and only inspect whether the smart contract is vulnerable, or train individual classifiers for each specific vulnerability, or demonstrate multi-class vulnerability detection without extensibility consideration.\nTo overcome the scalability and generalization limitations of existing works, we propose \\sys{}, the first Deep Neural Network (DNN)-based vulnerability \ndetection framework for Ethereum smart contracts that supports lightweight \\textit{transfer learning} on unseen security vulnerabilities, thus is \\textit{extensible} and \\textit{generalizable}. \n\\sys{} leverages a \\textit{multi-output} neural network architecture that consists of two parts: (i)~A common feature extractor that learns the semantics of the input smart contract; (ii)~Multiple branch structures where each branch learns a specific vulnerability type based on features obtained from the feature extractor. \nWe perform a comprehensive evaluation of \\sys{} on various smart contracts.\nExperimental results show that \\sys{} achieves an average F1 score of \\textcolor{red}{$95\\%$} on six vulnerability types and the detection time is $0.02$ seconds per contract. When extended to new vulnerability types, \\sys{} yields an average F1 score of \\textcolor{red}{$93\\%$}.\nTo the best of our knowledge, \\sys{} is the first framework that enables transfer learning on new vulnerability types with minimal modification of the DNN model architecture and re-training overhead. \n\n\\end{abstract}\n\n\\keywords{Blockchain, Ethereum Smart Contracts, Vulnerability Detection, Deep Neural Network, Transfer Learning}\n\n\\maketitle\n\n\\section{Introduction} \n\\label{ch:introduction}\nThe success of Bitcoin~\\cite{bitcoin} fueled the interest in the cryptocurrency platforms.\nAs a result, next generation blockchain-powered application platforms emerged, such as Ethereum~\\cite{ethereum-whitepaper} and Hyperledger~\\cite{Hyperledger}. Beyond financial transactions, these platforms provide smart contracts that are automated decentralized applications describing the terms of agreements and the transaction flow between the buyers and the sellers.\n\nGenerally, blockchains are append-only distributed and replicated databases, which maintain an ever-growing list of immutable and tamper-resistant data records (e.g., financial transactions and smart contracts). Immutability and tamper-resistance of blockchains stem from their append-only property and are paramount to the security of blockchain applications. In the context of digital currency and payments, they ensure that all the involved parties have access to a single history of payment transactions in a distributed setting and that such a history cannot be manipulated. In smart contract systems, immutability and tamper-resistance properties enforce \"code is law\" principle, meaning that conditions recorded in a smart contract are not to be modified since they have been written and published.\n\nHowever, these properties bear their own security risks and challenges: \nFirst, smart contracts are written in error-prone programming languages such as Solidity~\\cite{solidity}, and can contain exploitable programming errors/bugs that are often overlooked or detected only after deployment on the blockchain, and cannot be simply fixed.  \nSecond, Ethereum operates on open networks where everyone can join without trusted third parties while smart contracts are often in control of significant financial assets. Hence, smart contracts are attractive and easy attack targets for adversaries to gain financial profits~\\cite{SmartContractsBugs}. The consequences of bug exploitation may have global effects on the entire underlying blockchain platform, far beyond the boundaries of individual contracts.\nFor instance, vulnerabilities in a single smart contract, the DAO~\\cite{TheDAO}, affected the entire Ethereum network, when in June 2016 the attacker exploited a reentrancy bug and had withdrawn most of its funds worth about 60 million US dollars~\\cite{DAO_01,DAO_02}. In the aftermath, the value of Ether, Ethereum's cryptocurrency, dropped dramatically \\cite{EtherPriceDrop2016}, and the postulated \"code is law\" principle was undermined through the deployment of a hard fork -- a manual intervention orchestrated by a notable minority, the team of Ethereum core developers.\nThe Ethereum blockchain was thus split into two versions, Ethereum and Ethereum Classic, which are maintained in parallel since then. \nIn another case, a critical bug accidentally triggered in 2017 resulted in the freezing of more than \\$280M worth of Ether in the Parity multisig wallet~\\cite{Parity2017}. \n\nOnce it was understood that real-world attacks and even innocent mistakes can lead to fatal economic lose, the problem of detecting smart contract vulnerabilities became very appealing to the research community. \nA wide range of automated tools were developed to help find vulnerabilities in smart contracts using various techniques, such as symbolic execution~\\cite{rw_securify_paper,ethereum-background-03}, satisfiability modulo theories (SMT) solving~\\cite{alt2018smt}, data flow analysis~\\cite{feist2019slither}, runtime monitoring~\\cite{cook2017dappguard}, and fuzzing~\\cite{fu2019evmfuzzer}, to name a few examples.\nHowever, present methods provide a limited trade-off between detection effectiveness and efficiency. \nFor instance, symbolic execution-based vulnerability detection is slow since all program paths need to be examined~\\cite{rw_oyente_repo}, whereas data flow analysis has limited coverage~\\cite{feist2019slither}. Moreover, individual tools normally cover a limited set of vulnerabilities, hence to achieve sound testing, one would normally need to apply several tools. \n\nRecently, Machine Learning (ML) has attracted the attention of security researchers due to its capability to learn the hidden representation from the abundant data~\\cite{alpaydin2020introduction}. \nPrior works have shown the effectiveness of ML techniques for detecting vulnerabilities in software written in C and C++ languages~\\cite{russell2018automated,vytovtov21prediction}. \nThere are also first attempts to apply ML techniques for the detection of smart contact vulnerabilities~\\cite{rw_contractward,rw_lstm,huang2018hunting}. \nHowever, as we elaborate in details in~ Section~\\ref{sec:related}, the existing solutions suffer from either of the following shortcomings: (i) They are inherently \\textit{unscalable} and \\textit{inflexible}, as the inclusion of any new vulnerability types would require training of new models; or (ii) They only distinguish between vulnerable and non-vulnerable smart contracts (i.e., binary classification), without the ability to detect vulnerability types; or (iii) The tools require source code of the smart contract, which limits their applicability scope.\n\n\\vspace{0.1em}\n\\noindent\\textbf{Our goal and contributions.} In this paper, we aim to address the deficiencies and limitations of existing solutions and propose \\sys{}, the first Deep Neural Network (DNN) based framework for smart contract vulnerability detection that has the following properties: (i) Operates on bytecode of smart contracts and does not require access to the source code; (ii)~ Distinguishes safe contracts from vulnerable ones with one or more vulnerabilities; \n(iii) Automatically identifies the vulnerability types of detected vulnerabilities; and \n(iv) Presents an innovative multi-output model architecture that enables fast model extension to new vulnerabilities \nusing the concept of \\textit{transfer learning}. \n\n\\vspace{0.2em} \nIn particular, we make the following contributions:\n\n\\begin{itemize}\n    \\item \\sys{} enables \\textit{efficient} and \\textit{scalable} multi-vulnerability detection of smart contracts. It employs a \\textit{multi-output} architecture where the feature extractor\n    learns the program semantics and each branch of the DNN captures the semantics of a specific vulnerability class. The defender only needs to train a single DNN based on smart contract bytecode to detect multiple vulnerability types.\n\n    \\item \\sys{} is the first DNN-based\n    framework that supports lightweight transfer learning on new vulnerability types, thus is \\textit{extensible} and \\textit{generalizable}. Our multi-output architecture can be easily expanded by concatenating a new classification branch to the feature extractor. Only the new branch needs to be trained on the new dataset during transfer learning. \n    \n    \\vspace{0.1em}\n    \\item \\sys{} is automated for inspecting vulnerabilities in smart contracts prior to their deployment and demonstrates superior vulnerability detection performance while incurring low overhead. We perform a comprehensive evaluation of \\sys{} across various Ethereum smart contracts to corroborate its effectiveness, efficiency, and extensibility. Our framework can detect vulnerabilities in $0.02$ seconds per smart contract and yields an average F1 score of 95\\% across all evaluated classes.  \n\n    \\vspace{0.1em}\n    \\item We evaluate \\sys{} using a dataset consisting of 93.497 smart contracts downloaded from Ethereum blockchain and labeled them using three exiting vulnerability detection tools: Oyente~\\cite{rw_oyente_repo}, Mythril~\\cite{rw_mythril_repo}, and Dedaub~\\cite{dedaub}. To construct and label such a dataset, we developed a toolchain \\datatool{} that automates the acquisition and labeling process. \\datatool{}'s modular structure enables one to easily integrate other tools for labeling. We will open source \\datatool{} and our dataset to encourage further research on smart contract security.   \n\\end{itemize}\n\nOverall, \\sys{} is the first flexible and generalizable smart contract detection technique with superior vulnerability detection performance.\n\\vspace{0.1em}\n\\noindent\\textbf{Outline.} The remaining part of the paper is organized as follows: In Section~\\ref{sec:background}, we provide the necessary background information on smart contracts and their vulnerabilities, as well as give insights into deep learning. \nWe define the threat model and identify the design challenges in Section~\\ref{sec:overview}.\nSection~\\ref{sec:design} sheds light into \\sys{}'s design specifics, while Section~\\ref{sec:implementation} and~\\ref{sec:evaluation} provide implementation details and evaluation results, respectively. After that, the relevant related work is surveyed in Section~\\ref{sec:related}. We finally conclude in Section~\\ref{sec:conclusion}.  \\vspace{-0.5em}\n\\section{Background}\n\\label{sec:background}\nWe introduce smart contracts and their vulnerabilities in Section~\\ref{sec:smart_contracts}, and the background on deep learning (DL) in Section~\\ref{sec:dl}.\n\n \\vspace{-0.5em}\n\\subsection{Smart Contracts and Vulnerabilities}\n\\label{sec:smart_contracts}\n\\vspace{-0.2em}\nA smart contract is written in high-level programming languages such as Solidity~\\cite{solidity} and is called by its address to run operations on the blockchain.\nOnce compiled, the bytecode of the contract is generated and executed inside the Ethereum Virtual Machines (EVM). \nSince there is a one-to-one mapping between a blockchain operation and bytecode representation, it is feasible to analyze the control flow of a contract at the bytecode-level. When triggered, the execution of the smart contract is autonomous and enforceable for all participating parties~\\cite{ethereum-background-04}. \n\nThe EVM itself is a stack-based machine with a word size of 256 bits and stack size of 1024~\\cite{ethereum-yellowpaper}. The memory applies a word-addressable model. Once a contract is deployed on the blockchain, it requires gas to function. Gas is the unit used to pay the computational cost of the miners running contracts or transactions and is paid in Ether.\n\nSimilar to any other software, smart contracts might suffer from vulnerabilities and programming bugs. \nThe Smart Contract Weakness Classification (SWC) Registry~\\cite{swcregistry} collects information about various vulnerabilities. \nWe differentiate five categories of vulnerability types: External Calls, Programming Errors, Execution Cost, Influence by Miners, and Privacy. \n\n\\textbf{External Calls}. Any public function of a smart contract can be called by any other contract. A malicious user can then exploit public availability to attack vulnerable functions of smart contracts. A prominent example is the so-called reentrancy bug (SWC-107~\\cite{swcregistry}). Here, an attacker can call a contract's function multiple times before the initial call is terminated. If the internal contract state is not securely updated, the attacker can drain Ether from the contract by recursively calling the function.\n\n\\textbf{Programming Errors}.\nSome of the programming errors in smart contracts are very similar to those found in traditional programs,\nsuch as missing input validation, typecast bugs, use of untrusted inputs in security operations, unhandled exception, exception disorder, and Integer overflow and underflow vulnerabilities. In another example, an \\textit{assert} function used in tests and not removed by the programmer in the release version may lead to its misuse by an attacker, which can result in exploitable error conditions (SWC-110~\\cite{swcregistry}). Other vulnerabilities can be specific to smart contracts.\n\nExamples are greedy contracts that lock Ether indefinitely, gasless send bug that does not provide sufficient gas to execute the code of the smart contract, Ether lost in transfer if sent to unknown recipients, etc. \nFurther examples are \\textit{callstack depth} \nlimit reached exception bug and unprotected \\textit{selfdestruct} instructions (see SWC-106~\\cite{swcregistry}), where an\nattacker can call a smart contract's public function containing a \\textit{selfdestruct} to terminate the smart contract, or he can fill up the stack to reach the stack size limit. Both attacks result in a Denial of Service (DoS) of vulnerable smart contracts.\n\n\\textbf{Execution Cost}. Every transaction on the Ethereum network costs gas. However, every block has a spendable gas limitation. An attacker can use this limit to induce a DoS of a vulnerable contract. For example, if the execution time of a function is dependent on input from the caller, a malicious caller can expand the execution time of the smart contract over the gas limit (SWC-128~\\cite{swcregistry}). Thereby, execution is terminated by exceeding the gas limit before it is finished. Another way an attacker can misuse the gas limit per block is to induce an error on a \\textit{send} call. If a programmer bundles \\textit{multiple sends} in one function of the smart contract, the attacker can then prevent the execution of other \\textit{send} calls in the function.\n\n\\textbf{Influence by Miners}. Miners are entities that actually execute transactions on the blockchain. They can decide which transactions to execute, in what order, and also able to influence environment variables (e.g., timestamps). \nTo illustrate the problem, let us assume a scenario where a smart contract is instructed to send Ether to the first user that solved the puzzle. If two users commit a transaction with the solution at the same time, a miner decides who will be first and therefore will be getting the Ether (SWC-114~\\cite{swcregistry}). This vulnerability type is generally referred to as Transaction Order Dependence (TOD).\n\n\\textbf{Privacy}. Solidity~\\cite{solidity} offers different visibility labels for functions and variables. Most notably, a programmer can define a function as private or public. The default setting for functions is public, which can be overlooked by the programmer (SWC-100~\\cite{swcregistry}). If a variable or function is set to private, it can't be seen or changed by other contracts. However, even if it is set as private, an attacker can still parse the blockchain data, where those variables are stored in plaintext (SWC-136~\\cite{swcregistry}). \n\n\\begin{table*}\n\\centering\n\\scalebox{0.93}{\n\\begin{tabular}{|c|c|c|c|c|c|c|} \n\\hline\n\\textbf{Name}  & \\textbf{Method}  & \\textbf{Capability}  & \\textbf{Extensible}  & \\begin{tabular}[c]{@{}c@{}}\\textbf{Required }\\\\\\textbf{ Input} \\end{tabular} & \\begin{tabular}[c]{@{}c@{}}\\textbf{Detection time }\\\\\\textbf{ per Contract (s)} \\end{tabular} & \\textbf{F1-score}  \\\\ \n\\hline\n\\textbf{This work}  & \\begin{tabular}[c]{@{}c@{}}ML (LSTM) \\\\ + transfer learning \\end{tabular} & Multi-label & Yes & Bytecode & 0.02 & \\textcolor{red}{0.95} \\\\ \n\\hline\nOyente~\\cite{ethereum-background-03} & Symbolic execution & Multi-class & No & \\begin{tabular}[c]{@{}c@{}}Source code\\\\ and bytecode \\end{tabular} & 350 & 0.38 \\\\ \n\\hline\nMythril~\\cite{rw_mythx_article} & \\begin{tabular}[c]{@{}c@{}}Symbolic execution,\\\\ taint analysis, and SMT \\end{tabular} & Multi-class & No & Bytecode & 11.1 & 0.47 \\\\ \n\\hline\nDedaub~\\cite{rw_dedaub_contract_library_page} & Flow and loop analysis & Gas-focused vulnerability & No & Source code & 20 & NA \\\\ \n\\hline\nSecurify~\\cite{rw_securify_paper} & Symbolic analysis & Binary decision & No & Bytecode & 30 & 0.54 \\\\ \n\\hline\nVandal~\\cite{brent2018vandal}  & \\begin{tabular}[c]{@{}c@{}}Logic-driven \\\\ static program analysis \\end{tabular} & Multi-class & No & Bytecode & 4.15 & NA \\\\ \n\\hline\n\\multicolumn{1}{|l|}{ContractWard~\\cite{rw_contractward}} & ML (bigram model) & Binary decision & No & Opcode & 4 & 0.96 \\\\ \n\\hline\nTowards Sequential~\\cite{rw_lstm} & ML (LSTM) & Binary decision & No & Opcode & 2.2 & 0.86 \\\\ \n\\hline\nNLP-inspried~\\cite{gogineni2020multi} & ML (AWD-LSTM) & Multi-class & No & Opcode & NA & 0.9 \\\\ \n\\hline\nColor-inspried~\\cite{huang2018hunting} & ML (CNN) & Multi-label & No & Bytecode & 1.5 & 0.94 \\\\ \n\\hline\nGraph NN-based~\\cite{zhuangsmart} & ML (GNN) & Multi-class & No & Source code & NA & 0.77 \\\\\n\\hline\n\\end{tabular}\n}\n\\vspace{0.3em}\n\\caption{Qualitative comparison of \\sys{} and existing smart contract vulnerability detection methods. \\label{tab:comparison}}\n\\vspace{-1em}\n\\end{table*}\n\n\\vspace{-0.3em}\n\\subsection{Deep Learning}\n\\label{sec:dl}\n\\vspace{-0.2em}\n\\sys{} operates on the bytecode representation of the smart contracts, which can be considered as a special case of text data. \nWe introduce background about text representation and recurrent neural networks below.\n\n\\vspace{0.1em}\n\\textbf{Text Representation.} \nThe text modality is typically transformed into numerical vectors for usage in \nML algorithms. \nThis transformation can be realized in different ways, such as a bag of words~\\cite{wallach2006topic}, n-gram language model~\\cite{brown1992class}, and embedding layer~\\cite{zamani2017relevance}.\nThe numerical vectors converted from the text data are then used as the direct input to the DL models. \n\n\\setlength{\\belowcaptionskip}{-10pt}\n\\begin{figure}[t!]\n  \\centering\n  \\includegraphics[width=0.86\\columnwidth]{RNN.png}\n   \\vspace{-0.7em}\n  \\caption{A recurrent neural network and its unfolding in time~\\cite{deep-learning-background-03}. The computation of the forward pass is shown.}\n  \\label{fig:rnn}\n  \\vspace{-0.3em}\n\\end{figure}\n\\vspace{0.1em}\n\\textbf{Recurrent Neural Network.}\nAn RNN is a category of DNNs where the connections between nodes (i.e., neurons) construct a direct computational graph along the temporal sequence~\\cite{kim2017residual}. \nA key property of the RNN is that the model can use its internal states as memory cells to store the knowledge about prior inputs, thus capturing the contextual information in the sequential input data (e.g., text document).  \nAs shown in Figure~\\ref{fig:rnn}, the hidden states obtained from the previous input ($s_t$) affects the output in the current time step ($o_{t+1}$). The unfolded RNN diagram reveals the \\textit{`parameter sharing'} mechanism of RNNs where the weight matrices ($W$, $V$, and $U$) are shared across different time steps. Parameter sharing makes RNNs generalizable to unseen sequences of different lengths.   \n\n\\textbf{Multi-label vs. Multi-class classification.} \nSmart contracts vulnerability detection can be realized with two different paradigms. The first one is known as  \n\\textit{Multi-class classification}, which refers to the case where the classification task has more than two classes that are mutually \\textit{exclusive}. In particular, each sample is assigned with {one and only one} class label.\nThe second one, \\textit{Multi-label classification}, also involves multiple classes while a data sample can have more than one associated labels. This is because the classes in multi-label tasks describe non-exclusive attributes of the input (e.g., color and length). \n\nLet us use an example to illustrate the difference between these two paradigms.  \nGiven a clothing dataset with three colors (black, blue, red) and four categories (jeans, dress, shirt, shoes), we want to train a model to predict these two clothing attributes simultaneously. \nFigure~\\ref{fig:multioutput_nn} shows the architecture of the multi-class and multi-label formulation of the clothing classification task. \nThe multi-class design has only one set of dense layers (i.e., `heads') at the bottom of the DNN where the last dense layer has $3\\times4=12$ neurons.\nThe network topology for multi-label classification has two sets of dense heads at the end of the DNN where the last dense layer in each branch has $4$ and $3$ neurons to learn the clothing category and color attribute, respectively.  \nWe call the network design of the \\textit{multi-label} classification with multiple sets of dense heads as \\textit{`multi-output'} architecture throughout this paper.  \nThe `stem-branch' topology makes the multi-output architecture extensible to learn new attributes. \n\\sys{} leverages this observation to devise an efficient and extensible smart contract inspection solution. \n\n\\vspace{-1em}\n\\begin{figure}[ht!]\n  \\centering\n  \\includegraphics[width=0.9\\columnwidth]{images/multioutput_nn.png}\n  \\vspace{-0.5em}\n  \\caption{DNN architectures of multi-class (left) and multi-label (right) formulation of the clothing classification task~\\cite{multi_output}. \n  }\n  \\label{fig:multioutput_nn}\n  \\vspace{-0.3em}\n\\end{figure}\n\\section{Motivation} \\label{sec:motiv}\n\nVulnerability detection of smart contracts is a challenging task.  \nTable~\\ref{tab:comparison} summarizes the properties and performance metrics of previous detection tools. \nTo the best of our knowledge, none of the existing works takes into account of the extensibility requirement of vulnerability detection in their design. This means that when new vulnerabilities of smart contracts are discovered and exploited by the adversary, the detection tools cannot quickly adapt to the new contracts. \n\\sys{} is motivated to provide an efficient and extensible solution to concurrent detection of multiple vulnerability types using DL techniques.\nTo this end, we first investigate two research questions (RQs) about smart contract inspection in this section and answer them in details in Section~\\ref{sec:design}. \n\n\\vspace{0.2em}\n\\textit{RQ1: How to build a single DL model for detecting multiple vulnerability types?}\n\nPrior works have attempted to use ML algorithms to inspect the vulnerabilities in smart contracts.  \nAn LSTM-based detection approach is proposed in~\\cite{rw_lstm} to distinguish vulnerable contracts from safe ones (i.e., binary classification), which does not meet the goal of RQ1. \nContractWard~\\cite{rw_contractward} uses `One vs. Rest' algorithms and trains individual ML models for each vulnerability class. \nTherefore, ContractWard~\\cite{rw_contractward} does not meet the model number constraints in RQ1.  \nThe paper~\\cite{huang2018hunting} suggests to transform contract bytecode to RGB images and employs a Convolutional Neural Network (CNN) for binary classification.\nTheir method can support multi-label classification by re-training the obtained CNN on the corresponding dataset, thus satisfying both requirements in RQ1.    \n\n\\vspace{0.3em}\n\\textit{RQ2: How to make the DL model extensible to new vulnerabilities?}\n\nContractWard~\\cite{rw_contractward} can be adapted to detect a new vulnerability type by training a \\textit{new ML model} on the n-gram features from scratch.\nThe color-inspired inspection method~\\cite{huang2018hunting} does not consider the extensibility requirement of the detection. \nHowever, if applying the traditional transfer learning approach in the ML domain, the defender may replace the last dense layer of the pre-trained CNN with a new one. The new layer is then trained on the mixture of the old vulnerability data and the new one.  \nNote that training a new ML model from scratch or fine-tuning a pre-trained ML model on a large dataset incurs high computational cost, thus is not desirable in practice. \n\n\\vspace{-0.8em}%\\section{Overview}  \\label{sec:overview}\n\\vspace{-0.3em}\n\\section{Threat Model and Challenges}  \\label{sec:overview}\n\\vspace{-0.3em}\nWe introduce our threat model in Section~\\ref{sec:threat} and the challenges of developing an effective vulnerability detection technique for smart contracts in Section~\\ref{sec:challenges}.\n\n\\vspace{-0.5em}\n\\subsection{Threat Model} \n\\label{sec:threat}\n\\vspace{-0.2em}\nWe consider a scenario where the attacker is a malicious party that can obtain knowledge from any public data structure in the blockchain and can upload his contract code to the Ethereum system. The exact attack requirements and actions that the adversary need to take for the exploitation of a smart contract are specific to a vulnerability class, which we explain in Section~\\ref{sec:evaluation:dataset}.\nNote that \\sys{} is generic and we demonstrate its effectiveness with eight common vulnerability types in this paper. \nThe defender can be an Ethereum contract designer that aims to ensure the program is not exploitable by malicious adversaries during the code development time. This role can also be taken by the end user that intends to verify the security of the contract at runtime before sending any transactions to it.\n\\textcolor{magenta}{We assume the performance metrics reported in the previous papers~\\cite{ethereum-background-03,mueller2018smashing,rw_dedaub_mad_max_paper} as well as the open-sourced implementation of existing detection tools~\\cite{rw_oyente_repo,rw_mythril_repo,dedaub} are reliable. This assumption is feasible since expert inspection has been performed to cross-validate the performance of proposed detection methods in the previous works. \\sys{} relies on this assumption since our method is an instantiation of supervised learning paradigm.}\n\n\\sys{} aims to provide the defenders with a holistic smart contract vulnerability detection solution. To this end, we formulate vulnerability inspection as a\n\\textit{supervised} \\textit{multi-label classification} problem where the input is the contract (can be represented in high-level language, opcodes, or bytecodes) and the output is the corresponding vulnerability types as introduced in Section~\\ref{sec:evaluation:dataset}.\n\n\\setlength{\\belowcaptionskip}{-12pt}\n\\begin{figure*}\n  \\centering\n  \\includegraphics[width=0.83\\textwidth]{images/global.png}\n  \\vspace{-0.5em}\n  \\caption{Overview of \\sys{} framework for Ethereum smart contract vulnerability detection. \\sys{} has three stages: training, transfer learning, and deployment as shown in the top, middle, and bottom part of the figure. \n  }\n  \\label{fig:global}\n  \\setlength{\\belowcaptionskip}{-12pt}\n\\end{figure*}\n\n\\vspace{-0.5em}\n\\subsection{Challenges} \\label{sec:challenges}\nWe identify the challenges to develop an effective DNN for automated smart contract\nvulnerability detection below. \n\n\\textbf{(C1) Data Collection and Pre-processing.} Supervised learning of a DNN requires a sufficiently large labeled dataset. Analyzing smart contracts using the source code is difficult since not that many smart contracts are open-sourced. On another hand, blockchain platforms typically host their smart contracts in a form of a bytecode, which is publicly available.\nHowever, performing analysis on the bytecode raises another challenge due to the large bytecode length of long contracts.\nThis long sequence requires a large memory footprint during model training, suggesting that using the bytecode as direct input to the DNN model is impractical. \n\n\\vspace{0.1em}\n\\textbf{(C2) Feature Extraction.} \nThe second challenge concerns the problem of finding the proper feature representation of the smart contract program. \nOn the one hand, manual design of contract features is time-consuming and has limited efficacy, since the contract bytecode is long and hard to interpret by human developers. On the other hand, current implementations of automated feature extraction~\\cite{rw_contractward,rw_lstm,zhuangsmart}\n\n(Section~\\ref{sec:related}) mainly apply traditional software testing techniques on the smart contract without exploring its domain-specific properties, thus taking a long time to inspect a single contract.\n\n\\vspace{0.1em}\n\\textbf{(C3) Dataset Imbalance.} \nThe third challenge is a class imbalance in the training set. \nPrior works have shown that the number of contracts with specific vulnerability types is much lower than the one of non-vulnerable contracts~\\cite{rw_contractward}.\nLearning the characteristics of vulnerable contracts with a DNN is challenging since the stochastic gradient descent (SGD) based learning of DNN models is inherently biased towards the majority class, while our objective is to recognize the minority class (i.e., vulnerable contracts). As such, it is crucial to provide the DNN model with sufficient vulnerable contracts to ensure a high true positive rate.\n\n\\vspace{0.1em}\n\\textbf{(C4) Efficiency.} \nThe fourth challenge is to ensure the efficiency of DNN training and inference for concurrent detection of multiple vulnerability types. Identifying diverse attacks with a single DNN detector is challenging since different vulnerabilities exploit distinct loopholes in the contract, which might be hard to capture with a conventional DNN.\nEfficiency is important for practical development of the contract scanner since devising individual classifiers for each vulnerability class, as done, e.g., in~\\cite{rw_contractward}, is unscalable and incurs large computation overhead. \n\n\\vspace{0.2em}\n\\textbf{(C5) Extensibility/Generalizability.} \nFinally, smart contract inspection should be capable of learning new vulnerability types quickly while preserving the knowledge of the known ones. We call this requirement `extensibility'. \nThis property is important for both, researchers and practitioners, since new attacks on smart contracts are emerging at a fast speed.\nAugmenting an existing contract detector to new attacks is non-trivial since the new attack exploits the unseen and unpredictable susceptibilities of smart contracts compared to the previously known attacks.\nTraining a new DNN from scratch to accommodate the new vulnerabilities consumes extensive resources and incurs additional engineering costs. \n\nWe show how \\sys{} framework tackles each of the above challenges in Section~\\ref{sec:design}. \n\\vspace{-0.1em}\n\\section{\\sys{} Design}\n\\label{sec:design}\nWe propose \\sys{}, the first {extensible} and {transfer learning-friendly} DNN-based framework for vulnerability detection of Ethereum smart contracts. \nThe key innovation of \\sys{} is that we {decompose} the task of vulnerability detection into two subtasks: (T1) Learning the bytecode features of general contracts (\\textit{attack-agnostic}); (T2) Learning to identify each particular vulnerability class (\\textit{attack-specific}). To achieve (T1), we design a \\textit{feature extractor} that captures the semantic and syntactic information of contract bytecode regardless of its vulnerabilities. To perform (T2), we devise an individual \\textit{vulnerability class branch} to characterize susceptibility given the bytecode features extracted in (T1). Our \\textbf{divide-and-conquer} design is highly modular and flexible compared to previous detection techniques as we corroborate in Section~\\ref{sec:evaluation}. \n\nBelow we discuss each step of \\sys{} design, which aims to overcome the design challenges in Section~\\ref{sec:challenges}. \n\n\\vspace{-0.3em}\n\\subsection{\\sys{} Global Flow} \\label{sec:global}\n\nFigure~\\ref{fig:global} demonstrates the global overview of \\sys{} smart contract detection technique. Our framework has three stages: DNN classifier training, transfer learning, and deployment. We discuss each stage below.\n\n\\vspace{0.05em}\n\\textbf{Training.} The top part of Figure~\\ref{fig:global} shows \\sys{}'s training pipeline. \nTo enable supervised learning for vulnerability detection, the defender first constructs the smart contracts bytecode dataset with corresponding labels, as detailed in Section~\\ref{sec:data}.\nThe defender specifies the system parameters, including the vulnerabilities of interests and the available hardware resources for \\sys{}'s multi-output DNN design.  \nFinally, the devised model is trained on the collected contract data with their corresponding labels, resulting in a converged DNN detector.   \n\n\\vspace{0.05em}\n\n\\textbf{Transfer Learning.} The middle part of Figure~\\ref{fig:global} shows the transfer learning phase of \\sys{}. \nGiven a trained detector and the bytecode of smart contracts with new vulnerabilities, \\sys{} extends the DNN architecture devised in the original training phase with new parallel branches. \nThe layers in the expanded branch are then trained on the new vulnerability data with the associated labels to perform transfer learning. \nTo the best of our knowledge, \\sys{} is the first framework that supports transfer learning to accommodate new vulnerability types of the smart contracts. \n\n\\vspace{0.05em}\n\\textbf{Deployment.} The bottom part of Figure~\\ref{fig:global} shows the workflow of \\sys{}'s deployment stage. \nAfter the training/transfer learning phase completes, \\sys{} returns a trained DNN classifier that can detect whether an unknown smart contract has any of the learned vulnerability types.  \n\n\\vspace{-0.6em}\n\\subsection{Neural Network Design}\n\\label{sec:approach:deep-learning}\n\\vspace{-0.3em}\nPrior ML-based vulnerability detection techniques only explored simple architectures, such as K-Nearest Neighbors, SVM, Decision Trees~\\cite{rw_contractward}, or use a CNN~\\cite{huang2018hunting}/RNN~\\cite{rw_lstm} to decide whether a smart contract is vulnerable or not. \nTo overcome these constraints, \\sys{} aims to design an \\textbf{extensible} DNN detector that: (i) Provides the probability that the smart contract has certain vulnerabilities, instead of making a binary decision about contract security; (ii) Classifies multiple vulnerabilities with a single DNN. \nTo this end, we propose an innovative \\textbf{multi-output architecture} for \\textbf{concurrent} detection of multiple vulnerability types. \nThis neural network design step is shown by the `Multi-output DNN Design' module in \\sys{}'s global flow (Figure~\\ref{fig:global}). \n\nFigure~\\ref{fig:demo_nn} illustrates the generic architecture of our DNN detector. {The stem and branch layers shown in the diagram are typical DNN layers such as the Dense layer, Dropout layer, and GRU layer.}\nThe multi-output model has two main components and we discuss each one below:  \n\n\\begin{figure}[ht!]\n  \\centering\n  \\includegraphics[width=0.98\\columnwidth]{images/demo_nn.png}\n  \\vspace{-0.6em}\n  \\caption{General architecture of \\sys{}'s multi-output model for concurrent detection of multiple vulnerability types. \n  }\n  \\label{fig:demo_nn}\n  \\vspace{0.3em}\n\\end{figure}\n\n\\textbf{(i) Feature Extractor.} The first component of \\sys{}'s extensible DNN model is the common feature extractor (i.e., `stem') shared by all the bottom branches. \nThe feature extractor is a stack of layers that learn the fundamental features in the input data that are general and useful across different attributes. \nIn the context of smart contracts, the feature extractor is trained to learn the semantic and syntactic information from the contracts' bytecode. \nTo this end, we incorporate several key layers in \\sys{}'s feature extractor: \n\n\\begin{itemize}\n    \\item \\textit{Embedding Layer.} The bytecode of smart contracts are long hexadecimal numbers, while DNNs typically work with fractional numbers to achieve high accuracy. The embedding can solve this discrepancy since it stores the word embedding in the numerical space and retrieves them using indices~\\cite{zamani2017relevance}.\n    The embedding layer provides two key benefits: (i)~Compressing the input via a linear mapping, thus reducing the feature dimension; (ii)~Learning bytecode in the embedding space (fractional numbers). This facilitates representation exploration and gathers similar bytecode in the vicinity of each other. \n    \\sys{} leverages the advantages of the embedding layer to capture the semantics in the input bytecode. \n    \n    \\vspace{0.3em}\n    \\item \\textit{GRU/LSTM Layer.} The stem layers and branch layers in Figure~\\ref{fig:demo_nn} can include GRU/LSTM layers for processing sequential inputs. \n    Gated Recurrent Units (GRU) and Long Short-Term Memory (LSTM) are two typical layers in recurrent neural networks that help to overcome the short-term memory constraint and vanishing gradient problem~\\cite{kim2017residual} using a \\textit{`gating'} mechanism. \n    More specifically, both types of layers have internal gates that regulate the information flow along the time sequences and decide which data shall be kept/forgotten. \n    We mainly use GRU layers in \\sys{}'s DNN design. \n\\end{itemize}\n\n\\textbf{(ii) Vulnerability Branches.} \nThe second component of \\sys{}'s multi-output DNN architecture is the \\textbf{ensembling} of multiple vulnerability branches. Each branch is a stack of layers that are trained to learn the patterns/hidden representation of the corresponding vulnerability class. \nWhile there is no direct dependence between different branches, they share the same feature extractor, i.e., the input to each branch is the same. \nThis is feasible since the branch input (which is also the feature extractor's output) shall capture the semantics in the contract's bytecode, which is common/general information useful for different vulnerabilities. \n\n\\sys{}'s `stem-branches' architecture is similar to the \\textit{`mixture of experts'} paradigm where the problem space is divided into homogeneous regions and individual expert models (learners) are trained to tackle each sector~\\cite{kiyono2019mixture}. \nThe main difference between \\sys{}'s multi-output design and the mixture of experts model is that the latter one requires a trainable gating network to decide which expert shall be used for each input region, while our DNN model does not need such a gating mechanism since we aim to detect multiple vulnerability types of the input contract in parallel.  \n\nNote that the last layer of each vulnerability branch is a Dense layer with one neuron. \nThe \\textit{sigmoid} evaluation of this neuron's activation value gives the \\textit{probability} that the input contract has the specific vulnerability. \nAs such, \\sys{} engenders detection results with better \\textbf{interpretability} by providing the confidence score for its diagnosis instead of the binary decision about vulnerability existence. \n\nIn summary, \\sys{}'s multi-output architecture solves the feature extraction, efficiency and extensibility challenges (C2, C4, C5) identified in Section~\\ref{sec:challenges}.\nIn particular, \\sys{} allows the defender to train a \\textit{single} DNN for detecting multiple vulnerability types instead of training an individual classifier for each attack, thus demonstrating superior efficiency compared to the prior work~\\cite{rw_contractward,huang2018hunting,rw_lstm}. \n\\sys{} design incurs minimal non-recurring engineering cost and is scalable as new vulnerabilities are identified. \n\n\\vspace{-0.3em}\n\\subsection{Transfer Learning} \\label{sec:transfer}\n\\vspace{-0.3em}\nMalicious parties have a strong incentive to discover and exploit new vulnerabilities of smart contracts due to the associated prodigious profits. \nAs such, the contract inspection technique shall be extensible to learn new vulnerabilities as they are identified.  \nWe propose \\textit{transfer learning} as the solution to the challenge (C5) in Section~\\ref{sec:challenges}.\nMore specifically, we suggest to \\textit{expand} the pre-trained multi-output DNN model by adding new vulnerability branches for transfer learning. \nThis process is demonstrated in the middle part of Figure~\\ref{fig:global}. \nThe transfer learning capability of \\sys{} ensures that our detection framework can be upgraded with the minimal cost to defend against emerging attacks on smart contracts. \n\nOur transfer learning stage has two goals: \n\n\\vspace{0.1em}\n\\textbf{(G1) Preserve Knowledge on Old Vulnerabilities.}\nOn the one hand, the DNN detector shall retain knowledge about the previous vulnerability types that are used in the initial training phase. \nThis property is important since \\sys{} aims to provide a holistic and extensible solution to concurrent detection of multiple vulnerabilities. \nAs such, maintaining high classification accuracy on the known attacks is essential. \n\n\\vspace{0.1em}\n\\textbf{(G2) Learn New Vulnerabilities Quickly.} On the other hand, transfer learning aims to adapt the pre-trained model to achieve high accuracy on the new dataset in an efficient way. \nThis is also required by the extensibility challenge (C4) in Section~\\ref{sec:challenges}. \nTo achieve fast adaptation, transfer learning shall yield minimal runtime overhead. \nThis requirement is crucial for practical deployment, since training a new DNN model from scratch for the new vulnerabilities is prohibitively expensive and hard to maintain. \n\n\\sys{}'s transfer learning phase works as follows. \nWhen a new vulnerability is identified, the defender constructs a new training dataset accordingly and updates the converged DNN detector by adding a new vulnerability branch (i.e., the stack of layers). \nDuring transfer learning, the parameters of the common feature extractor and existing vulnerability branches are \\textit{fixed}. \nOnly the parameters in the newly added branch are updated with the new vulnerability dataset. \nFreezing the feature extractor and the converged branches ensures that the updated DNN classifier preserves the detection accuracy on the old vulnerabilities (G1), and training a new branch enables the updated model to learn the new attack (G2).\n\n\\textcolor{magenta}{Besides extensibility, \\sys{} also enables lightweight and fast adaptation when \\textit{mode drift} occurs. Smart contracts running on Ethereum are dynamic and change over time, which might lead to a decrease of \\sys{}'s performance. To alleviate the model drift concern, the contract developer can update the parameters of the vulnerability branches given a set of labeled new contracts while fixing the ones of the feature extractor. }\\vspace{-0.2em}\n\\section{Dataset Construction Toolchain}\n\\label{sec:data}\n\\vspace{-0.2em}\nIn this section, we present \\datatool{}, the toolchain we built to construct the labeled smart contract dataset and to address the challenge (C1) defined in Section~\\ref{sec:challenges}. \nDetails about our dataset used in DNN training is given in Section~\\ref{sec:evaluation:dataset}. \nIt is worth mentioning that a standard and public smart contract vulnerability dataset was not available before. We will open source \\datatool{} toolchain and our dataset used in the evaluation to facilitate the development and comparison between emerging detection techniques.\n\n\\subsection{Design Choices}\n\\label{sec:dataset:choices}\n\\vspace{-0.2em}\nTo build a sufficiently large training set for our supervised DNN training, we make the design choice to work on the bytecode-level since the bytecode of smart contracts are publicly available. The accessibility of contract bytecode solves the challenge (C1) in Section~\\ref{sec:challenges}.\nThis also makes our approach agnostic to the programming languages of smart contracts, since smart contracts are written in different languages (e.g., Solidity~\\cite{solidity}, Viper~\\cite{vyper}, and Serpent~\\cite{serpent}) get eventually compiled to the same bytecode.  \nThe EVM bytecodes are executed in a stack context, thus the control flow of a program at the bytecode level contains useful information for detection. \n\n\\datatool{} is designed to obtain the bytecode files of smart contracts from the Ethereum platform, \\textcolor{magenta}{label them using available bytecode-level detection tool(s), }\nand store the result in a database.\nNote, that we concentrate on Ethereum smart contracts for exemplary purposes in this paper. Generally, \\sys{} can also be used for vulnerability detection in smart contracts of other cryptocurrency platforms that use Ethereum-compatible EVM, such as Quorum~\\cite{quorum}, Vechain~\\cite{vechain}, Rootstock~\\cite{rootstock}, and Tron~\\cite{tron}, to name a few. This is possible since the bytecode of smart contracts on these platforms is compatible with Ethereum EVM. \n\n\\subsection{\\datatool{} Architecture}\n\\label{sec:implementation:bytecode}\n\n\\vspace{-0.5em}\n\\begin{figure}[ht!]\n  \\centering\n  \\includegraphics[width=\\columnwidth]{images/toolchain2.png}\n  \\vspace{-2em}\n  \\caption{Generic workflow of \\datatool{} for smart contract acquisition and labeling.}\n  \\label{fig:data:toolchain}\n  \\vspace{0.3em}\n\\end{figure}\n\nWe show the generic workflow of \\datatool{} toolchain in Figure~\\ref{fig:data:toolchain}.\nIn step~(1), the addresses of contracts are retrieved from the blockchain. Step (2) involves downloading \nthe bytecode from the Ethereum network by address and extracting information into a database. In step (3), the bytecode is pre-processed for input efficiency. \n\\textcolor{magenta}{The last step (4) outputs the vulnerability types of the contracts using the bytecode-level detection tools. It is worth noticing that any vulnerability detection techniques that take bytecode as input can be used by \\datatool{} for contract labeling, including existing methods such as Oyente~\\cite{rw_oyente_repo}, Mythril~\\cite{rw_mythril_repo}, Dedaub~\\cite{dedaub}, and our proposed new method \\sys{}. We show in Section~\\ref{sec:evaluation} that \\sys{} outperforms existing tools in terms of both detection effectiveness and efficiency.}\n\nFor a concrete instantiation of the generic flow, we use the open-source tool Ethereum ETL~\\cite{ethereum-etl-article,ethereum-etl-repo} to retrieve the addresses of contracts in step (1). The ETL tool connects to the Ethereum network and exports blockchain content into CSV files. For step (2), we also utilize existing tools: Multiple Web APIs exist to download the contracts' bytecode by its address. We opt for two APIs for instantiating the bytecode downloading module of \\datatool{}: Infura~\\cite{infura} and Dedaub's Contract-Libray~\\cite{dedaub}. For the instantiation of step (3), we develop an assistive Python module named \\textit{Contract Loader} to extract the information from smart contracts into a MySQL database~\\cite{mysql}. \nIn the last step (4), we use three tools for data labeling:  Oyente~\\cite{rw_oyente_repo}, Mythril~\\cite{rw_mythril_repo}, and Dedaub~\\cite{dedaub}. \nWe do not consider tools that scan smart contracts on the source code level since decompilation might result in information loss. \nThe modular structure of \\datatool{} makes it possible to easily extend the toolchain with other bytecode-level vulnerability detection tools \\textcolor{magenta}{including \\sys{}.}\n\n\\vspace{-0.4em}\n\\subsection{Bytecode Acquisition}\n\\label{sec:implementation:preclassification}\n\\vspace{-0.3em}\nFor dataset construction, \\datatool{} first utilizes \\textit{Infura} API to download smart contracts. We were able to download 1.155.085 bytecodes from the first 5 million Ethereum blockchain blocks. \nThis number corresponds to about 96\\% of the smart contracts in the targeted blocks.  \nIn some cases, the download resulted in an empty bytecode 0x. The possible reasons could be: (i)~The Ethereum node is not fully synced with the network, thus the bytecode is not available; (ii)~An empty contract is deployed; (iii)~The smart contract is self-destructed. \nTo tackle the situation where the smart contracts' bytecode exists but cannot be downloaded via Infura API, \\datatool{} uses another API provided by Dedaub tool to retrieve the missing bytecode files. \nFinally, at the end of the bytecode acquisition process, 1.156.611 smart contract bytecode files are available for \\sys{}'s vulnerability analysis.  \n\n\\vspace{-1em}\n\\subsection{Bytecode Preprocessing}\n\\label{sec:implementation:preclassification}\n\\vspace{-0.3em}\n\nThe downloaded bytecode consists of hexadecimal digits that represent particular operation sequences and parameters. \nIn the preprocessing step, \\datatool{} first transforms the collected raw bytecodes to sequences of operations divided by a unique separator and removes the input parameters from the bytecode to reduce the input size.\nFurthermore, it merges operations with the same functionality into one common operation. \nFor instance, the similar commands \\textit{PUSH1} - \\textit{PUSH32} commands (represented by the bytes \\textit{0x60}-\\textit{0x7f}) are replaced with the \\textit{PUSH} operation (represented by \\textit{0x60}).\nNote that some hexadecimal digits in the crawled bytecode do not correspond to any operations defined in the Ethereum Yellow Paper~\\cite{ethereum-yellowpaper}. These bytes are considered as invalid operations and substituted with the value \\textit{XX}.\n\n\\vspace{-0.4em}\n\\subsection{Labeling of Smart Contracts}\n\\label{sec:implementation:preclassification}\n\\vspace{-0.2em}\n\nA smart contract might have multiple vulnerabilities as introduced in Section~\\ref{sec:smart_contracts}. \nEach of the vulnerability detection tools used by \\datatool{} is specialized for detecting a specific set of vulnerability types. \n\\textcolor{magenta}{Note that besides the bytecode-level detection tools themselves, \\datatool{} also store the performance metrics (e.g., F1 score) of each tool on each vulnerability type that they can detect. The performance characterizations are obtained from the previous publications~\\cite{rw_oyente_repo,rw_mythril_repo,dedaub} with experts' manual inspection to ensure the correctness. \nTo determine if a given smart contract has a specific vulnerability type, \\datatool{} selects the detection tool that features the highest F1 score on this vulnerability among all available ones and use it for contract labeling. }\n\n\\textcolor{magenta}{\\datatool{} repeats the above process for each contract and each vulnerability type.} \nWe develop Python modules to perform the above task.\nIn the end, 1.156.611 smart contracts are labeled. It is worth repeating that since there are no dependencies among the vulnerability scanning tools, the set of vulnerability types can be easily extended with other available tools. \n\\vspace{-0.2em}\n\\section{Implementation}\n\\label{sec:implementation}\n\\vspace{-0.2em}\nIn this section, we instantiate the generic design of \\sys{} described in Section~\\ref{sec:design} on eight\nvulnerability types and elaborate on implementation details.\n\n\\vspace{-0.3em}\n\\subsection{Implementation of the DNN Model}\n\\label{sec:implementation:dl}\n\\vspace{-0.2em}\n\nWe begin with the instantiation of the \\sys{}'s DNN model.\nWe utilize the \\textit{tf.keras} package~\\cite{tensorflow} for model building, training, and inference.\nFurthermore, we devise a model serving API that takes the plain bytecode as input and returns the vulnerability detection labels as output. Our API provides end-to-end usage for the defender to update/deploy his own DNN and inspect unknown contract bytecode.\nWe detail the implementation procedures as follows. \n\n\\subsubsection{Dataset Chunking}\nTo enable our supervised learning, a designated dataset with the preprocessed bytecode and associated labels is required. The labeled bytecode dataset for the model training process is constructed as explained in Section~\\ref{sec:data}.\nFurthermore, we develop a Python module to read data from the database and generate CSV files as the inputs to \\sys{}'s DNN model.  \nSince the size of our bytecode dataset is large, loading the full dataset into memory at one time is likely to incur out of memory (OOM) error.\nTo alleviate the memory constraint (Challenge (C1) in Section~\\ref{sec:challenges}), we perform \\textit{data chunking} as follows:\n(i) The bytecode samples and the corresponding labels in the CSV file are merged into one \\textit{DataFrame}; (ii)~The dataset is then shuffled and stored as a temporary file; and (iii)~We create chunks from the shuffled dataset and store the segments as chunk files based on the pre-defined chunk size (default is $1024$). The chunk files are passed directly to the DNN model.\nWe provide more details about our data chunking process in Appendix Section~\\ref{sec:appendix:chunking}. \n\nNote that the collected contract data might have the class imbalance issue~\\cite{rw_contractward} (Challenge (C3) in Section~\\ref{sec:challenges}). In our work, we construct a balanced training set to ensure that each batch of data fed into \\sys{}'s DNN model has a comparable number of vulnerable and safe contracts. Details about our dataset balancing is given in Section~\\ref{sec:evaluation:dataset}. \n\n\\subsubsection{Model Building and Training}\nTo realize \\sys{}'s DNN-based vulnerability scanning approach, we instantiate a Multi-Output-Layer (MOL) DNN model based on our generic architecture explained in Section~\\ref{sec:approach:deep-learning}.\n\n\\begin{figure}[ht!]\n  \\centering\n  \\includegraphics[width=0.86\\columnwidth]{images/mol_arc.png}\n  \\vspace{-0.8em}\n  \\caption{Multi-output DNN architecture of \\sys{} for concurrent detection of multiple vulnerability types. Here, $BS$ is the batch size, the rightmost red branch denotes adding a new branch for transfer learning on new vulnerabilities. }\n    \\label{fig:implementation:mol-gru}\n    \\vspace{0.8em}\n\\end{figure} \n\nFigure~\\ref{fig:implementation:mol-gru} visualizes the actual model implemented in our experiments. We first build a MOL-DNN model with six output branches for main model training and then extend it with two new branches for transfer learning.\nRecall that our objective is to enable concurrent detection of multiple vulnerability types. To this end, we construct a recurrent neural network by stacking embedding layer, GRU layers, Dropout layers, and Dense layers to process sequential bytecode inputs. \nThe feature extractor is concatenated with multiple branches to output the probability of having each specific vulnerability.  \nAfter building the MOL-DNN model, we specify the model hyper-parameters as shown in Table~\\ref{tab:model_param}, and launch the training process as depicted in Figure~\\ref{fig:global}.\nSince the bytecode dataset is chunked to avoid OOM errors, \\sys{}'s DNN model iterates over all chunks multiple times during model training. \n\n\\begin{table}[ht!]\n\\centering\n\\scalebox{0.96}{\n\\begin{tabular}{|l|l|}\n\\hline\n\\thead{\\textbf{Variable}} & \\thead{\\textbf{Setting}} \\\\ \\hline\nLayer Type & Embedding, GRU, Dense, Dropout \\\\ \\hline\n\\#Hidden Unites& GRU:64, Dense:[128,64,1]  \\\\ \\hline\nOptimizer &  Adam \\\\ \\hline\nLoss Function & Binary Cross-Entropy \\\\ \\hline\nLearning Rate & 0.001 \\\\ \\hline\nDropout Values  &  0.2 \\\\ \\hline\n\\#Local\\_Epochs & 1  \\\\ \\hline\n\\#Global\\_Epochs & 1  \\\\ \\hline\nBatch Size     & 32 \\\\ \\hline\nMAX Seq. Length & 4100 \\\\ \\hline\n\\end{tabular}\n}\n\\vspace{1.6em}\n\\caption{Model Hyper-parameters.}\n\\label{tab:model_param}\n\\vspace{-1.6em}\n\\end{table}\n\nWe define `\\#Global\\_Epochs' to be the total number of times that the full training set is iterated by our DNN model and `\\#Local\\_Epochs' as the number of times that each chunk is used to update the model.\nBefore the chunked data are passed to the model's input layer, the bytecode sequence needs to be vectorized.\nThis is realized by a \\textit{tokenizer}, which transforms the hexadecimal data into numeric vectors. \nAfter tokenization, a hyper-parameter \\textit{MAX\\_SE\\-QUENCE\\-\\_LENGTH} is applied to the input vectors. Sequences shorter than this length are zero-padded, while sequences longer than this length are truncated. \nWe empirically study the distribution of the bytecode length and show the results in Figure~\\ref{fig:dataset-length-distribution}. The hyperp-arameter \\textit{MAX\\_SE\\-QUENCE\\-\\_LENGTH} is set to 4100 to ensure more than $98.5\\%$ of the contracts are not truncated\\footnote{Both excessive padding and truncation may worsen performance. For instance, truncated contracts may end up being mislabeled as benign if a vulnerability resides in the truncated part of the contract.}.\n\n\\begin{figure}[ht!]\n  \\centering\n  \\includegraphics[width=0.77\\columnwidth]{dataset_length_distribution.png}\n  \\vspace{-1.5em}\n  \\caption{Distribution of bytecodes length in the dataset.}\n  \\label{fig:dataset-length-distribution}\n  \\vspace{0.8em}\n\\end{figure}\n\nThe tokenized data are then passed to the DNN model for training. We assess the classification accuracy of the model after each Local Epoch (L\\_Ep., train on one chunk) and each Global Epoch (G\\_Ep., train on all chunks). The evaluation results are stored in a metric history object to keep track of the progress.  \nIn the testing phase, the remaining (unseen) data chunks are passed to the model to compute the detection metrics. \nAt the end of the model training stage, we save the converged MOL-DNN model, the used tokenizer, and the evaluation metrics files to wrap the model as an API service. \n\n\\vspace{-0.3em}\n\\subsection{Model Serving API}\n\\label{sec:implementation:deeplearning:modelapi}\n\\vspace{-0.2em}\nOur trained DNN model can detect pre-defined vulnerability types in smart contracts. We wrap the model within an API to ensure that we can serve predictions to end-users on the fly. We utilize Flask~\\cite{flask} and devise a Python module to provide a REST API endpoint for running model inference on bytecode files.  \nOur API also performs automated bytecode transformation (input preprocessing) to remove the manual efforts for the defender. \nThe learned \\sys{} model and associated configurations are passed to our API. \nThe Python module creates two different API endpoints. The first endpoint shows the configuration passed to the module and the second one triggers model inference. \nListing~\\ref{lst:model-api-request-body} shows an example of the plain bytecode of the smart contracts, which is passed to the second endpoint for vulnerability detection.  \n\n\\vspace{-0.4em}\n\\begin{lstlisting}[caption={Sample request body when calling \\sys{}'s prediction endpoint.},language=json,label={lst:model-api-request-body},firstnumber=1,frame=tblr\n,basicstyle=\\fontsize{8}{9}\\selectfont\n]\n{\"smart_contract\": \"606060405236150100000...\"}\n\\end{lstlisting}\n\nIn the second endpoint, the bytecode of the input smart contract is vectorized using the same tokenizer as the one used in \\sys{}'s model training step. The processed sequence is then fed as the input to the trained MOL-DNN model for vulnerability detection. In addition to the detected vulnerability types, the prediction time of \\sys{} is tracked and shown to the user. An example response from \\sys{}'s API endpoint is shown in Listing~\\ref{lst:model-api-prediction}.\n\n\\vspace{-0.4em}\n\\begin{lstlisting}[caption={\\sys{}'s response to the sample request when calling our prediction endpoint. The response includes the analysis results of multiple vulnerability types. },label={lst:model-api-prediction},language=json,firstnumber=1,frame=tblr, basicstyle=\\fontsize{8}{9}\\selectfont]\n{\"prediction\": {\n    \"ASSERT_VIOLATION\": 0.0001,\n    \"ACCESSIBLE_SELFDESTRUCT\": 0.9998,\n    \"DoS (UNBOUNDED_OP)\": 0.9996,\n    \"MULTIPLE_SENDS\": 0.0012,\n    \"TAINTED_SELFDESTRUCT\": 0.9998,\n    \"CALLSTACK\": 0.9995,\n    \"MONEY_CONCURRENCY\": 0.0013,\n    \"REENTRANCY\": 0.0009}, \n \"prediction_time in_second\": \"0.02\"}\n\\end{lstlisting}\\vspace{-0.3em}\n\\section{Evaluation}\n\\label{sec:evaluation}\nWe assess \\sys{} on the large-scale smart contract dataset built as described in Section~\\ref{sec:data}.\nIn this section, we explain our experimental setup and the evaluation metrics to characterize the performance of \\sys{}'s DNN model.  \n\n\\vspace{-0.3em}\n\\subsection{Dataset}\n\\label{sec:evaluation:dataset}\nTo build our dataset, we collected $\\sim1.2$ million smart contracts from the first 5 million Ethereum blockchain blocks using \\datatool{}, as explained in Section~\\ref{sec:implementation:preclassification} and label them accordingly. Note that vulnerability scanners can normally detect multiple vulnerability types, thus there might also be overlap in coverage. \nFor instance, a reentrancy bug is detected by all three tools, Oyente, Mythril, and Dedaub.\n\nTo select only one label for redundantly labeled vulnerability types, we first compute respective F1 scores of different tools~\\cite{metric_web} based on the true positives, false positives, and false negatives reported in the papers.\nThe tool with the highest F1 score on this particular vulnerability class is then used to determine if the collected smart contracts are vulnerable to this vulnerability class.\nFor instance, Oyente~\\cite{rw_oyente_repo} is used to detect the reentrancy bug since it yields the highest score. \n\nFor the purpose of evaluation, we include eight vulnerability types in our dataset. \nHowever, as discussed in Section~\\ref{sec:transfer}, we stress that our approach is not limited only to eight classes and can be easily extended with new attacks. \n\nIn the following, we define eight vulnerability types included in our evaluation and refer to vulnerability categories presented in Section~\\ref{sec:smart_contracts} for more detailed vulnerability description. \n\n\\begin{itemize}\n\\item \\textbf{Callstack Depth [cl. 1]}: \nThis vulnerability class belongs to the category \\textbf{Programming Error} (cf. Section~\\ref{sec:smart_contracts}) and exploits the stack size limit issues of the EVM.\n\n\\item \\textbf{Reentrancy [cl. 2]}: % detected by Oyente:\nReentrancy bugs are caused by \\textbf{External Calls} and allow an attacker to drain funds, as explained in Section~\\ref{sec:smart_contracts}.\n\n\\item \\textbf{Multiple Sends [cl. 3]}:\nThis class hinges on the exploitation of a smart contract's \\textbf{Execution Costs} to induce DoS.\n\n\\item \\textbf{Accessible selfdestruct [cl. 4]}: \nThis \\textbf{Programming Error} can be exploited to terminate a contract such that the remaining funds are sent to a predefined address.\n\n\\item \\textbf{DoS (Unbounded Operation) [cl. 5]}: \nAn attacker can exploit the limited \\textbf{Execution Costs} of a smart contract when the execution time is dependent on input from an external caller.\n\n\\item \\textbf{Tainted selfdestruct [cl. 6]}: \nThis vulnerability is an extension of vulnerability class 4 (cl. 4). The attacker here can set to which address the remaining balance of the smart contract is sent.\n\n\\item \\textbf{Money concurrency [cl. 7]}:\nThis vulnerability is also known as Transaction Ordering Dependence (TOD) and belongs to the \\textbf{Influence by Miners} category.\n\n\\item \\textbf{Assert violation [cl. 8]}:\nThis \\textbf{Programming Error} leads to a constant error state of the smart contract, which can be exploited by an attacker.\n\\end{itemize}\n\nFor each vulnerability class, we select at least 15.000 samples with this specific vulnerability from our raw dataset ($\\sim 1.2$ million contracts) and concatenate them to construct the vulnerable contract set with the equally-sized distribution. \nWe empirically set the minimal sample number to 15.000 since this is the smallest size of the well-represented vulnerability types in our dataset. The above dataset was then completed with 15.000 completely clean smart contracts where no vulnerabilities were detected by the tools used in this work (Section~\\ref{sec:implementation:preclassification}).\nFigure~\\ref{fig:dataset-distribution} shows the vulnerability class distribution of our balanced, labeled dataset.  \nOne can see from Figure~\\ref{fig:dataset-distribution} that our dataset construction method solves the challenge (C3) formulated in Section~\\ref{sec:challenges}.\n\n\\begin{figure}[ht!]\n\\centering\n\\includegraphics[width=0.88\\columnwidth]{images/dataset_label_distribution.png}\n\\vspace{-1em}\n\\caption{Vulnerability class distribution of our dataset. \n}\n\\label{fig:dataset-distribution}\n\\vspace{0.7em}\n\\end{figure}\n    \nIt is worth mentioning that the actual size of our labeled dataset is 93.497 samples instead of $15000 \\times (8+1)$. This is because \\sys{} formulates vulnerability detection as \\textit{multi-label classification}, meaning that a contract might have multiple labels and repeatedly appear in the selection of several vulnerability types described above.\nWe take $80\\%$ and $20\\%$ of the labeled dataset to construct the training and test dataset for \\sys{}. Note that we set aside $10\\%$ of the training data as the validation data to prevent model over-fitting.\n\n\\subsection{Evaluation Metrics}\n\\label{sec:evaluation:metrics}\n\\vspace{-0.2em}\n\\sys{} provides concurrent detection of multiple vulnerability types. We evaluate the performance of \\sys{}'s multi-output DNN model with F1 score, precision, and recall. \nIn addition, we calculate two of the most common performance metrics, hamming loss, and Jaccard similarity~\\cite{book:MML}.  \nWe detail each metric as follows. \n\n\\subsubsection{Base Values}\nThe results of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) are the base values to compute other metrics. \nThe true values represent the number of correctly predicted results, which can be either true positive or true negative. \nThe false values indicate that the DL model gives the wrong outputs~\\cite{deep-learning-glossary}. \n\n\\vspace{0.1em}\n\\subsubsection{Precision and Recall}\nThe precision metric describes the ratio of truly positive values to all positive predictions. \n\nThis indicates the reliability of the classifier's positive prediction~\\cite{deep-learning-metrics}. \nThe recall (or sensitivity) metric shows the proportion of actual positives that are correctly classified.  \nThe formulas to compute these two metrics are given below:\n\n \\resizebox{.96\\linewidth}{!}{\n   \\begin{minipage}{\\linewidth}\n   \\begin{align}\n   \\label{eq:precision_recall}\n     Precision = \\frac{TP}{TP + FP},~Recall = \\frac{TP}{TP + FN}. \n   \\end{align}\n   \\end{minipage}\n }\n\n\\vspace{0.1em}\n\\subsubsection{F1 Score}\nThe F1 score metric is commonly used in information retrieval and it quantifies the overall decision accuracy using precision and recall.  \nThe F1 score is defined as the \\textit{harmonic mean} of the precision and recall:\n\n\\resizebox{.96\\linewidth}{!}{\n   \\begin{minipage}{\\linewidth}\n   \\begin{align}\n   \\label{eq:f1_score}\n      F1\\_score = \\frac{2 * Precision * Recall}{Precision + Recall}. \n   \\end{align}\n  \\vspace{0.03em}\n   \\end{minipage}\n}\nThe best and the worst value of the F1 score is 1 and 0, respectively. The F1 score can be calculated for each class label or globally~\\cite{sklearn}. In our evaluation, we use the weighted F1 score where the per-class F1 scores are weighted by the number of samples from that class~\\cite{metric_web}.\n \n\\subsubsection{Jaccard Similarity} In multi-label classification, Jaccard similarity (Jaccard index) is defined as the size of the intersection divided by the size of the union of two label sets. It is used to compare the set of predicted labels for a sample to the corresponding set of true labels. It ranges from 0 to 1 where 1 is the perfect score. The Jaccard similarity does not consider the correct classification of negatives~\\cite{deep-learning-metrics} and can be computed as follows: \\\\\n\n \\resizebox{.96\\linewidth}{!}{\n   \\begin{minipage}{\\linewidth}\n   \\begin{align}\n   \\label{eq:jaccard}\n      Jaccard\\_Similarity = \\frac{TP}{TP + FP + FN}.\n   \\end{align}\n   \\end{minipage}\n }\n\n\\vspace{0.1em}\n\\subsubsection{Hamming Loss}\nThe Hamming loss gives the percentage of wrong labels to the total number of labels. A lower hamming loss indicates the better performance of a model. For an ideal classifier, the hamming loss is 0. In multi-label classification, the hamming loss is defined as the \\textit{hamming distance}~\\cite{norouzi2012hamming} between the ground-truth label $y$ and the prediction value $\\hat{y}$: \\\\ \n\\resizebox{.96\\linewidth}{!}{\n  \\begin{minipage}{\\linewidth}\n  \\begin{align}\n  \\label{eq:hamming}\n     \\mathcal{L}_{Hamming} = \\frac{\\#Mismatch(y,~\\hat{y})}{Length(y)}.\n  \\end{align}\n  \\vspace{0.05em}\n  \\end{minipage}\n}\n\n\\noindent where $Length(y)$ is the total number of vulnerability types.\n\n\\vspace{0.1em}\n\\subsubsection{DNN Loss Function}\nThe loss function is a crucial part of DNN training since the training process aims to minimize the loss for obtaining a high task accuracy. \nAs such, the loss value quantifies how well a classifier performs on the given dataset. In our experiments, we use \\textit{Binary Cross-Entropy} (BCE) loss to train \\sys{}'s multi-output DNN model. Given the expected value $y$ and the prediction $\\hat{y}$, the BCE loss is computed as:  \\\\\n \\resizebox{.96\\linewidth}{!}{\n   \\begin{minipage}{\\linewidth}\n   \\begin{align}\n   \\label{eq:bce_loss}\n      \\mathcal{L}_{BCE}(y, \\hat{y}) = -(y log(\\hat{y}) + (1 - y) log (1 - \\hat{y})). \n   \\end{align}\n   \\end{minipage}\n }\n\n\\subsection{Experimental Setup}\n\\label{sec:evaluation:setup}\nAll of our experiments are conducted on a machine with Arch Linux OS having AMD Ryzen 3 3200G and NVIDIA GeForce RTX 3090 GPU with 32 and 24 GB of RAM, respectively. The software versions are as follows: Tensorflow 2.3.1, CUDA 11.1, NVIDIA driver 455.38, cuDNN 8.0.5.39-1, and kernel 5.4.77-1.\n\n\\vspace{-0.3em}\n\\subsection{Evaluation Results}\n\\label{sec:evaluation:results}\n\\subsubsection{Classifier Learning}\nWe train \\sys{}'s model on the training set with hyper-parameters listed in Table~\\ref{tab:model_param} and assess it on the test set {(consisting of $18.700$ contracts)}.\nTo corroborate the detection effectiveness of \\sys{}, we plot the learning curves of our multi-output DNN \nin Figure~\\ref{fig:metrics-training-part1}. \nThe training and the validation curves demonstrate the \\textit{time-evolving} performance of \\sys{} for supervised learning and the \\textit{generalization} capability of the model, respectively. \nThe learning curves show that our DNN model can achieve an average F1 score higher than $95\\%$ on both the training and validation set.  \n\n\\begin{figure}[h]\n  \\centering\n    \\subfloat[\\sys{}'s BCE loss on training and validation set.]{\n     \\label{figur:metrics-training:loss}\n     \\includegraphics[width=0.68\\columnwidth]{loss.png}\n  }\n  \n  \\vspace{-0.8em}\n  \\subfloat[\\sys{}'s F1 score on training and validation set.]{\n     \\label{figur:metrics-training:f1}\n     \\includegraphics[width=0.68\\columnwidth]{f1.png}\n  }\n  \\vspace{-0.5em}\n  \\caption{The model learning process of \\sys{}. \n  }\n  \\label{fig:metrics-training-part1}\n\\end{figure}\n\n\\vspace{0.8em}\n\\subsubsection{Sensitivity to Training Configurations}  \n\\sys{}'s training pipeline is described in Section~\\ref{sec:implementation:dl}.\nWe use the MOL-DNN architecture in Figure~\\ref{fig:implementation:mol-gru} with six vulnerability branches in \\sys{}'s training phase. \nThis model has a total number of $115,846$ learnable parameters.\nWe investigate whether the detection performance of \\sys{} can be improved by increasing the number of global and local epochs.\nTo characterize \\sys{}'s performance, we compute the metrics defined in Section~\\ref{sec:evaluation:metrics} and summarize the results in Table~\\ref{tab:differentiterationepoch}. \nIt can be seen that \\sys{}'s accuracy has a slight increase with a longer training time. Since the accuracy improvement is minor w.r.t. the large increase of training time, we use the first configuration (G\\_{Ep}=1, L\\_{Ep}=1) as our default setting for the rest of our evaluations.\n\n\\begin{table}[ht!]\n\t\\centering\n\t\\scalebox{0.95}{\n\\begin{tabular}{|l|l|l|l|l|l|}\n\\hline\n\\multicolumn{2}{|l|}{\\thead{Metrics (Avg.)}}               & \\thead{G\\_Ep.:1 \\\\ L\\_Ep.:1} & \\thead{G\\_Ep.:1 \\\\ L\\_Ep.:3} & \\thead{G\\_Ep.:3 \\\\ L\\_Ep.:1} & \\thead{G\\_Ep.:3 \\\\ L\\_Ep.:3} \\\\ \\hline\n\\multirow{6}{*}{\\rotatebox[origin=c]{90}{Training}} & Loss &            0.06              &         0.05                 &          0.06                &     0.05     \\\\ \\cline{2-6} \n                          & Precision                      &            0.99              &         1.00                 &          0.99                &     0.97     \\\\ \\cline{2-6} \n                          & Recall                         &            0.91              &         0.90                 &          0.90                &     0.95     \\\\ \\cline{2-6} \n                          & F1 score                       &            0.95              &         0.95                 &          0.94                &     0.96     \\\\ \\cline{2-6} \n                          & Hamming Loss                   &            0.02              &         0.02                 &          0.02                &     0.01     \\\\ \\cline{2-6} \n                          & Jaccard Similarity             &            0.90              &         0.90                 &          0.89                &     0.92     \\\\ \\hline\n\\multirow{6}{*}{\\rotatebox[origin=c]{90}{Test}}     & Loss &            0.06              &         0.05                 &          0.05                &     0.05     \\\\ \\cline{2-6} \n                          & Precision                      &            0.98              &         0.99                 &          0.99                &     0.97     \\\\ \\cline{2-6} \n                          & Recall                         &            0.90              &         0.91                 &          0.91                &     0.95     \\\\ \\cline{2-6} \n                          & F1 score                       &            0.95              &         0.95                 &          0.95                &     0.96     \\\\ \\cline{2-6} \n                          & Hamming Loss                   &            0.02              &         0.02                 &          0.02                &     0.01     \\\\ \\cline{2-6} \n                          & Jaccard Similarity             &            0.90              &         0.90                 &          0.90                &     0.92     \\\\ \\hline\n\\multirow{2}{*}{\\rotatebox[origin=c]{90}{Time}} & Training (H:M)   &   5:44              &        17:11                 &         17:40                &    49:41     \\\\ \\cline{2-6} \n                          & Prediction (Sec.)               &            0.02              &         0.02                 &          0.02                &     0.02     \\\\ \\hline\n\\end{tabular}\n}\n\\vspace{2em}\n\\caption{The averaged performance of our multi-label classification model across initial vulnerability types (cl. 1-6) with different G\\_Ep. and L\\_Ep. configurations.\n}\n\\label{tab:differentiterationepoch}\n\\end{table}\n\n\\subsubsection{Class-wise Detection Performance} \nWe describe \\sys{}'s overall performance on the vulnerability types introduced in Section~\\ref{sec:evaluation:dataset}. \nHere, we provide a fine-grained insight into \\sys{}'s capability on each vulnerability class. \nTable~\\ref{tab:class-metrics} shows the class-specific metrics obtained by our MOL-DNN model. \n\\sys{} achieves an average of $97\\%$ precision and $95\\%$ F1 score across all six vulnerability types. \n{In the case of the Accessible selfdestruct vulnerability (cl. 4), \\sys{}'s recall score is relatively lower than others. The low recall value indicates that \\sys{} yields more false negatives on this vulnerability class according to Equation~(\\ref{eq:precision_recall})}.\n\n\\begin{table}[ht!]\n\t\\centering\n\t\\scalebox{0.95}{\n\\begin{tabular}{|l|l|l|l|l|l|l|l|l|}\n\\hline\n\\multirow{2}{*}{\\thead{Metrics}} & \\multicolumn{6}{l|}{ \\thead{Initial vulnerability types}} & \\multicolumn{2}{l|}{\\begin{tabular}[c]{@{}l@{}} \\thead{New Vuln.\\\\ Classes}\\end{tabular}} \\\\ \\cline{2-9} \n                    & cl. 1     & cl. 2     & cl. 3     & cl. 4   & cl. 5   &  cl. 6   &cl. 7  & cl. 8  \\\\ \\hline\nLoss                &   0.08    &   0.05    &   0.07    &  0.09   &  0.01   &   0.09   & 0.14  &  0.08  \\\\ \\hline\nPrecision           &   0.99    &   0.97    &   0.99    &  0.99   &  1.00   &   0.98   & 0.95  &  0.98  \\\\ \\hline\nRecall              &   0.88    &   0.96    &   0.91    &  0.85   &  0.99   &   0.88   & 0.90  &  0.90  \\\\ \\hline\nF1 score            &   0.93    &   0.96    &   0.95    &  0.91   &  0.99   &   0.93   & 0.92  &  0.93  \\\\ \\hline\nFPR                 &   0.00    &   0.01    &   0.00    &  0.00   &  0.00   &   0.00   & 0.02  &  0.00  \\\\ \\hline\nFNR                 &   0.12    &   0.06    &   0.10    &  0.15   &  0.01   &   0.12   & 0.10  &  0.10  \\\\ \\hline\n\\end{tabular}\n}\n\\vspace{2em}\n   \\caption{Class-specific metrics (for unseen/test data) retrieved by our multi-output model for initial training phase (cl. 1-6) and after transfer learning phase (cl. 7-8). %\\textcolor{red}{need to update FNR.}\n   }   \\label{tab:class-metrics}\n\\end{table}\n\n\\subsection{Extensibility/Generalizability Performance}\n\nTo corroborate the extensibility of \\sys{}, we first train a MOL-DNN model on six vulnerability types (cl. 1-6), and then perform transfer learning on the remaining two vulnerability types (cl. 7-8). The details of the transfer learning procedures can be found in Section~\\ref{sec:transfer}. \nThe two newly added branches (for cl. 7-8) have in total $33,282$ trainable parameters. For transfer learning, we used the same hyper-parameters listed in Table~\\ref{tab:model_param} and trained the model on vulnerability types 7 and 8 simultaneously.\nThis process takes only $2$ hours and $43$ minutes, which is $47.39\\%$ of the time used by model training with six vulnerabilities. \nThe detection result on the new vulnerability types are shown in the last two columns of Table~\\ref{tab:class-metrics}.\nIt can be seen that \\sys{} achieves $92\\%$ and $93\\%$ F1 score on the two new vulnerabilities cl. 7 and cl. 8, respectively. \nThe empirical results corroborate that \\sys{} is extensible to new attacks by enabling lightweight and effective transfer learning.\n\n\\textcolor{magenta}{We also demonstrate the superior efficiency and effectiveness of \\sys{}'s innovative multi-output architecture compared to the existing ML-based detection techniques. \nIn this comparison experiment, we define a regular RNN consisting of the three top layers and two branches shown in Figure~\\ref{fig:implementation:mol-gru} as the baseline model. This new model is trained \\textit{from scratch} on the two new vulnerability types. For \\sys{}, we use the pre-trained feature extractor obtained from the main training stage and append two new branches of layers to it. As we explain in Section~\\ref{sec:transfer}, only the parameters in the new vulnerability branches are trained during transfer learning.}\n\n\\textcolor{magenta}{Note that the size of the transfer learning dataset is considerably smaller than the data size in the main training phase since the new smart contracts are collected in a shorted time period. The limited training data raises concerns about model \\textit{under-fitting} if the amount of trainable parameters is too large. We show the empirical comparison results in Table~\\ref{tab:tl_comparison} when adapting the ML model to the new vulnerability types (cl. 7 and cl. 8). It can be seen that \\sys{} reduces the training time by $\\sim 43\\%$ while yielding a similar F1 score compared to the baseline. The advantage of \\sys{} is derived from our multi-output RNN design which decomposed the contract vulnerability problem into two sub-tasks: contract representation learning (performed by feature extractor), and vulnerability pattern identification (performed by each branch). As such, when extending the ML-based detector to new vulnerability types, \\sys{} can focus on distinguishing the new vulnerability pattern without \\textit{`re-learning'} the contract representation.}\n\n\\vspace{-0.3em}\n\\begin{table}[ht!]\n\\centering\n\\scalebox{0.96}{\n\\begin{tabular}{|c|c|c|c|c|}\n\\hline\n\\textbf{\\begin{tabular}[c]{@{}c@{}}Transfer \\\\ Learning\\end{tabular}} & \\textbf{FPR} & \\textbf{FNR} & \\textbf{F1 score} &  \\textbf{\\begin{tabular}[c]{@{}c@{}}Training Time \\\\ (H:M)\\end{tabular}} \\\\ \\hline\nESCORT & 0.02 & 0.10 & 0.93 & 2:43 \\\\ \\hline\nBaseline & 0.01 & 0.10 & 0.94 & 4:46 \\\\ \\hline\n\\end{tabular}\n}\n\\vspace{1.8em}\n\\caption{Performance comparison of transfer learning between \\sys{} and baseline (training-from-scratch). \\label{tab:tl_comparison}}\n\\end{table}\n\\vspace{-2.3em}\n\\section{Related Work} \n\\label{sec:related}\nVarious vulnerability inspection tools have been developed for smart contracts to ensure the security of the cryptocurrency system. We categorize the existing detection techniques based on their working mechanism and discuss each type below. \n\n\\subsection{Static Vulnerability Detection Methods}\n\\label{sec:related:static}\nStatic detection techniques analyze the smart contract in a static environment by examining its source code or bytecode. \n\n\\subsubsection{Information Flow Analysis-based}\n{Slither}~\\cite{feist2019slither} uses \\textit{taint analysis}~\\cite{tripp2009taj} to detect vulnerabilities in Solidity source code. \nIt can find nearly all vulnerabilities related to the user inputs or critical data flows while the inspection time might be prohibitively long.\n{Dedaub's Contract-Library} by Dedaub~\\cite{rw_dedaub_contract_library_page} provides multiple different features via an online API. It collects bytecode of the smart contracts and performs vulnerability classifications using tool MadMax~\\cite{rw_dedaub_mad_max_paper} that performs flow and loop analysis to detect gas-focused vulnerabilities~\\cite{brent2020ethainter}. \n\n\\subsubsection{Symbolic Execution-based}\n{Oyente}~\\cite{ethereum-background-03} detects vulnerabilities in the source code or bytecode of Solidity contracts using \\textit{symbolic execution}. \nSymbolic execution represents the program's behavior as built formula and uses symbolic inputs to decide if a certain path can be reached~\\cite{king1976symbolic}.\nAs such, its performance depends on the number of explored paths and the program's complexity~\\cite{rw_tech_01, rw_tech_02}. \nOyente constructs the control flow graph of the contract and uses it to create inputs for symbolic execution. \n{Manticore}~\\cite{rw_manticore_paper} analyzes the contract by repeatedly executing symbolic transactions against the bytecode, tracking the discovered states, and verifying code invariants~\\cite{rw_manticore_repo}.\n{Securify}~\\cite{rw_securify_paper}\nfirst obtains the contract's semantic information by performing symbolic analysis of the dependency graph, then checks the predefined compliance and violation patterns for vulnerability detection. \nteEther~\\cite{teether} searches for certain critical paths in the control flow graph of the smart contract and uses symbolic execution for vulnerability identification. \n\n\\subsubsection{Logic Rules-based}\nVandal~\\cite{brent2018vandal} is a logic-driven static program analysis framework.  \nIt converts the low-level EVM bytecode to semantic logic relations and describes the security analysis problems with logic rules. The datalog engine executes the specifications for input relations and outputs the vulnerabilities. % and locations in bytecode. \n{eThor}~\\cite{ethor} is a static analysis technique built on top of reachability analysis achieved by Horn clause resolution.  \n{NeuCheck}~\\cite{NeuCheck} adopts a syntax tree in a syntactical analyzer to transform source code of smart contracts to an intermediate representation (IR). Vulnerabilities are identified by searching for detection patterns in the syntax tree. \n{SmartCheck}~\\cite{smartcheck} converts the Solidity source code to XML-based IR and verifies it against detection patterns defined in XPath language~\\cite{xpath}. \n\n\\subsubsection{Composite Methods-based}\nMythril~\\cite{rw_mythx_article} combines multiple vulnerability detection approaches, including symbolic execution, taint analysis, and Satisfiability Modulo Theories (SMT). SMT solving converts the contract to SMT constraints to reveal program flaws. \n{Zeus}~\\cite{zeus} uses symbolic model checking, abstract interpretation, and constrained horn clauses to verify contracts' security. \n{Osiris}~\\cite{osiris} combines symbolic execution and taint analysis to precisely identify integer bugs in smart contracts. \n\n\\subsection{Dynamic Vulnerability Detection Methods}\n\\label{sec:related:dynamic}\nDynamic testing techniques execute the program and observe its behaviors to determine the vulnerability's existence. \n\n\\subsubsection{Fuzzing-based} {MythX}~\\cite{rw_mythx_page} \ncombines synthetic execution and \\textit{code fuzzing}. It provides a cloud-based API for developers to inspect smart contracts.\nFuzzing~\\cite{godefroid2012sage} is a testing method that attempts to expose the vulnerabilities by executing the program with invalid, unexpected, or random inputs. The brute-force nature determines that fuzzing incurs large runtime overhead and might have poor code coverage due to its dependency on the inputs~\\cite{rw_tech_02}.\n{ReGuard}~\\cite{ethereum-background-05} is another fuzzing tool specialized in the Reentrancy bug. It creates an IR for the smart contract. A fuzzing engine is used to generate random byte inputs and analyze the execution traces for reentrancy bugs detection.  \n{ContractFuzzer}~\\cite{contractfuzzer} generates fuzzing inputs based on the ABI specifications of smart contracts. Test oracles are defined to monitor and analyze the contract's runtime behaviors for vulnerability detection. \n{Echidna}~\\cite{echidna} is a fuzzer that generates random tests to detect violations in assertions and custom properties. \n{ILF}~\\cite{ilf} uses symbolic execution to generate contract inputs and employs imitation learning to design a neural network-based fuzzer from symbolic execution.\n{sFuzz}~\\cite{nguyen2020sfuzz} is an adaptive fuzzer for smart contracts that combines the AFL fuzzer and multi-objective strategy to explore hard-to-cover branches. \n{Harvey}~\\cite{wustholz2020harvey} is a greybox fuzzer that predicts new inputs to cover new paths and fuzzes the transaction sequence in a demand-driven manner. \n\n\\subsubsection{Validation-based}  ContractLarva~\\cite{rw_contractlarva_paper} is a runtime verification tool for smart contracts where a violation of defined properties can lead to various handling strategies, such as a system stop. These properties can include undesired event traces of control or data flow. \nMaian~\\cite{rw_maian_paper,rw_maian_repo} combines symbolic analysis and concrete validation to inspect the smart contract's bytecode. In concrete validation, the contract is executed on a fork of Ethereum for tracing and validation. By passing symbolic inputs to the contract, the execution trace is analyzed to identify the vulnerabilities.\nSereum~\\cite{rodler2018sereum} uses runtime monitoring and verification to protect existing smart contracts against reentrancy attacks without modifications or semantic knowledge of the contracts. \nIt detects inconsistent states in the contract via dynamic taint tracking and data flow monitoring during contract execution. %, thus preventing reentrancy attacks. \n\n\\vspace{-1.2em}\n\\subsection{Machine Learning for Vulnerability Detection}\nSeveral works have attempted to perform automated contract scanning using machine learning techniques. We discuss their working mechanisms and limitations below.\n\n\\vspace{0.2em}\n\\textbf{ContractWard.}\nContractWard detects smart contracts vulnerability in the \\textit{opcode-level} by extracting \\textit{bigram} features from the simplified opcode and training individual binary ML classifiers for each vulnerability class~\\cite{rw_contractward}. The paper targets six vulnerabilities and experiments with Random Forests, K-Nearest Neighbors, SVM, AdaBoost, and XGBoost classifiers. \n\nCompare to our work, ContractWard has three main limitations:\n\\textit{(i) Requires source code of smart contracts}. This approach analyzes smart contracts with opcodes. To do so, it decompiles source codes and converts them to opcodes. It is worth mentioning that decompilation might result in information loss. \\textit{(ii) Not extensible to new exploitation attacks}. This paper uses `One vs. Rest' algorithms and designs separate ML models to detect each vulnerability class. This means that supporting a new vulnerability class requires training a new ML model from scratch, which is costly.  \n\\textit{(iii) Not scalable to long contracts}. The \\textit{bigram} language model has a short window size in the Markov chain model. This determines that ContractWard is not scalable to long contracts and cannot capture long-term dependency in the code. However, using an n-gram model with a larger window size increases the feature size, thus complicating model training due to the high dimensionality of data.\n\n\\vspace{0.2em}\n\\textbf{LSTM-based.}\nThe paper~\\cite{rw_lstm} proposes a sequence learning approach to detect weakness in the opcode of smart contracts. \nParticularly, this paper uses one-hot encoding and an embedding matrix to represent the contract's opcode. \nThe obtained code vectors are used as input to train an LSTM model for determining whether the given smart contract is safe or vulnerable (i.e., binary classification). \n\nThe LSTM-based scheme yields limited detection performance since: (i) The reported F1 score of $86\\%$ is relatively low. We hypothesize that this might be because different vulnerability types have diverse behaviors, thus making it hard to distinguish the group of multiple vulnerabilities from the safe contracts. (ii) The LSTM model only provides a binary decision about contract security without distinguishing vulnerability types.\n\n\\textbf{AWD-LSTM based.} A sequence-based multi-class classification scheme is presented in~\\cite{gogineni2020multi}. This paper adapts `Average Stochastic Gradient Descent Weighted Dropped LSTM' (AWD-LSTM)~\\cite{merity2017regularizing} for vulnerability detection. \nThe proposed model consists of two parts: a pre-trained encoder for language tasks~\\cite{howard2018universal}, and an LSTM-based classifier for vulnerability classification. \nThis method works on the opcode-level and can detect three vulnerability types. \n\nCompared to \\sys{}, the AWD-LSTM based detection method has the following constraints: \\textit{(i) Non-uniform effectiveness.} The multi-class detection performance of~\\cite{gogineni2020multi} is not uniformly effective across different vulnerabilities. In particular,~\\cite{gogineni2020multi} yields an F1 score of $95\\%$ on safe contracts and $30\\%$ on Prodigal contracts~\\cite{nikolic2018finding}. \\sys{} features a much smaller performance divergence across different classes as can be seen from Table~\\ref{tab:class-metrics}. \\textit{(ii) Not extensible.} The AWD-LSTM based model in~\\cite{gogineni2020multi} is a fixed design to detect pre-specified vulnerability types. The extension to incorporate new attacks is not considered in~\\cite{gogineni2020multi}.\n\n\\vspace{0.1em}\n\\textbf{CNN-based.} \nThe paper~\\cite{huang2018hunting} transforms the contract bytecode into fix-sized RGB color images and trains a convolution neural network for vulnerability detection. \n\nSimilarly to \\sys{}, CNN-based classifier uses multi-label classification, which has a low confidence score when determining the exact vulnerability types. %The inspection time of a single contract is $1.5$ seconds.} \n\nCompare to our work, the CNN-based detection scheme has the following limitations: (i) The multi-label classification performance is not satisfying due to its low confidence level. We hypothesize that this is because image representation of the bytecode and the CNN architecture ignore the sequential information existing in the contract. (ii) The extensibility/generalization ability of the CNN-based detection method is neither discussed nor evaluated. \n\n\\textbf{GNN-based.} The paper~\\cite{zhuangsmart} proposes a graph neural network (GNN)-based approach. In particular, this work builds a `contract graph' from the contract's source code where nodes and edges represent critical function calls/variables and temporal execution trace, respectively. This graph is normalized to highlight important nodes and passed to a temporal message propagation (TMP) network for vulnerability detection. \n\nWhile supporting multi-class detection, the GNN-based method has the following drawbacks: \\textit{(i) Restricted applicability.} The paper~\\cite{zhuangsmart} requires to build a graph from the contract's source code. However, the source code is typically hard to obtain from the public blockchain. \\sys{} operates on the contract bytecode which is publicly available from the EVM, thus can be deployed in more scenarios. \\textit{(ii) Limited effectiveness.} The GNN-based technique yields an average F1 score of $77\\%$ across all three vulnerabilities. We hypothesis that the graph normalization process in~\\cite{zhuangsmart} does not preserve the malicious nodes responsible for vulnerability exploitation, leading to the low F1 score. \\vspace{-0.7em}\n\\section{Conclusion}\n\\label{sec:conclusion}\n\nTo ensure the safety of the Ethereum cryptocurrency system,  \nwe present \\sys{}, the first deep learning-based automated framework that supports concurrent detection of multiple vulnerability classes and lightweight transfer learning. \nWe identify two key components of vulnerability detection: feature extraction of general smart contracts and each particular vulnerability class, and disentangle these two subtasks.\n\\sys{}'s multi-output RNN design is highly modular, scalable, efficient, and extensible as opposed to the previous works.\nEmpirical results show that \\sys{} achieves an average of $95\\%$ detection accuracy in terms of F1 score across various vulnerability classes and can be quickly adapted on the new vulnerability data. Given an unknown smart contract, \\sys{} can provide parallel detection of eight vulnerabilities in $0.02$ second.\nAs a separate contribution, we devise \\datatool{}, a toolchain for dataset construction and labeling based on smart contracts' bytecode downloaded from Ethereum blockchain and existing vulnerability detection tools.\nWe will open source\n\\datatool{} toolchain and our dataset to promote research in this area.\n\\clearpage\n\n\\end{document}\n</paper 1>\n\n<paper 2>\n\\title{Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection}\n\n\\begin{document}\n\n\\title{Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection}\n\n\\author{Zhenguang~Liu, %~\\IEEEmembership{Member,~IEEE,}\n        Peng~Qian, Xiaoyang Wang, Yuan~Zhuang, Lin~Qiu, and Xun~Wang \n       \n\\IEEEcompsocitemizethanks{\n\\IEEEcompsocthanksitem Zhenguang Liu, Peng Qian are with School of Computer and Information Engineering, Zhejiang Gongshang University and Zhejiang University, China. Email: liuzhenguang2008@gmail.com, messi.qp711@gmail.com\n\\IEEEcompsocthanksitem Yuan Zhuang is with National University of Singapore, Singapore.\n\\IEEEcompsocthanksitem Xiaoyang Wang is with School of Computer and Information Engineering, Zhejiang Gongshang University, China.\n\\IEEEcompsocthanksitem Lin Qiu is with Southern University of Science and Technology, China.\n\\IEEEcompsocthanksitem Xun Wang is with School of Computer and Information Engineering, Zhejiang Gongshang University and Zhejiang Lab, China. Email: xwang@zjgsu.edu.cn.\n}\n\\thanks{Corresponding authors: Peng Qian, Xun Wang}\n}\n\\markboth{IEEE Transactions on Knowledge and Data Engineering}\n{Liu \\MakeLowercase{\\textit{et al.}}: Combining Expert Knowledge with Graph Neural Networks for Smart Contract Vulnerability Detection}\n\n\\IEEEtitleabstractindextext{\n\\begin{abstract}\nSmart contract vulnerability detection draws extensive attention in recent years due to the substantial losses caused by hacker attacks. Existing efforts for contract security analysis heavily rely on rigid rules defined by experts, which are \\emph{labor-intensive} and \\emph{non-scalable}. More importantly, expert-defined rules tend to be \\emph{error-prone} and suffer the inherent risk of being cheated by crafty attackers. Recent researches focus on the symbolic execution and formal analysis of smart contracts for vulnerability detection, yet to achieve a precise and scalable solution. Although several methods have been proposed to detect vulnerabilities in smart contracts, there is still a lack of effort that considers combining expert-defined security patterns with deep neural networks.\n\n\\quad In this paper, we explore using graph neural networks and expert knowledge for smart contract vulnerability detection. Specifically, we cast the rich control- and data- flow semantics of the source code into a \\emph{contract graph}. To highlight the critical nodes in the graph, we further design a node elimination phase to normalize the graph. Then, we propose a novel temporal message propagation network to extract the graph feature from the normalized graph, and combine the graph feature with designed expert patterns to yield a final detection system. Extensive experiments are conducted on all the smart contracts that have source code in Ethereum and VNT Chain platforms. Empirical results show significant accuracy improvements over the state-of-the-art methods on three types of vulnerabilities, where the detection accuracy of our method reaches {89.15\\%, 89.02\\%, and 83.21\\%} for reentrancy, timestamp dependence, and infinite loop vulnerabilities, respectively.\n\\end{abstract}\n\n\\begin{IEEEkeywords}\nDeep learning, blockchain, smart contract, vulnerability detection, expert knowledge\n\\end{IEEEkeywords}\n}\n\n\\maketitle\n\n\\IEEEdisplaynontitleabstractindextext\n\\IEEEpeerreviewmaketitle\n\\IEEEraisesectionheading{\n\\section{Introduction}\n\\label{sec:introduction}}\n\\IEEEPARstart{B}lockchain and its killer applications, \\emph{e.g., Bitcoin and smart contract}, are taking the world by storm \\cite{blockbench,Yaga,bitcoin,Dhawan,tsikhanovich2019pd,dinh2018untangling}. A blockchain is essentially a distributed and shared transaction ledger, maintained by all the miners in the blockchain network following a consensus protocol \\cite{consensus}. The consensus protocol and replicated ledgers enforce all the transactions immutable once recorded on the chain, endowing blockchain with  decentralization and tamper-free nature.\n\n\\textbf{Smart contract.} Smart contracts are programs running on top of the blockchain \\cite{Dhawan,oyente}. A smart contract can implement arbitrary rules for managing assets by encoding the rules into source code. The defined rules of a contract will be strictly and automatically followed during execution, effectuating the `code is law' logic. Smart contracts make the automatic execution of contract terms possible, facilitating complex decentralized applications (DApps). Indeed, many DApps are basically composed of several smart contracts as the backend and a user interface as the frontend \\cite{dapps}.\n\nMillions of smart contracts have been deployed in various blockchain platforms, enabling a wide range of applications including wallets \\cite{wallet}, crowdfunding, decentralized gambling \\cite{decentralized}, and cross-industry finance \\cite{industry}. The number of smart contracts is still growing rapidly. For example, within the last six months, over 15,000 new contracts were deployed on Ethereum alone, which is the most famous smart contract platform. \n\n\\textbf{Security issues of smart contracts.} Smart contracts from various fields now hold more than 10 billion dollars worth of virtual coins. Undoubtedly, holding so much wealth makes smart contracts attractive enough to attackers. In June 2016, attackers exploited the reentrancy vulnerability of the DAO contract \\cite{DAO} to steal 3.6 million Ether, which was worth 60 million US Dollars. This case is not isolated and several security vulnerabilities are discovered and exploited every few months \\cite{DAO,King,Multisig}, undermining the trust for smart contract-based applications.\n\nThere are several reasons that make smart contracts particularly prone to errors. \\emph{First}, the programming languages (\\emph{e.g., Solidity}) and tools are still new and crude, leaving plenty of rooms for bugs and misunderstandings in the tools \\cite{oyente,smartcheck}. \\emph{Second}, since smart contracts are immutable once deployed, developers are required to anticipate all possible status and environments the contract may encounter in the future, which is undoubtedly difficult. Distinct from conventional distributed applications that can be updated when bugs are detected, there is no way to patch the bugs of a smart contract without forking the blockchain (almost an impossible task), regardless of how much money the contract holds or how popular it is \\cite{oyente}. Therefore, effective vulnerability checkers for smart contracts before their deployment are essential.\n\n\\textbf{Drawbacks of conventional methods.} Conventional methods for smart contract vulnerability detection, \\emph{such as} \\cite{oyente,smartcheck,contractfuzzer,securify}, employ classical static analysis or dynamic execution techniques to identify vulnerabilities. Unfortunately, they fundamentally rely on several expert-defined patterns. The manually defined patterns bear the inherent risk of being \\emph{error-prone} and some complex patterns are \\emph{non-trivial} to be covered. Crudely using several rigid patterns leads to high \\emph{false-positive} and \\emph{false-negative} rates, and crafty attackers may easily bypass the pattern checking using tricks. Moreover, as the number of smart contracts increases rapidly, it is becoming impossible for a few experts to sift through all the contracts to design precise patterns. A feasible solution might be: ask each expert to label a number of contracts, then collect all the labeled contracts from many experts to train a model that can automatically give a prediction on whether a contract has a specific type of vulnerability. \n\nRecently, efforts have been made towards adopting deep neural networks for smart contract vulnerability detection \\cite{pengqian,ijcai,Wesley}, achieving improved accuracy. \\cite{pengqian} utilizes LSTM based networks to sequentially process source code, while \\cite{ijcai} models the source code into control flow graphs. \\cite{Wesley} builds a sequential model to analyze the Ethereum operation code. However, these approaches either treat the source code or operation code as a text sequence instead of semantic blocks, or fail to highlight critical variables in the data flow \\cite{ijcai}, leading to insufficient semantic modeling and unsatisfactory results. \n\nTo fill the research gap, in this paper, we investigate more than 300,000 smart contract functions and present a fully automated and scalable approach that can detect vulnerabilities at the function level. Specifically, we cast the rich control- and data- flow semantics of the source code into graphs. The nodes in the graph represent critical variables and function invocations, while directed edges capture their temporal execution traces. Since not all nodes in the graph are of equal importance and most graph neural networks are inherently flat during information propagation on the graph, we design a node elimination phase to normalize the graph and highlight the key nodes. The normalized graph is then fed into a temporal message propagation network to learn the \\emph{graph} feature. In the meantime, we extract the \\emph{security pattern} feature from the source code using expert knowledge. Finally, the \\emph{graph} feature and \\emph{security pattern} feature are incorporated to produce the final vulnerability detection results. \n\nWe conducted experiments on all the 40k contracts that have source code in Ethereum and on all the contracts in VNT Chain, demonstrating significant improvements over state-of-the-art vulnerability detection methods: F1 score from $78\\%$ to $86\\%$, $79\\%$ to $88\\%$, $74\\%$ to $82\\%$ for \\emph{reentrancy, timestamp dependence}, and \\emph{infinite loop} vulnerabilities, respectively. Our implementations\\footnote{Github: https://github.com/Messi-Q/GPSCVulDetector} are released to facilitate future research.\n\nWe would like to point out that this work is clearly distinct from the previous one \\cite{ijcai} in three ways: 1) this work is to investigate whether combining graph neural networks with conventional expert patterns could achieve better vulnerability detection results, while the objective of the previous work is to explore the possibility of using neural networks for smart contract vulnerability detection. 2) In this work, we propose to extract vulnerability-specific expert patterns and combine them with the graph feature. We also explicitly model the key variables in the data flow. In contrast, in the previous work, we only utilize the graph feature while ignoring expert patterns and key variables. 3) This work consistently outperforms the previous one across different vulnerabilities, and overall provides more insights and findings in this field. Note that in the previous paper, we proposed two neural networks, \\emph{DR-GCN} and \\emph{TMP}, to explore the applicability of different graph neural networks on smart contract vulnerability detection. In this paper, we focus on extending TMP, which delivers better performance than \\emph{DR-GCN}. We will also extend \\emph{DR-GCN} and compare it with the extension of TMP. \n \n\\textbf{Contributions.} To summarize, the key contributions are: \n\n\\begin{itemize} \n\\item\nTo the best of our knowledge, we are the first to investigate the idea of fusing conventional expert patterns and graph-neural-network extracted features for smart contract vulnerability detection. \n\\item We propose to characterize the contract function source code as contract graphs. We also explicitly normalize the graph to highlight key variables and invocations. A novel temporal message propagation network is proposed to automatically capture semantic graph features.  \n\\item Our methods set the new state-of-the-art performance on smart contract vulnerability detection, and overall provide insights into the challenges and opportunities. As a side contribution, we have released our implementations to facilitate future research.\n\\end{itemize}\n\n\\vspace{-0.7em}\n\\section{Related Work}\n\\label{related_work}\n\n\\subsection{Smart Contract Vulnerability Detection}\nSmart contract vulnerability detection is one of the fundamental problems in blockchain security. Early works on smart contract vulnerability detection verify smart contracts by employing formal methods \\cite{Bhargavan,Grishchenko,Hildenbrandt,Hirai}. For example, \\cite{Bhargavan} introduces a framework, translating \\emph{Solidity} code (the smart contract programming language of Ethereum) and the EVM (Ethereum Virtual Machine) bytecode into the input of an existing verification system. \\cite{Hirai} proposes a formal model for EVM and reasons the potential bugs in smart contracts by using the Isabelle/HOL tool. Further, \\cite{Grishchenko} and \\cite{Hildenbrandt} define formal semantics of the EVM using the F* framework and the $\\mathbb{K}$ framework, respectively. Although these frameworks provide strong formal verification guarantees, they are still semi-automated. \n\nAnother stream of work relies on generic testing and symbolic execution, such as Oyente \\cite{oyente}, Maian \\cite{Maian}, and Securify \\cite{securify}. Oyente is one of the pioneering works that perform symbolic execution on contract functions and flags bugs based on simple patterns. Zeus \\cite{zeus} leverages abstract interpretation and symbolic model checking, as well as the constrained horn clauses to detect vulnerabilities in smart contracts. \\cite{securify} introduces compliance (negative) and violation (positive) patterns to filter false warnings. \n\nResearchers also explore smart contract vulnerability detection using dynamic execution. \\cite{contractfuzzer} presents ContractFuzzer to identify vulnerabilities by fuzzing and runtime behavior monitoring during execution. Similarly, \\cite{reguard} develops a fuzzing-based analyzer to identify the reentrancy vulnerability. Sereum \\cite{sereum} uses taint analysis to monitor runtime data flows during smart contract execution for vulnerability detection. However, dynamic execution methods require a hand-crafted agent contract to interact with the contract under test, preventing them from fully-automated applications and endowing them non-scalability.  \n\nRecently, a few attempts have been made to study using deep neural networks for smart contract vulnerability detection. \\cite{pengqian} constructs the sequential \\emph{contract snippet} and feeds them into the BLSTM-ATT model to detect reentrancy bugs. \\cite{ijcai} proposes to convert the source code of a contract into the \\emph{contract graph} and constructs graph neural networks as the detection model. \\cite{wang2020contractward} proposes ContractWard, extracting bigram features from the operation code of smart contracts and utilizing machine learning algorithms. However, although a few methods have been proposed, the field of contract vulnerability detection using deep learning is still in its infancy and the accuracy is still unsatisfactory. For common smart contract vulnerabilities and attacks, motivated readers may refer to \\cite{Sok} for a comprehensive survey. \n\n\\vspace{-0.7em}\n\\subsection{Graph Neural Network}\nWith the remarkable success of neural networks, graph neural network has been investigated extensively in various fields such as graph classification \\cite{Zhang,wang2016incremental}, program analysis \\cite{devign,Miltiadis}, and graph embedding \\cite{cai2018comprehensive}. Existing approaches roughly cast into two categories: \\textbf{(i)} \\emph{Spectral-based approaches} generalize well-established neural networks like CNNs to work on graph-structured data. For instance, GCN \\cite{GCN} implements a first-order approximation of spectral graph convolutions \\cite{Defferrard,zhou2018graph,wei2019mmgcn} and develops a layer-wise propagation network using the Laplacian matrix, which achieves promising performance on graph node classification tasks. \\cite{adaptive} proposes a graph CNN which can take data of arbitrary graph structure as input. \\textbf{(ii)} \\emph{Spatial-based methods} inherit ideas from recurrent GNNs and adopt information propagation to define graph convolutions. Early work such as \\cite{Micheli} directly sums up the nodes' neighborhood information for graph convolutions. Another line of work, such as GAT \\cite{velivckovic2017graph} and GAAN \\cite{zhang2018gaan}, employs attention mechanisms to learn the weights of different neighboring nodes. Motivated by these spatial-based approaches, \\cite{gilmer2017neural} outlines a message-passing neural network framework to predict the chemical properties of molecules. \n\n\\begin{figure}\n    \\begin{center}\n     \\includegraphics[width=3.1in]{fig/BasicDAOAttack.pdf}\n    \\end{center}\n     \\vspace{-1.0em}\n \\caption{A simplified example of reentrancy vulnerability.}\n  \\label{fig_dao}\n  \\vspace{-1.5em}\n\\end{figure}\n\nRecently, \\cite{Miltiadis,xu2017neural,devign,shen2019neuro} attempt to apply GNNs to program analysis issues. Specifically, \\cite{Miltiadis} introduces a gated graph recurrent network for variable prediction, while \\cite{xu2017neural} proposes Gemini for binary code similarity detection, where functions in binary code are represented by attributed control flow graphs. \\cite{devign} develops Devign, a general graph neural network-based model for vulnerability identification in C programming language. Different from these methods, we focus on the specific smart contract vulnerability task, and explicitly take into account the distinct roles and temporal relationships of program elements.\n\n\\begin{figure*}\n    \\begin{center}\n     \\includegraphics[width=7.1in]{fig/framework.pdf}\n\\vspace{-1.0em}\n    \\end{center}\n \\caption{The overall architecture of our proposed method. (a) The expert pattern extraction phase; (b) the contract graph construction and normalization phase; (c) the vulnerability detection phase.} \n \\label{fig_framework}\n \\vspace{-1.6em}\n\\end{figure*}\n\n\\section{Problem Statement}\n\\label{sec_problem}\nIn this section, we first formulate the problem, then introduce the three types of vulnerabilities studied in this paper, and present the reasons for focusing on these three vulnerabilities.\n\n\\label{preliminaries} \n\\textbf{Problem formulation.} Given the source code of a smart contract, we are interested in developing a fully automated approach that can detect vulnerabilities at the function level. In other words, we are to estimate the label $\\hat{y}$ for each smart contract function $f$, where $\\hat{y}$ = 1 represents $f$ has a specific vulnerability while $\\hat{y} = 0$ denotes $f$ is safe. In this paper, we focus on three types of vulnerabilities, which will be presented below. Before that, we first introduce the preliminary knowledge of the fallback mechanism in smart contracts, which is important in understanding the problem.\n\n\\textbf{Fallback mechanism.} Within a smart contract, each function is uniquely identified by a signature, consisting of its name and parameter types \\cite{Sok}. Upon a function invocation, the signature of the invoked function is passed to the called contract. If the signature matches a function of the called contract, the execution jumps to the corresponding function. Otherwise, it jumps to the fallback function. Money transfer is considered as an empty signature, which will trigger the fallback function as well. The fallback function is a special function with no name and no argument, which can be arbitrarily programmed \\cite{Sok}. After introducing this background knowledge, we now are ready to elaborate on the three types of vulnerabilities.\n\n(1) \\textbf{Reentrancy} is a well-known vulnerability that caused the infamous DAO attack. When a smart contract function $f_1$ transfers money to a recipient contract $C$, the fallback function $f_2$ of $C$ will be automatically executed. In its fallback function $f_2$, $C$ may invoke back to $f_1$  for conducting an invalid second-time transfer. Since the current execution of $f_1$ waits for the first-time transfer to finish, $C$ can make use of the intermediate state of $f_1$ to succeed in stealing money. A simplified example is shown in Fig. \\ref{fig_dao}, where the \\emph{withdraw} function of contract \\emph{Bank} has a reentrancy vulnerability, contract \\emph{Attacker} steals money by exploiting the vulnerability. First, \\emph{Attacker} deposits 10 Ether (Ether is the virtual money of Ethereum) in contract \\emph{Bank} (step 1). Then, \\emph{Attacker} withdraws the 10 Ether by invoking the {\\emph{withdraw}} function (step 2). When the contract \\emph{Bank} sends 10 Ether to \\emph{Attacker} using \\textbf{\\emph{call.value}} (\\emph{Bank}, line 9), the fallback function (\\emph{Attacker}, lines 8--11) of \\emph{Attacker} will be automatically invoked (step 3). In its fallback function, \\emph{Attacker} calls \\textbf{\\emph{withdraw}} again (step 4). Since the {\\emph{userBalance}} of \\emph{Attacker} has not yet been set to 0 (\\emph{Bank}, line 10), \\emph{Bank} believes that \\emph{Attacker} still has {10 Ether} in the contract, thus transfers 10 Ether to \\emph{Attacker} again (Step 5). The withdraw loop lasts for 9 times ({\\small$count++ < 10$}, \\emph{Attacker} line 9). Finally, \\emph{Attacker} obtains much more Ether (100 Ether) than expected (10 Ether).\n\n(2) \\textbf{Timestamp dependence} vulnerability exists when a smart contract uses the block timestamp as a triggering condition to execute some critical operations, e.g., using the \\emph{timestamp} of a future block as the source to generate random numbers so as to determine the winner of a game. The miner (a node in the blockchain) who mines the block has the freedom to set the timestamp of the block within a short time interval ($<$ 900 seconds) \\cite{contractfuzzer}. Therefore, miners may manipulate the block timestamps to gain illegal benefits.\n\n(3) \\textbf{Infinite loop} is a common vulnerability in smart contracts. The program of a function may contain a loop (e.g. \\emph{for} loop, \\emph{while} loop, and self-invocation loop) with no exit condition or the exit condition cannot be reached, namely an infinite loop. \n\n\\textbf{Why focus on these vulnerabilities.} We mainly focus on the three aforementioned vulnerabilities since: \\textbf{(i)} In real attacks, blockchain networks have suffered more than 100 million USD losses due to the three vulnerabilities. For instance, attacks on reentrancy have caused one of the biggest losses (60 million USD in The Dao Event) in smart contract history. \\textbf{(ii)} We empirically found that the three vulnerabilities may affect a significant number of smart contracts and are non-trivial to be detected. Specifically, we surveyed 40,932 Ethereum smart contracts, observing that around 5,013 out of 307,396 functions  possess at least one invocation to \\emph{call.value}. Although possessing a \\emph{call.value} invocation does not necessarily mean that the contract has a reentrancy vulnerability, the contract has the potential to be affected by the \\emph{reentrancy} vulnerability and thus requires further checking. Similarly, around 4,833 functions have used \\emph{block.timestamp} and thus are potentially affected by the \\emph{timestamp dependence} vulnerability. Many functions have \\emph{for} or \\emph{while} loops, which may lead to the \\emph{infinite loop} vulnerability. In contrast, most other contract vulnerabilities affect a relatively smaller number of functions, \\emph{e.g.}, the \\emph{locked ether} vulnerability affects less than 900 functions, and the \\emph{integer overflow} vulnerability affects less than 1,000 functions. \n\n\\vspace{-0.7em}\n\\section{Our Method}\n\\label{our_method}\n\\textbf{Method overview.} The overall architecture of our proposed method is depicted in Fig. \\ref{fig_framework}, which consists of three phases: (1) a security pattern extraction phase, which obtains the vulnerability-specific expert patterns from the source code; (2) a contract graph construction and normalization phase, which extracts the control flow and data flow semantics from the source code and highlights the critical nodes; and (3) a vulnerability detection phase, which casts the normalized contract graph into graph feature using temporal graph neural network, and combines the pattern feature and graph feature to output the detection result. In what follows, we elaborate on the details of the three components one by one.\n\\begin{figure*}\n\t\\centering\n\t\\includegraphics[width=7.1in]{fig/node_elimination.pdf} \n\t\\caption{The contract graph construction and normalization phase. The first figure shows the source code of a contract function, while the second figure visualizes the contract graph extracted from the code. Nodes $\\bold{C_i}$ denote core nodes, nodes $\\bold{N_i}$ represent normal nodes, and node $\\bold{F}$ denotes fallback node. The third figure illustrates the temporal edges in the extracted graph, where the types of edges are detailed in Table \\ref{symbols}. The fourth figure demonstrates the graph after normalization.}\n\t\\label{fig:normalization}\n\t \\vspace{-1.6em}\n\\end{figure*}\n\n\\vspace{-0.7em}\n\\subsection{Expert Pattern Extraction}\n\\label{pattern_representation}\nIn this section, we summarize existing patterns and design new patterns for the three specific vulnerabilities respectively, and implement an open-sourced tool to automatically extract these patterns.\n\n\\textbf{Reentrancy.} Conventionally, the reentrancy vulnerability is considered as an invocation to \\emph{call.value} that can call back to itself through a chain of calls. That is, the invocation of \\emph{call.value} is successfully re-entered to perform the unexpected operation of repeated money transfer. By investigating existing works such as \\cite{oyente,contractfuzzer,zeus}, we design three sub-patterns. The first sub-pattern is \\textbf{callValueInvocation} that checks whether there exists an invocation to \\emph{call.value} in the function. The second sub-pattern \\textbf{balanceDeduction} checks whether the user balance is deducted \\emph{after} money transfer using \\emph{call.value}, which considers the fact that the money stealing can be avoided if user balance is deducted each time \\emph{before} money transfer. The third sub-pattern \\textbf{enoughBalance} concerns whether there is a check on the sufficiency of the user balance before transferring to a user. Note that \\emph{enoughBalance} is a new pattern designed in this paper.\n\n\\textbf{Timestamp dependence.} Generally, the timestamp dependence vulnerability exists when a smart contract uses the block timestamp as part of the conditions to perform critical operations \\cite{contractfuzzer}. By investigating previous works including \\cite{Sok,oyente,contractfuzzer}, we design three sub-patterns that are closely related to timestamp dependence. \\emph{First,} sub-pattern \\textbf{timestampInvocation} models whether there exists  an invocation to opcode \\emph{block.timestamp} in the function. \\emph{Then,} the second sub-pattern \\textbf{timestampAssign} checks whether the value of \\emph{block.timestamp} is assigned to other variables or passed to a function as a parameter, namely whether \\emph{block.timestamp} is actually used. \\emph{Last,} the third sub-pattern \\textbf{timestampContamination} checks if \\emph{block.timestamp} may contaminate the triggering condition of a critical operation, which can be implemented by taint analysis. Sub-pattern \\emph{timestampContamination} is a new pattern designed in this paper.\n\n\\textbf{Infinite loop.} Infinite loop is conventionally considered as a loop bug which unintentionally iterates forever, failing to jump out of the loop and return an expected result. Specifically, we define three expert patterns for infinite loop as follows. (1) The first sub-pattern \\textbf{loopStatement} checks whether the function possesses a loop statement such as \\emph{for} and \\emph{while}. (2) The second sub-pattern \\textbf{loopCondition} models whether the exit condition can be reached. For example, for a \\emph{while} loop, its exit condition $i<10$ may not be reached if $i$ is never updated in the loop. (3) The third sub-pattern \\textbf{selfInvocation} models whether the function invokes itself and the invocation is not in an \\emph{if} statement. This concerns the fact that if the self-invocation statement is not in an \\emph{if} statement, the self-invocation loop will never terminate.\n\n\\textbf{Pattern Extraction Implementations.} We implemented an open-sourced tool to extract the designed expert patterns from smart contract functions. Particularly, simple sub-patterns such as \\emph{callValueInvocation}, \\emph{timestampInvocation}, and \\emph{loopStatement} can be directly extracted by keyword matching. Sub-patterns \\emph{balanceDeduction}, \\emph{enoughBalance}, \\emph{loopCondition}, \\emph{timestampAssign}, and \\emph{selfInvocation} are obtained by syntax analysis. Complex sub-pattern \\emph{timestampContamination} is extracted by taint analysis where we follow the traces of the data flow and flag all the variables that may be affected along the traces.\n\n\\vspace{-0.7em}\n\\subsection{Contract Graph Construction and Normalization}\n\\label{graph_representation}\nExisting works \\cite{Miltiadis,rossi2018deep} have shown that programs can be transformed into symbolic graph representations, which are able to preserve semantic relationships (e.g., data dependency and control dependency) between program elements. Inspired by this, we formulate smart contract functions into \\emph{contract graphs}, and assign distinct roles to different program elements (namely nodes). We also construct edges to model control and data flow between program elements, taking their temporal orders into consideration. Further, we design a node elimination process to normalize the \\emph{contract graph} and highlight important nodes. Next, we introduce contract graph construction and normalization, respectively.\n\n\\vspace{-0.7em}\n\\subsubsection{Contract Graph Construction}\n\\label{nodes_and_edges}\n\\textbf{Nodes construction.} Our first insight is that different program elements in a function are not of equal importance in detecting vulnerabilities. Therefore, we extract three types of nodes, \\emph{i.e.}, \\textit{core nodes}, \\textit{normal nodes}, and \\textit{fallback nodes}.\n\n\\textit{Core nodes.} Core nodes symbolize the key invocations and variables that are critical for detecting a specific vulnerability. In particular, for reentrancy vulnerability, core nodes model (i) an invocation to a money transfer function or the built-in \\emph{call.value} function, (ii) the  variable that corresponds to \\emph{user balance}, and (iii) variables that can directly affect \\emph{user balance}. For timestamp dependence vulnerability,  (i) invocations to \\textit{block.timestamp}, (ii) variables assigned by \\textit{block.timestamp}, and (iii) invocations to a random function that takes \\textit{block.timestamp} as the cardinal seed are extracted as core nodes. For infinite loop vulnerability, (i) all the loop statements such as \\emph{for} and \\emph{while} statements, (ii) the loop condition variables, and (iii)  self invocations are considered as core nodes.\n\n\\textit{Normal nodes.} While core nodes represent key invocations and variables, normal nodes are used to model invocations and variables that play an auxiliary role in detecting vulnerabilities. Specifically, invocations and variables that are not extracted as core nodes are modeled as normal ones, e.g., for timestamp dependence vulnerability, invocations that do not call \\emph{block.timestamp} and variables indirectly related to \\emph{block.timestamp} are considered as normal nodes.  \n\n\\textit{Fallback node.} Further, we construct a fallback node $F$ to stimulate the fallback function of a {virtual} attack contract, which can interact with the function under test. \n\n\\emph{A simplified example.} Taking contract \\emph{Vulnerable} presented in the left of Fig. \\ref{fig:normalization} as an example, suppose we are to evaluate whether its \\emph{withdraw} function possesses a reentrancy vulnerability. As shown by the arrows in the left two figures of Fig. \\ref{fig:normalization}, function \\emph{withdraw} itself is first modeled as a core node $C_1$ since its inner code contains \\emph{call.value}. Then, following the temporal order of the code, we treat the critical variable $Balance[msg.sender]$ as a core node $C_2$, while variable $amount$ is modeled as normal node $N_1$. The invocation to \\emph{call.value} is extracted as a core node $C_3$, and the \\emph{fallback} function of a virtual attack contract is characterized by the fallback node $F$.\n\n\\begin{table}\n\\centering\n\\resizebox{0.4\\textwidth}{!}{\n\\begin{tabular}{|c|c|c|}\n\\hline\n\\multicolumn{1}{|c|}{\\textbf{Type (Abbreviation)}} & \\textbf{Semantic Fact} & \\textbf{Category} \\\\\n\\hline\nAH & assert\\{X\\} & \\multirow{11}{*}{\\begin{tabular}[c]{@{}c@{}}Control-flow\\end{tabular}} \\\\\nRG & require\\{X\\} & \\\\\nIR & if\\{...\\} revert & \\\\\nIT & if\\{...\\} throw & \\\\\nIF & if\\{X\\} & \\\\\nGB & if\\{...\\} else \\{X\\} & \\\\\nGN & if\\{...\\} then \\{X\\} & \\\\\nWH & while\\( \\{ X\\}\\) do\\{...\\} & \\\\\nFR & for\\( \\{ X\\}\\) do\\{...\\} & \\\\\nFW & natural sequential relationships & \\\\\n\\hline\n\\multicolumn{1}{|c|}{AG} & assign\\{X\\} & \\multirow{2}{*}{\\begin{tabular}[c]{@{}c@{}}Data-flow\\end{tabular}} \\\\\n\\multicolumn{1}{|c|}{AC} & access\\{X\\} & \\\\\n\\hline\n\\multicolumn{1}{|c|}{FB} & interactions with fallback function& Fallback \\\\\n\\hline\n\\end{tabular}\n}\n\\caption{Semantic edges summarization. All edges are classified into three categories, namely control-flow, data-flow, and fallback edges.}\n\\label{symbols}\n \\vspace{-1.8em}\n\\end{table}\n\n\\textbf{Edges construction.} Our second insight is that the nodes are closely related to each other in a temporal manner rather than being isolated. To capture rich semantic dependencies between the nodes, we construct three categories of edges, namely \\emph{control flow, data flow}, and \\emph{fallback} edges. Each edge describes a path that might be traversed through by the function under test, and the temporal number of the edge characterizes its sequential order in the function. We investigated various functions and summarized the semantic edges in Table \\ref{symbols}. All edges are classified into three categories. \n\n\\emph{Control flow edges.} Control flow edges capture the control semantics of the code. Specifically, a control flow edge is constructed for a \\emph{conditional} statement or \\emph{security handle} statement, such as a \\emph{if, for, assert}, and \\emph{require} statement. The edge directs from the previous node encountered, which represents the critical function call or variable preceding to the current statement, to the node representing the function call or variable in the current statement. In particular, we use forward edges to describe the natural control flow of the code sequence. A forward edge connects two nodes in the adjacent statements. The main benefit of such encoding is to reserve the programming logic reflected by the sequence of the source code. The control flow edges are depicted with red arrows in Fig. \\ref{fig:normalization}.\n\n\\emph{Data flow edges.} Data flow edges track the usage of variables. A data flow edge involves the access or modification of a variable. The data flow edges are demonstrated with orange arrows in Fig. \\ref{fig:normalization}. For example, the \\emph{access} and \\emph{assign} statement $Balance[msg.sender]$-=$amount$ (line 8, \\emph{Vulnerable}, Fig. \\ref{fig:normalization}) is characterized by two data flow edges, i.e., an access edge $e_7$ starting from the $Balance[msg.sender]$ variable node $C_2$ to itself, and an assign edge $e_8$ starting from $C_2$ to the \\emph{amount} variable node $N_1$.\n\n\\emph{Fallback edges.} {In order to explicitly model the specific fallback mechanism, two fallback edges are constructed. The first fallback edge connects from the first \\emph{call.value} invocation to the fallback node, while the second edge directs from the fallback node to the function under test. The fallback edges are shown by dashed purple edges in Fig. \\ref{fig:normalization}}.\n\n\\textbf{Node and edge features.} Fig. \\ref{fig:features} illustrates the extracted features for edges and nodes, respectively. Specifically, the feature of an edge is extracted as a tuple ($V_{start}$, $V_{end}$, \\emph{Order}, \\emph{Type}), where $V_{start}$ and $V_{end}$ represent its start and end nodes, \\emph{Order} denotes its temporal order, and \\emph{Type} stands for edge type. For nodes, different kinds of nodes possess different features. 1) The feature of a node that models function invocation consists of (\\emph{ID}, \\emph{AccFlag}, \\emph{Caller}, \\emph{Type}), where \\emph{ID} denotes its identifier, \\emph{Caller} represents the caller address of the invocation, and $Type$ stands for the node type. Interestingly, the modifier of a smart contract function $\\Psi$ may trigger the pre-check of certain conditions, e.g., modifier \\emph{owner} will check whether the caller of $\\Psi$ is the owner of the contract before executing $\\Psi$. Therefore, we use \\emph{AccFlag} to capture this semantics, where \\emph{AccFlag} = `LimitedACC' specifies the function has limited access while AccFlag =`NoLimited' denotes non-limited access. 2) In contrast, the feature of a fallback node or a node that models variable consists of only \\emph{ID} and \\emph{Type}.\n\n\\begin{figure}\n    \\begin{center}\n     \\includegraphics[width=3.2in]{fig/node_edge_feature.pdf}\n    \\end{center}\n \\caption{Illustration of the edge feature and node feature.}\n  \\label{fig:features}\n   \\vspace{-1.6em}\n\\end{figure}\n\n\\begin{figure*}\n    \\begin{center}\n     \\includegraphics[width=5.8in]{fig/classifier_detection.pdf}\n    \\end{center}\n \\caption{The process of vulnerability detection. First, a feed-forward neural network generates the pattern feature $P_{r}$ for the security patterns extracted from the source code. Then, the temporal message propagation network  is used to extract the graph feature $G_{r}$ from the contract graph. Finally, the CGE network combines $G_{r}$ and $P_{r}$ into the merged feature $X_{r}$, which is fed into the FC and sigmoid layers to output the vulnerability detection results.}\n  \\label{fig:classifier}\n   \\vspace{-1.6em}\n\\end{figure*}\n\n\\subsubsection{Contract Graph Normalization}\n\\label{graph_normalization}\nMost graph neural networks are inherently flat when propagating information, ignoring that some nodes play more central roles than others. Moreover, different contract functions yield distinct graphs, hindering the training of graph neural networks. Therefore, we propose a node elimination process to normalize the \\emph{contract graph}.\n\n\\textbf{Nodes elimination.} As introduced in Section~\\ref{nodes_and_edges}, the nodes of a \\emph{contract graph} are partitioned into core nodes $\\{C_{i}\\}_{i=1}^{|C|}$, normal nodes $\\{N_{i}\\}_{i=1}^{|N|}$, and the fallback node $F$. We remove each normal node $N_i$, but pass the feature of $N_i$ to its nearest core nodes. For example, the normal node $N_1$ in the second figure of Fig.~\\ref{fig:normalization} is removed with its feature aggregated to nearest core nodes $C_2$ and $C_3$. For a node $N_i$ that has multiple nearest core nodes, its feature is passed to all of them. The edges connected to the removed normal nodes are preserved but with their start or end node moving to the corresponding core node. The fallback node is also removed similar to the normal node. \n\n\\textbf{Feature aggregation.} After removing normal nodes, features of core nodes are updated by aggregating features from their neighboring normal nodes. More precisely, the new feature of $C_i$ is composed of three components: \\textbf{(i)} self-feature, namely the feature of core node $C_i$ itself; \\textbf{(ii)} in-features, namely features of the normal nodes $\\{P_{j}\\}^{|P|}_{j=1}$ that are merged to $C_i$ and having a path pointing from $P_{j}$ to $C_i$; and \\textbf{(iii)} out-feature, namely features of the normal nodes $\\{Q_{k}\\}^{|Q|}_{k=1}$ that are merged to $C_i$ and having a path directs from $Q_{k}$ to $C_i$. Note that features of different normal nodes that model variables and invocations are added respectively when aggregating to the same node.\n\n\\vspace{-0.7em}\n\\subsection{Vulnerability Detection} \n\\label{vulnerability_detection}\nIn this subsection, we introduce the proposed vulnerability detection network CGE (\\underline{C}ombining \\underline{G}raph feature and \\underline{E}xpert patterns). First, we obtain the expert pattern feature $P_{r}$ by passing the extracted sub-patterns (introduced in subsection~\\ref{pattern_representation}) into a feed-forward neural network (FNN). Then, we extract the graph feature $G_{r}$ from the normalized \\emph{contract graph} by our proposed temporal message propagation network, consisting of a \\emph{message propagation} phase and a \\emph{readout} phase. Finally, we use a fusion network to combine the graph feature $G_{r}$ and the pattern feature $P_{r}$, outputting the detection results. The process is demonstrated in Fig. ~\\ref{fig:classifier} with details presented below.\n\n\\textbf{Security pattern feature $P_{r}$ extraction.} For the sub-patterns closely related to a specific vulnerability, we utilize a one-hot vector to represent each sub-pattern, and append a 0/1 digit to each vector, which indicates whether the function under test has the sub-pattern. The vectors for all sub-patterns related to a specific vulnerability are concatenated into a final vector $x$. Taking $x$ as the input, and the ground truth  of whether the function has the specific vulnerability as the target label, we utilize a feed-forward neural network $\\varphi (x) $ to extract high-dimensional semantic feature $P_{r} \\in \\mathbb{R}^{d}$. \n\n\\textbf{Contract graph feature $G_r$ Extraction}. \nAfter extracting security pattern feature $P_{r}$, we further obtain the semantic feature of the contract graph by using our proposed temporal-message-propagation network, which consists of a \\emph{message propagation} phase and a \\emph{readout} phase. In the message propagation phase, the network passes information along the edges successively by following their temporal orders. Then, it generates the graph feature $G_{r}$ by using a readout function, which aggregates the final states of all nodes in the contract graph.\n\n\\emph{Message propagation phase.} Formally, we denote the normalized contract graph as $G = \\{V, E\\}$, where $V$ consists of the core nodes, and $E$ consists of all edges. Denote $E$ = \\{\\textlist[N]{e}{1,2}\\}, where $e_{k}$ represents the $k^{th}$ temporal edge.\n\nMessages are passed along the edges, one edge per time step. At first, the hidden state $h^{0}_{i}$ for each node $V_{i}$ is initialized with its own node feature. Then, at time step $k$, message flows through the $k^{th}$ temporal edge $e_{k}$ and updates the hidden state $h_{ek}$ of the end node of $e_{k}$. \n\nMore specifically, message $m_{k}$ is first computed basing on the hidden state $h_{sk}$ of the start node of $e_{k}$, and the edge type $t_{k}$:\n\\begin{align}\n\\label{eq:e1}\nx_{k} = h_{sk} \\oplus t_{k} \\\\\nm_{k} = W_{k}x_{k} + b_{k}\n\\end{align}\nwhere $\\oplus$ denotes concatenation, matrix $W_{k}$ and bias vector $b_k$ are network parameters. The original message $x_{k}$ contains information from the start node of $e_{k}$ and edge $e_{k}$ itself, which are then transformed into a vector embedding using $W_{k}$ and $b_k$.\n\nAfter receiving the message, the end node of $e_{k}$ updates its hidden state $h_{ek}$ by aggregating information from the incoming message and its previous state. Formally, $h_{ek}$ is updated according to:\n\\begin{align}\n\\label{eq:e2}\n\\hat{h}_{ek} = tanh(Um_{k} + Zh_{ek} + b_{1}) \\\\\nh^{'}_{ek} = softmax(R\\hat{h}_{ek} + b_{2})\n\\end{align}\nwhere network parameters $U$, $Z$, $R$ are matrices, while $b_{1}$ and $b_{2}$ are bias vectors.\n\n\\emph{Readout phase.} After successively traversing all the edges in $G$, we extract the feature for $G$ by reading out the final hidden states of all nodes. Let $h^{T}_{i}$ be the final hidden state of the $i^{th}$ node, we find that the differences between the final hidden state $h^{T}_{i}$ and the original hidden state $h^{0}_{i}$ are informative in the vulnerability detection task. Therefore, we consider to generate the graph  feature $G_{r}$ by\n\\begin{align}\n\\label{eq:e3}\ns_{i} &= h^{T}_{i}\\oplus h^{0}_{i} \\\\\ng_{i} &= softmax(W^{(2)}_{g}(tanh(b^{(1)}_{g} + W^{(1)}_{g}s_{i})) + b^{(2)}_{g}) \\\\\no_{i} &= softmax(W^{(2)}_{o}(tanh(b^{(1)}_{o} + W^{(1)}_{o}s_{i})) + b^{(2)}_{o}) \\\\\nG_{r} &= FC(\\sum^{|V|}_{i = 1}o_{i} \\odot g_{i})\n\\end{align}\nwhere $\\oplus$ denotes concatenation, and $\\odot$ denotes element-wise product. $W_{j}$, $b^{(1)}_{j}$, and $b^{(2)}_{j}$, with subscript $j \\in \\{g, o\\}$ are network parameters.\n\n\\textbf{Vulnerability detection by combining $P_r$ and $G_r$.} After obtaining the security pattern feature $P_{r}$ and the contract graph feature $G_{r}$, we combine them to compute the final label $\\hat{y} \\in (0, 1)$, indicating whether the function under test has the specific vulnerability. To this end, we first filter $P_{r}$ and $G_{r}$ using a convolution layer and a max pooling layer, then we concatenate the filtered features and pass them to a network consisting of 3 fully connected layers and a sigmoid layer. The process can be formulated as: \n\\begin{align}\n\\label{eq:e4}\nX_{r} = \\psi(P_{r}) \\oplus \\psi(G_{r}) \\\\\n\\hat{y} = sigmoid(FC(X_{r}))\n\\end{align}\nThe convolutional layer learns to assign different weights to different elements of the semantic vector, while the max pooling layer highlights the significant elements and avoids overfitting. The fully connected layer and the non-linear sigmoid layer produce the final estimated label $\\hat{y}$.\n\n\\vspace{-0.7em}\n\\section{Experiments}\n\\label{experiments}\nIn this section, we empirically evaluate our proposed methods on all the Ethereum smart contracts that have source code verified by Etherscan \\cite{Etherscan}, as well as on all the available smart contracts on another blockchain platform VNT Chain \\cite{Vntchain}. We seek to answer the following research questions:\n\\begin{itemize}[noitemsep,wide=0pt, leftmargin=\\dimexpr\\labelwidth + 2\\labelsep\\relax]\n\\item \\textbf{RQ1}: Can the proposed method effectively detect the reentrancy, infinite loop, and timestamp dependence vulnerabilities? How are its \\emph{accuracy}, \\emph{precision}, \\emph{recall}, and \\emph{F1 score} performance against the state-of-the-art conventional vulnerability detection approaches?\n\\item \\textbf{RQ2}: Is our proposed method useful for detecting new types of vulnerabilities, e.g., sharing-variable reentrancy, which is difficult for existing methods?\n\\item \\textbf{RQ3}: Can the proposed method outperform other neural network-based methods? \n\\item \\textbf{RQ4}: How do the proposed \\emph{security pattern}, \\emph{graph normalization}, \\emph{message propagation} modules, and \\emph{different network layers} in \\emph{CGE} affect the performance of the proposed method?\n\\end{itemize}\nNext, we first present the experimental settings, followed by answering the above research questions one by one.\n\n\\renewcommand\\arraystretch{1.0}\n\\begin{table*}\n\\centering\n\\resizebox{0.999\\textwidth}{!}{\n\\begin{tabular}{cccccccccccccc}\n\\toprule\n\\multirow{2}{*}{\\textbf{Methods}} & \\multicolumn{4}{c}{\\textbf{Reentrancy (ESC dataset)}} & \\multicolumn{4}{c}{\\textbf{Timestamp dependence (ESC dataset)}} & \\multirow{2}{*}{\\textbf{Methods}} & \\multicolumn{4}{c}{\\textbf{Infinite Loop (VSC dataset)}}\\\\\n\\cmidrule(lr){2-5}\\cmidrule(lr){6-9}\\cmidrule(lr){11-14} & Acc(\\%) & Recall(\\%) & Precision(\\%) & F1(\\%) & Acc(\\%) & Recall(\\%) & Precision(\\%) & F1(\\%) & & Acc(\\%) & Recall(\\%) & Precision(\\%) & F1(\\%) \\\\\n\\midrule\nSmartcheck & 52.97 & 32.08 & 25.00 & 28.10 & 44.32 & 37.25 & 39.16 & 38.18 & Jolt & 42.88 & 23.11 & 38.23 & 28.81 \\\\\nOyente & 61.62 & 54.71 & 38.16 & 44.96 & 59.45 & 38.44 & 45.16 & 41.53 & PDA & 46.44 & 21.73 & 42.96 & 28.26 \\\\\nMythril & 60.54 & 71.69 & 39.58 & 51.02 & 61.08 & 41.72 & 50.00 & 45.49 & SMT & 54.04 & 39.23 & 55.69 & 45.98 \\\\\nSecurify & 71.89 & 56.60 & 50.85 & 53.57 & -- & -- & -- & -- & Looper & 59.56 & 47.21 & 62.72 & 53.87 \\\\\nSlither & 77.12 & 74.28 & 68.42 & 71.23 & 74.20 & 72.38 & 67.25 & 69.72 & -- & -- & -- & -- & -- \\\\\n\\midrule\nVanilla-RNN & 49.64 & 58.78 & 49.82 & 50.71 & 49.77 & 44.59 & 51.91 & 45.62 & Vanilla-RNN & 49.57 & 47.86 & 42.10 & 44.79 \\\\\nLSTM & 53.68 & 67.82 & 51.65 & 58.64 & 50.79 & 59.23 & 50.32 & 54.41 & LSTM & 51.28 & 57.26 & 44.07 & 49.80 \\\\\nGRU & 54.54 & 71.30 & 53.10 & 60.87 & 52.06 & 59.91 & 49.41 & 54.15 & GRU & 51.70 & 50.42 & 45.00 & 47.55 \\\\\n\\textbf{GCN} & \\textbf{77.85} & \\textbf{78.79} & \\textbf{70.02} & \\textbf{74.15} & \\textbf{74.21} & \\textbf{75.97} & \\textbf{68.35} & \\textbf{71.96} & \\textbf{GCN} & \\textbf{64.01} & \\textbf{63.04} & \\textbf{59.96} & \\textbf{61.46} \\\\\t\n\\midrule\t\n{DR-GCN} & {81.47} & {80.89} & {72.36} & {76.39} & {78.68} & {78.91} & {71.29} & {74.91} & {DR-GCN} & {68.34} & {67.82} & {64.89} & {66.32} \\\\\n\\textbf{TMP} & \\textbf{84.48} & \\textbf{82.63} & \\textbf{74.06} & \\textbf{78.11} & \\textbf{83.45} & \\textbf{83.82} & \\textbf{75.05} & \\textbf{79.19} & \\textbf{TMP} & \\textbf{74.61} & \\textbf{74.32} & \\textbf{73.89} & \\textbf{74.10} \\\\\n\\textbf{CGE} & \\textbf{89.15} & \\textbf{87.62} & \\textbf{85.24} & \\textbf{86.41} & \\textbf{89.02} &  \\textbf{88.10} & \\textbf{87.41} & \\textbf{87.75} & \\textbf{CGE} & \\textbf{83.21} & \\textbf{82.29} & \\textbf{81.97} & \\textbf{82.13} \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\caption{ Performance comparison in terms of \\emph{accuracy}, \\emph{recall}, \\emph{precision}, and \\emph{F1 score}. A total of sixteen methods are investigated in the comparison, including state-of-the-art vulnerability detection methods, neural network-based alternatives, DR-GCN, TMP, and CGE. ‘--’ denotes not applicable.}\n\\label{Performance_comparison}\n \\vspace{-1.8em}\n\\end{table*}\n\n\\vspace{-0.7em}\n\\subsection{Experimental Settings}\n\\textbf{Datasets.} We conducted experiments on two real-world smart contract datasets, namely \\texttt{ESC} (Ethereum Smart Contracts) and \\texttt{VSC} (VNT chain Smart Contracts), which are collected from Ethereum and VNT Chain platforms, respectively. Experiments for reentrancy and timestamp dependence vulnerabilities are conducted on \\texttt{ESC}, while the infinite loop vulnerability is evaluated on \\texttt{VSC}.\n\\begin{itemize}\n\\item The \\texttt{ESC} dataset consists of  307,396 smart contract functions from  40,932 smart contracts in Ethereum \\cite{Ethereum}. Among the functions, around 5,013 functions possess at least one invocation to \\emph{call.value}, making them potentially affected by the reentrancy vulnerability. Around 4,833 functions contain the \\emph{block.timestamp} statement, making them susceptible to the timestamp dependence vulnerability.  {Around 56,800 functions contain \\emph{for} or \\emph{while} loop statements}. \n\\item The \\texttt{VSC} dataset contains $13,761$ functions, which are collected from all the available $4,170$ smart contracts in the VNT Chain network \\cite{Vntchain}. VNT Chain is an experimental public blockchain platform proposed by companies and universities from Singapore, China, and Australia.  The VNT Chain runs smart contracts written in Class C language.\n\\end{itemize}\n\n\\textbf{Implementation details.} All the experiments are conducted on a computer equipped with an Intel Core i7 CPU at 3.7GHz, a GPU at 1080Ti, and 32GB of Memory. Our vulnerability detection system consists of three main components: the auto \\emph{CodeExtractor} tool for extracting the security patterns and contract graphs from the source code; the \\emph{Normalization} tool for normalizing contract graphs; the CGE network that outputs  results by combining pattern feature and graph feature. The \\emph{CodeExtractor} and \\emph{Normalization} tools are implemented with Python, while the CGE network is implemented with TensorFlow. The implementations of our vulnerability detection system are available at \\url{https://github.com/Messi-Q/GPSCVulDetector}. \n\n\\textbf{Parameter settings.} The adam optimizer is employed in the CGE network. We apply a grid search to find out the best settings of hyper-parameters: the learning rate $l$ is tuned amongst \\{0.0001, 0.0005, 0.001, 0.002, 0.005, 0.01\\}, the dropout rate $d$ is searched in \\{0.1, 0.2, 0.3, 0.4, 0.5\\}, and batch size $\\beta$ in \\{8, 16, 32, 64, 128\\}. To prevent overfitting, we tuned the L2 regularization $\\lambda$ in \\{$10^{-6}$, $10^{-5}$, $10^{-4}$, $10^{-3}$, $10^{-2}$, $10^{-1}$\\}. Without special mention in texts, we report the performance of all neural network models with following default setting: 1) $l=0.002$, 2) $d=0.2$, 3) $\\beta=32$, and 4) $\\lambda=10^{-4}$. For each dataset, we randomly select $80\\%$ of them as the training set and the other $20\\%$ as the testing set for several times, and report the averaged result. The ground truth labels for contract functions are provided by experts.\n\n\\vspace{-0.7em}\n\\subsection{Comparison with  State-of-the-art Existing Methods (RQ1)}\n\\label{comparisons}\nIn this section, we benchmark our proposed method against existing non-deep-learning vulnerability detection approaches, which include:\n\\begin{itemize}[noitemsep,wide=0pt, leftmargin=\\dimexpr\\labelwidth + 2\\labelsep\\relax]\n\t\\item \\textbf{Oyente} \\cite{oyente}: A well-known symbolic verification tool for smart contract vulnerability detection, which performs symbolic execution on the CFG (control flow graph) to check vulnerable patterns.\n\t\\item \\textbf{Mythril} \\cite{mythril}: A security analysis method, which uses concolic analysis, taint analysis, and control flow checking to detect smart contract vulnerabilities.\n\t\\item \\textbf{Smartcheck} \\cite{smartcheck}: An extensible static analysis tool for discovering smart contract code vulnerabilities.\n\t\\item \\textbf{Securify} \\cite{securify}: A formal-verification based tool for detecting Ethereum smart contract bugs, which checks compliance and violation patterns to filter false positives.\n\t\\item \\textbf{Slither} \\cite{feist2019slither}: A static analysis framework designed to find issues in Ethereum smart contracts by converting a smart contract into an intermediate representation of \\emph{SlithIR}.\n\\end{itemize}\n\n\\textbf{Comparison on reentrancy vulnerability detection.} First, we compare our CGE approach with the five existing methods on the reentrancy vulnerability detection task. The performance of different methods is presented in the left of Table~\\ref{Performance_comparison}, where metrics of \\emph{accuracy}, \\emph{recall}, \\emph{precision}, and \\emph{F1 score} are engaged. We would like to highlight that all metrics are computed over only the susceptible smart contract functions having invocation(s) to \\emph{call.value}, i.e., the functions that may be infected with the reentrancy vulnerability. Functions with no \\emph{call.value} invocation are known to be immune to reentrancy vulnerability and is trivial to be handled (using purely keyword matching), thus we do not involve those functions in the calculation to better investigate the problem. From the quantitative results of Table \\ref{Performance_comparison}, we have the following observations. First, we find that conventional non-deep-learning methods have not yet achieved a satisfactory accuracy on the reentrancy vulnerability detection task, e.g., the state-of-the-art method (i.e., Slither) yields a $77.12\\%$ accuracy. Second, our proposed method substantially outperforms the existing methods on reentrancy vulnerability detection. Specifically, CGE achieves a 89.15\\% accuracy, gaining a 12.03\\% accuracy improvement over conventional methods. The strong empirical evidences suggest the great potential of combing graph neural networks with expert patterns for reentrancy vulnerability detection. \n\nBy looking into the existing methods, we believe that the reasons for the low precision and recall of conventional methods are: (1) they heavily rely on simple and fixed patterns to detect vulnerabilities, \\emph{e.g., Mythril checks whether the call.value invocation is not followed by any internal function call to detect reentrancy}, and (2) the rich data dependencies and control dependencies within smart contract code are not characterized with fine-grained details in these methods. \n\n\\textbf{Comparison on timestamp dependence vulnerability detection.} We further compare the proposed CGE with the five methods on the timestamp dependence vulnerability detection task. The comparison results are demonstrated in the middle of Table~\\ref{Performance_comparison}. The state-of-the-art conventional method (i.e., Slither) has obtained a 74.20\\% accuracy on timestamp dependence vulnerability detection, which is quite low. This may stem from the fact that most of existing methods detect timestamp dependence vulnerability by crudely checking whether there is \\emph{block.timestamp} statement in the function. Moreover, in consistent with the results on reentrancy vulnerability detection, CGE keeps delivering the best performance in terms of all the four metrics. In particular, CGE gains a 14.82\\% accuracy improvement over state-of-the-art conventional methods.\n\n\\begin{figure*}\n\\centering \n\\resizebox{0.205\\textwidth}{!}{\n\\subfigure[Reentrancy comparison of tools]{\n    \\includegraphics[width=4.5cm]{fig/re_com_tools.pdf}\n}}\n\\resizebox{0.205\\textwidth}{!}{\n\\subfigure[Timestamp comparison of tools]{\n    \\includegraphics[width=4.5cm]{fig/timestamp_com_tools.pdf}\n}}\n\\resizebox{0.205\\textwidth}{!}{\n\\subfigure[Infinite loop comparison of tools]{\n    \\includegraphics[width=4.5cm]{fig/loop_com_tools.pdf}\n}}\n\\quad\\quad\\quad\\quad\\quad\\quad\n\\quad\\quad\\quad\\quad\\quad\\quad\n\\resizebox{0.205\\textwidth}{!}{\n\\subfigure[Reentrancy comparison of networks]{\n    \\includegraphics[width=4.5cm]{fig/re_com_nn.pdf}\n}}\n\\resizebox{0.205\\textwidth}{!}{\n\\subfigure[Timestamp comparison of networks]{\n    \\includegraphics[width=4.5cm]{fig/timestamp_com_nn.pdf}\n}}\n\\resizebox{0.205\\textwidth}{!}{\n\\subfigure[Infinite loop comparison of networks]{\n    \\includegraphics[width=4.5cm]{fig/loop_com_nn.pdf}\n}}\n\\caption{{Visuallization of the quantitative results in Table~\\ref{Performance_comparison}: (a) \\& (d) present comparison results of reentrancy vulnerability detection, while (b) \\& (e) present comparison results of timestamp dependence detection, (c) \\& (f) show comparison results of infinite loop vulnerability detection. In (a) \\& (b), the 7 rows from front to back denote the Smartcheck, Oyente, Mythril, Securify, Slither, TMP, and CGE methods, respectively. In (c), the 6 rows from front to back denote the Jolt, PDA, SMT, Looper, TMP, and CGE methods, respectively. In (d) \\& (e) \\& (f), the 7 rows from front to back denote the Vanilla-RNN, LSTM, GRU, GCN, DR-GCN, TMP, and CGE methods, respectively. For each row in the figures, \\emph{accuracy}, \\emph{recall}, \\emph{precision}, and \\emph{F1 score} are respectively demonstrated from left to right.}}\n\\label{3D_fig}\n \\vspace{-0.8em}\n\\end{figure*} \n\n\\textbf{Comparison on infinite loop vulnerability detection.} We also evaluated our methods on the infinite loop vulnerability. Specifically, we compare our methods against available infinite loop detection methods including:\n\\begin{itemize}[noitemsep,wide=0pt, leftmargin=\\dimexpr\\labelwidth + 2\\labelsep\\relax]\n\t\\item \\textbf{Jolt} \\cite{Jolt}: The tool detects infinite loop bugs by monitoring the program state of two consecutive loop iterations. \n\t\\item \\textbf{SMT} \\cite{Smt}: An algorithm that relies on satisfiability modulo theories for automated detection of infinite loop bugs.\n\t\\item \\textbf{PDA} \\cite{Pda}: A method that performs program path-based checking for infinite loop detection.\n\t\\item \\textbf{Looper} \\cite{Looper}: Loop detection based on symbolic execution.\n\\end{itemize}\n\nQuantitative results are illustrated in the right of Table~\\ref{Performance_comparison}. From the table, we see that CGE consistently and significantly outperforms other methods on the infinite loop vulnerability detection task. In particular, CGE achieves a 83.21\\% accuracy and a 82.13\\% F1 score. In contrast, state-of-the-art detection tools Looper are 59.56\\% and 53.87\\%, and TMP are 74.61\\% and 74.10\\%. The improvements may come from the fact that we consider key variables and rich dependencies between program elements in smart contracts. \n\nWe further visualize the quantitative results of Table~\\ref{Performance_comparison} in Figs.~\\ref{3D_fig}(a), (b), and (c). Specifically, Fig.~\\ref{3D_fig}(a) and Fig.~\\ref{3D_fig}(b) present comparison results of reentrancy vulnerability detection and timestamp dependence vulnerability detection, respectively. The 7 rows (in different colors) from front to back denote methods \\textit{Smartcheck}, \\textit{Oyente}, \\textit{Mythril}, \\textit{Securify}, \\textit{Slither}, TMP, and CGE, respectively. For each row in the figures, \\emph{accuracy}, \\emph{recall}, \\emph{precision}, and \\emph{F1 score} are respectively demonstrated from left to right. Fig.~\\ref{3D_fig}(c) shows comparison results of infinite loop vulnerability detection, where the 6 rows from front to back denote \\textit{Jolt}, \\textit{PDA}, \\textit{SMT}, \\textit{Looper}, TMP, and CGE methods, respectively. We can clearly observe that CGE outperforms existing methods by a large margin.\n\n\\vspace{-0.7em}\n\\subsection{A Case Study Towards Better Understanding of the Reasons Behind the Results (RQ2)}\nIn this subsection, we present an interesting case of smart contract vulnerabilities, which may bring new insights into the abilities of the studied methods. Particularly, we investigate a new type of reentrancy vulnerability, \\emph{i.e., sharing-variable} reentrancy. To our knowledge, most existing methods cannot precisely detect such vulnerabilities.\n\nBesides classical reentrancy introduced in Fig.~\\ref{fig_dao} and section~\\ref{sec_problem}, a reentrancy attack is also possible when a transfer function shares internal variables with another function, which we define as sharing-variable reentrancy.\n\nIn Fig. \\ref{fig:sharingvariable}, we illustrate a real-world sharing-variable reentrancy example, where the \\emph{Malicious} contract plays an attack role against the \\emph{Vulnerable} contract. More specifically, contract \\emph{Vulnerable} contains two functions: \\emph{getBonusWithdraw} and \\emph{withdrawAll}. Function \\emph{withdrawAll} allows a user to withdraw all her rewards, while function \\emph{getBonusWithdraw} allows a user to withdraw all her rewards together with a 0.1 Ether bonus for each new user. \n\n\\textbf{Attack.} As demonstrated in Fig. \\ref{fig:sharingvariable}, contract \\emph{Malicious} first uses its \\emph{attack} function to call the $\\emph{getBonusWithdraw}$ function of contract \\emph{Vulnerable} (step 1). As $\\emph{getBonusWithdraw}$ invokes the \\emph{withdrawAll} function (\\emph{Vulnerable}, line 6) to send the rewards and bonus to \\emph{Malicious} (step 2). This will automatically trigger the fallback function of \\emph{Malicious} (step 3), where \\emph{Malicious} invokes $\\emph{getBonusWithdraw}$ again to steal money (step 4). Since the bonus flag \\emph{Bonus}[\\emph{msg.sender}] has yet been set to true, \\emph{Vulnerable} believes \\emph{Malicious} has not got the new user bonus yet and thus gives 0.1 Ether bonus again to \\emph{Vulnerable} (\\emph{Vulnerable}, line 5), then function \\emph{withdrawAll} is re-entered to withdraw the 0.1 Ether illegal bonus (step 5). \\emph{Malicious} actually invokes \\emph{getBonusWithdraw} 9 times (\\emph{Malicious}, line 9) in its fallback function to steal 1 Ether.\n\n\\textbf{Underlying issue.} This example reveals that although in the \\emph{withdrawAll} function, contract \\emph{Vulnerable} updates the user balance (i.e., \\emph{Reward}) before money transfer, \\emph{Malicious} can still be attacked. The novel attack utilizes the shared variable (\\emph{Reward}) to steal money. Although \\emph{withdrawAll} function itself is safe, the malicious contract may call $\\emph{getBonusWithdraw}$ to modify the shared variable \\emph{Reward} to enable attacks.\n\n\\iffalse\n\\renewcommand\\arraystretch{1.0}\n\\begin{table*}\n\\centering\n\\begin{tabular}{lccccccccc}\n\\toprule\n{\\multirow{3}{*}{\\textbf{Metrics}}} & \\multicolumn{3}{c}{\\textbf{Reentrancy}} & \\multicolumn{3}{c}{\\textbf{Timestamp dependence}} & \\multicolumn{3}{c}{\\textbf{Infinite loop}} \\\\\n\\cmidrule(lr){2-4}\\cmidrule(lr){5-7}\\cmidrule(lr){8-10} & CGE-WOG &  CGE-WON & CGE & CGE-WOG & CGE-WON & CGE & CGE-WOG & CGE-WON & CGE  \\\\\n\\midrule\nAcc(\\%) & 82.09 & 86.34 & \\textbf{89.15} & 81.30  &  86.61 & \\textbf{89.02} & 72.23 &  79.51 & \\textbf{83.21} \\\\\nRecall(\\%) &  80.18 & 84.38 & \\textbf{87.62} & 80.68  &  84.06 & \\textbf{88.10} & 70.08  & 77.14 & \\textbf{82.29} \\\\\nPrecision(\\%) & 72.15 & 83.35 & \\textbf{85.24} & 78.42  & 83.90 & \\textbf{87.41} & 71.44 & 76.26 & \\textbf{81.97} \\\\\nF1(\\%) & 75.95  &  83.86 & \\textbf{86.41} & 79.53 &  83.98 & \\textbf{87.75} & 70.75  & 76.70 & \\textbf{82.13} \\\\\n\\bottomrule\n\\end{tabular}\n\\caption{Accuracy comparison between CGE and its variants on the three vulnerability detection tasks.}\n\\label{normalization_com}\n\\end{table*}\n\\fi\n\nUnfortunately, such kind of attacks cannot yet be detected by existing methods. We empirically checked the \\emph{Vulnerable} contract using the state-of-the-art tools including \\emph{Oyente \\cite{oyente}, Securify \\cite{securify}, {Smartcheck} \\cite{smartcheck}, Slither \\cite{feist2019slither}, and Mythril \\cite{mythril}}, and manually inspected their generated reports. Oyente, Smartcheck, Slither, and Mythril fail to identify the reentrancy bug, whereas Security presents a lot of warnings all at the wrong places and misses the sharing-variable reentrancy vulnerability as well. In contrast, CGE successfully detects the vulnerability. These evidences reveal that the underlying detection rules of existing reentrancy vulnerability detection methods indeed can be cheated by the \\emph{sharing variable} trick and some vulnerability patterns are hard to be covered. The current rules check only the \\emph{user balance} variable that is directly related to the \\emph{call.value} invocation, while ignoring dependencies between variables, e.g., other variables may affect the \\emph{user balance} variable. In this regard, an essential highlight of our method is the capability of capturing data dependencies between critical variables.\n\n\\vspace{-0.7em}\n\\subsection{Comparison with Neural Network-based Methods (RQ3)} \nWe further compare our methods with other neural network alternatives to seek out which neural network architectures could succeed in the smart contract vulnerability detection task. The compared methods are summarized below.\n\\begin{itemize}[noitemsep,wide=0pt, leftmargin=\\dimexpr\\labelwidth + 2\\labelsep\\relax]\n \\item \\textbf{Vanilla-RNN} \\cite{Vanilla-RNN}: A two-layer recurrent neural network, which takes the code sequence as input and evolves its hidden states recurrently to capture the sequential pattern lying in the code.\n \\item \\textbf{LSTM} \\cite{LSTM}: The most widely used recurrent neural network for processing sequential data. LSTM is short for long short term memory, which recurrently updates the cell state upon successively reading the code sequence.\n \\item \\textbf{GRU} \\cite{GRU}: The gated recurrent unit, which uses gating mechanisms to handle the code sequence.\n \\item \\textbf{GCN} \\cite{GCN}: Graph convolutional network that takes the contract graph as input and implements layer-wise convolution on the graph using  graph Laplacian.\n\\item \\textbf{DR-GCN} \\cite{ijcai}: The degree-free graph convolutional network, which increases the connectivity of nodes and removes the diagonal node degree matrix.\n \\item \\textbf{TMP} \\cite{ijcai}: The temporal message propagation network, which learns the contract graph feature by flowing information along the edges successively following their temporal order. The final graph feature is used for vulnerability prediction.\n\\end{itemize}\n\n \\begin{figure}\n \t\\centering\n \t\\includegraphics[width=3in]{fig/NewContractAttack.pdf}\n \t\\caption{A real-world smart contract with the sharing-variable reentrancy vulnerability.}\n \t\\label{fig:sharingvariable}\n\t \\vspace{-0.8em}\n\\end{figure} \n\nFor a feasible comparison, Vanilla-RNN, LSTM, and GRU are fed with the contract function code sequence, represented as vectors. GCN, DR-GCN, and TMP are presented with the normalized graph extracted from the source code and are required to detect the corresponding vulnerabilities. \n\nWe illustrate the results of different models in terms of \\emph{accuracy}, \\emph{recall}, \\emph{precision}, and \\textit{F1 score} in Table~\\ref{Performance_comparison}, while Figs.~\\ref{3D_fig}(d), (e), and (f) further visualize the results. Interestingly, experimental results show that Vanilla-RNN, LSTM, and GRU perform relatively worse than the state-of-the-art conventional (non-deep-learning) methods. In contrast, graph neural networks GCN, DR-GCN, and TMP, which are capable of handling graphs, achieve significantly better results than conventional methods. This suggests that blindly treat the source code as a sequence is not suitable for the vulnerability detection task, while modeling the source code into graphs and adopting graph neural networks is promising. We conjecture that processing code sequentially loses valuable information from smart contract code since they ignore the structural information of contract programs, such as the data-flow and invocation relationships. The accuracies of GCN and DR-GCN are lower than TMP,  this may due to the fact that GCN and DR-GCN fail to capture the temporal information induced by data flow and control flow, which is explicitly considered in TMP using ordered edges. Further, we attribute the improved performance of CGE over TMP to that TMP does not consider known security patterns and ignores key variables.\n\n\\renewcommand\\arraystretch{1.0}\n\\begin{table*}\n\\centering\n\\resizebox{0.95\\textwidth}{!}{\n\\begin{tabular}{lcccccccccccc}\n\\toprule\n{\\multirow{3}{*}{\\textbf{Metrics}}} & \\multicolumn{4}{c}{\\textbf{Reentrancy}} & \\multicolumn{4}{c}{\\textbf{Timestamp dependence}} & \\multicolumn{4}{c}{\\textbf{Infinite loop}} \\\\\n\\cmidrule(lr){2-5}\\cmidrule(lr){6-9}\\cmidrule(lr){10-13} & CGE-WOG &  CGE-WOE & CGE-WON & CGE & CGE-WOG & CGE-WOE &CGE-WON & CGE & CGE-WOG & CGE-WOE &CGE-WON & CGE  \\\\\n\\midrule\nAcc(\\%) & 82.09 & 84.42 & 86.34 & \\textbf{89.15} & 81.30  & 83.52 &  86.61 & \\textbf{89.02} & 72.23 & 74.68 & 79.51 & \\textbf{83.21} \\\\\nRecall(\\%) &  80.18 &  82.65 & 84.38 & \\textbf{87.62} & 80.68  &  82.89 & 84.06 & \\textbf{88.10} & 70.08  & 74.21  & 77.14 & \\textbf{82.29} \\\\\nPrecision(\\%) & 72.15 & 78.94 & 83.35 & \\textbf{85.24} & 78.42  & 80.16  & 83.90 & \\textbf{87.41} & 71.44 & 73.86  & 76.26 & \\textbf{81.97} \\\\\nF1(\\%) & 75.95  &  80.75 & 83.86 & \\textbf{86.41} & 79.53 & 81.50  & 83.98 & \\textbf{87.75} & 70.75  & 74.03 & 76.70 & \\textbf{82.13} \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\caption{Accuracy comparison between CGE and its variants on the three vulnerability detection tasks.}\n\\label{normalization_com}\n\\end{table*}\n\n\\renewcommand\\arraystretch{1.0}\n\\begin{table*}\n\\centering\n\\resizebox{0.95\\textwidth}{!}{\n\\begin{tabular}{lcccccccccccc}\n\\toprule\n\\multirow{2}{*}{\\textbf{Variants}} & \\multicolumn{4}{c}{\\textbf{Reentrancy}} & \\multicolumn{4}{c}{\\textbf{Timestamp dependence}} &  \\multicolumn{4}{c}{\\textbf{Infinite Loop}}\\\\\n\\cmidrule(lr){2-5}\\cmidrule(lr){6-9}\\cmidrule(lr){10-13} & Acc(\\%) & Recall(\\%) & Precision(\\%) & F1(\\%) & Acc(\\%) & Recall(\\%) & Precision(\\%) & F1(\\%) & Acc(\\%) & Recall(\\%) & Precision(\\%) & F1(\\%) \\\\\n\\midrule\nVanilla-RNN-EP & 56.06 & 60.24 & 58.21 & 59.20 & 54.58 & 49.65 & 59.35 & 54.07 & 54.72 & 52.62 & 49.94 & 51.24 \\\\\nLSTM-EP & 60.15 & 72.26 & 58.68 & 64.77 & 59.82 & 63.38 & 58.28 & 56.29 & 56.52 & 59.98 & 49.75 & 54.39 \\\\\nGRU-EP & 62.08 & 75.01 & 60.13 & 66.75 & 61.22 & 64.18 & 58.45 & 61.18 & 57.09 & 60.54 & 49.81 & 54.65 \\\\\nGCN-EP & 80.96 & 81.05 & 76.84 & 78.89 & 79.32 & 79.94 & 73.65 & 76.67 & 70.06 & 69.81 & 64.29 & 66.94 \\\\\t\nDR-GCN-EP & 85.14 & 84.12 & 79.38 & 81.68 & 83.74 & 84.02 & 80.59 & 82.27 & 74.36 & 73.08 & 69.45 & 71.22 \\\\\n\\midrule\nCGE(LSTM) & 86.74 & 85.18 & 82.85 & 84.00 & 87.92 & 85.08 & 87.13 & 86.09 & 79.18 & 78.25 & 76.80 & 77.52\\\\\nCGE(FC) & 87.64 & 85.74 & 82.97 & 84.33 & 88.12 & 87.98 & 85.04 & 86.49 & 80.62 & 78.96 & 77.24 & 78.09 \\\\\nCGE(1-FC) & 88.54 & 86.12 & 83.80 & 84.94 & 86.62 & 87.82 & 81.73 & 84.66 & 81.43 & 81.25 & 80.98 & 81.11 \\\\\nCGE(2-FC) & 88.89 & 86.47 & 84.51 & 85.48 & 87.05 & 84.96 & 85.02 & 84.98 & 81.82 & 81.76 & 80.54 & 81.15 \\\\\nCGE(AP) & 88.02 & 85.92 & 83.45 & 84.67 & 85.25 & 85.16 & 81.84 & 83.47 & 79.53 & 78.58 & 76.94 & 77.75 \\\\\t\n\\textbf{CGE} & \\textbf{89.15} & \\textbf{87.62} & \\textbf{85.24} & \\textbf{86.41} & \\textbf{89.02} &  \\textbf{88.10} & \\textbf{87.41} & \\textbf{87.75} & \\textbf{83.21} & \\textbf{82.29} & \\textbf{81.97} & \\textbf{82.13} \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\caption{Upper: Performance comparison between CGE and other neural networks combined with expert patterns. ‘-EP’ denotes combining with expert patterns. Lower: Comparison with other feature fusion network architectures.}\n\\label{expert_pattern_com}\n \\vspace{-1.5em}\n\\end{table*}\n\n\\begin{figure*}\n\\centering \n\\resizebox{0.95\\textwidth}{!}{\n\\subfigure[Reentrancy]{\n    \\begin{minipage}[t]{0.342\\linewidth}\n    \\includegraphics[width=7.0cm]{fig/Roc.pdf}\n    \\end{minipage}\n}\n\\quad\n\\subfigure[Timestamp dependence]{\n    \\begin{minipage}[t]{0.35\\linewidth}\n    \\includegraphics[width=7.0cm]{fig/Roc_timestamp.pdf}\n    \\end{minipage}\n}\n\\quad\n\\subfigure[Infinite loop]{\n    \\begin{minipage}[t]{0.35\\linewidth}\n    \\includegraphics[width=7.0cm]{fig/Roc_loop.pdf}\n    \\end{minipage}\n}\n\\quad\n\\subfigure[Accuracy study on the security pattern module]{\n    \\begin{minipage}[t]{0.35\\linewidth}\n    \\includegraphics[width=7.0cm]{fig/tmp_sp.pdf}\n    \\end{minipage}\n}\n\\quad\n\\subfigure[Accuracy study on the graph feature module]{\n    \\begin{minipage}[t]{0.35\\linewidth}\n    \\includegraphics[width=7.0cm]{fig/model.pdf}\n    \\end{minipage}\n}\n}\n\\caption{Curves comparison: (a), (b), and (c) present the ROC analysis of graph normalization module for TMP, CGE, and their variants on the three vulnerability detection tasks, where AUC stands for area under the curve. In (d), the two curves study the effect of removing the security pattern extraction module, while (e) presents the study on removing the contract-graph feature extraction module.}\n\\label{fig_roc}\n\\vspace{-1.8em}\n\\end{figure*} \n\n\\vspace{-0.7em}\n\\subsection{Ablation Study (RQ4)}\nBy default, CGE adopts the \\emph{graph normalization} module to highlight the core nodes in the \\emph{contract graph},  it is interesting to study the effect of removing this module. Moreover, CGE incorporates an \\emph{expert pattern extraction} module and a \\emph{message propagation} module to aggregate information from both security patterns and the contract graph. It is useful to evaluate the contributions of the two modules by removing them respectively from CGE. Finally, we are also interested in exploring the effect of different network layers in CGE. In what follows, we conduct experiments to study the four aforementioned modules.\n\n\\textbf{Effect of the graph normalization module.} We removed the graph normalization module (introduced in subsection~\\ref{graph_normalization}) from CGE, and compared it with the default CGE. The variant is denoted as CGE-WON, where WON is short for \\emph{without normalization}. Quantitative results are summarized in Table~\\ref{normalization_com}. We can observe that with the proposed graph normalization phase, the performance of CGE is better. For example, for reentrancy vulnerability detection task, the CGE model obtains a 2.81\\% and 2.55\\% improvement in terms of accuracy and F1 score, respectively.\n\nFigs.~\\ref{fig_roc}(a) \\& (b) \\& (c) further plot the ROC curves of CGE and CGE-WON. We adopt Receiver Operating Characteristic (ROC) analysis to show the impact of the graph normalization module. AUC (area under the curve) is used as the measure for performance, the higher AUC the better performance. Fig.~\\ref{fig_roc}(a) demonstrates that CGE performs better on the reentrancy detection task, the AUC increases by 0.03 with the graph normalization module. On the timestamp dependence detection task, CGE obtains a 0.03 improvement in AUC (shown in Fig. ~\\ref{fig_roc}(b)). On the infinite loop detection task, CGE gains a 0.04 improvement in AUC (shown in Fig.~\\ref{fig_roc}(c)). In the figures, we also demonstrate the effect of removing the graph normalization module of another method, namely TMP. Similar findings are observed. The experimental results suggest that program elements should contribute distinctly to vulnerability detection rather than having equal contributions.\n\n\\textbf{Effect of the security pattern module.} To evaluate the effect of our proposed security pattern module, we analyze the performance of CGE with and without the security pattern module. Towards this, we modify CGE by removing the expert pattern extraction module, utilizing only the graph feature for vulnerability learning and detection. This variant is denoted as CGE-WOE, where WOE is short for without expert pattern. The empirical findings are demonstrated in Table~\\ref{normalization_com}, while the visual curves are illustrated in Fig. \\ref{fig_roc}(d). In Fig. \\ref{fig_roc}(d), the red curve demonstrates the accuracy of CGE over different epochs on the reentrancy vulnerability detection. Obviously, we can observe that the performance of CGE is consistently superior to CGE-WOE across all epochs, revealing that incorporating security patterns is necessary and important to improve the performance. Quantitative results on all the three vulnerabilities, which are presented in Table~\\ref{normalization_com}, further reconfirm the finding. \n\nWe also conduct experiments to extend other neural networks with expert patterns, and empirically compared these methods with CGE. The results are illustrated in Table~\\ref{expert_pattern_com}, where `-EP' denotes combining with expert patterns. We can observe that neural networks combined with expert patterns indeed achieve better results compared to their pure neural network counterparts. For example, DR-GCN-EP gains a 4.92\\% accuracy improvement over DR-GCN in average, and LSTM-EP obtains a 6.91\\% accuracy improvement over LSTM. These results indicate the effectiveness of combining neural networks with expert patterns. On the other hand, the proposed method CGE consistently outperforms other approaches including DR-GCN-EP. DR-GCN-EP ranks second in the tested methods.\n\n\\textbf{Effect of the contract graph feature extraction module.} We further investigate the impact of the contract graph feature extraction module in CGE by comparing it with its variant. Towards this, we remove the proposed contract graph construction and temporal message propagation module, while utilizing only the security pattern feature. The new variant is denoted as CGE-WOG, namely CGE without contract graph feature. Fig. \\ref{fig_roc}(e) visualizes the results, where the red curve demonstrates the accuracy of CGE over different epochs, while the blue curve shows the accuracy of CGE-WOG. Clearly, the performance of CGE is consistently better compared to its variant across all epochs. Quantitative results are further presented in Table~\\ref{normalization_com}, where all the three vulnerabilities are involved. The results, together with the experimental results on CGE-WOE, suggest that the contract graph feature contributes significant performance gain in CGE and leads to a higher gain than the security pattern feature. \n\n \\textbf{Effect of different feature fusion networks.} When combining security pattern features and contract graph features, CGE uses a neural network with a convolution layer and a max pooling layer followed by 3 fully connected layers and a sigmoid layer. To verify this network architecture, we also study five other alternatives. First, we replace the convolution and max pooling layer with a fully connected layer, which we denote as CGE(FC). We also try replacing them with an LSTM layer, which we term as CGE(LSTM). Then, we keep the convolution and max pooling layer, but change the 3 fully connected layers to 1 or 2 fully connected layers. The two variants are denoted as CGE(1-FC) and CGE(2-FC), respectively. Finally, we explore replacing the max pooling layer with an average pooling layer, namely CGE(AP), while keeping other layers fixed. The empirical results are illustrated in Table~\\ref{expert_pattern_com}. The  results reveal that: 1) RNN architectures such as LSTM are not suitable for the feature fusion task, 2) the default setting of CGE yields better results than the five alternatives, and 3) using average pooling or changing the number of fully connected layers leads to a slight performance drop.\n\n\\vspace{-0.7em}\n\\section{Discussions}\n\\textbf{Specialty of our method in dealing with smart contracts.} Distinct from conventional programs that consume only CPU resources, users have to pay a fee for executing each line of smart contract code. The fee is approximately proportional to how much code needs to run and is referred to as \\emph{gas}. Therefore, in the proposed method, we studied the infinite loop vulnerability since an \\emph{infinite loop} will consume a lot of gas but all the gas is consumed in vain. This is because the infinite loop is unable to change any state (any execution that runs out of gas is aborted).  Moreover, the function libraries of the smart contracts and other program languages are quite different. For example, \\emph{call.value} and \\emph{block.timestamp} are unique and specially designed in smart contracts. We implement an open-sourced tool to analyze the specific syntax of smart contract statements. We also use core nodes to symbolize  invocations and variables closely related to a specific vulnerability, and represent other variables and invocations as normal nodes. We would like to point out that there is a unique fallback mechanism in smart contracts, which is different from other programming languages. In the contract graph, we build a fallback node to stimulate the fallback function of a virtual attack contract, which can interact with the function under test.\n\n\\textbf{Discussions on the contract graph.} Existing efforts adopted the \\emph{control flow graph}, \\emph{code property graph}, and \\emph{abstract syntax tree} to represent program code. The differences between them and our \\emph{contract graph} can be summarized as: (i) Control flow graph utilizes a node to model a basic block, \\emph{i.e. a straight-line piece of code without any jumps,} and {uses} edges to represent jumps \\cite{phan2017convolutional}. They focus mainly on execution path jumps and tend to consider each node as of equal importance. (ii) \\emph{Code property graph} \\cite{yamaguchi2014modeling,suneja2020learning} models statements as nodes, and represents the control flow between statements as edges. (iii) \\emph{Abstract syntax tree} \\cite{mou2016convolutional,zhang2019novel} adopts a tree representation of the abstract syntactic structure of source code, which relies on a tree structure and has difficulties in fully characterizing the rich semantic information between nodes. (iv) In our contract graph, nodes are used to model variables and invocations related to a specific vulnerability and are classified into different categories, i.e. \\emph{core nodes, normal nodes}, and \\emph{fallback nodes}. We also explicitly model the order of the edges following their temporal order in the code and consider the specific fallback mechanism of the smart contracts.\n\n\\vspace{-0.7em}\n\\section{Conclusion and Future Work}\n\\label{conclusion}\nIn this paper, we have proposed a fully automated approach for smart contract vulnerability detection at the function level. In contrast to existing approaches, we combine both expert patterns and contract graph semantics, consider rich dependencies between program elements, and explicitly model the fallback mechanism of smart contracts. We also explore the possibility of using novel graph neural networks to learn the graph feature from the contract graph, which contains rich control- and data- flow semantics. Extensive experiments are conducted, showing that our method significantly outperforms the state-of-the-art vulnerability detection tools and other neural network-based methods. We believe our work is an important step towards revealing the potential of combining deep learning with conventional patterns on smart contract vulnerability detection tasks. For future work, we will investigate the possibility of extending this method to smart contracts that have only bytecode, and explore this architecture on more other vulnerabilities.\n\n\\vspace{-0.7em}\n\\section*{Acknowledgments}\nThis paper was supported by the Natural Science Foundation of Zhejiang Province, China (Grant No. LQ19F020001), the National Natural Science Foundation of China (No. 61902348, 61802345), and the Research Program of Zhejiang Lab (2019KD0AC02).\n\n\\ifCLASSOPTIONcaptionsoff\n  \\newpage\n\\fi\n\n\\footnotesize\n\n\\vspace{-4em}\n\\begin{IEEEbiography}[{\\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photo/liuzhenguang.png}}]{Zhenguang Liu}\nis currently a professor of Zhejiang Gongshang University. He had been a research\nfellow in National University of Singapore and A*STAR. %(Agency for Science, Technology and Research, Singapore). \nHe respectively received his Ph.D. and B.E. degrees from Zhejiang University\nand Shandong University, China. His research interests include smart contract security and multimedia\ndata analysis. %Various parts of his work have been published in first-tier venues including CVPR, TKDE, TIP, AAAI, ACM MM, INFOCOM, IJCAI. \nDr. Liu\nhas served as technical program committee member for conferences\nsuch as ACM MM, CVPR, AAAI, IJCAI, and ICCV, session chair of ICGIP, local chair of KSEM, and reviewer for IEEE TVCG, IEEE TPDS, ACM TOMM, etc.  %Transactions on\n\\end{IEEEbiography}\n\n\\vspace{-4em}\n\\begin{IEEEbiography}[{\\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photo/qianpeng.png}}]{Peng Qian}\nreceived his BSc degree in software engineering from Yangtze University, MSc degree in computer science from Zhejiang Gongshang University, in 2018 and 2021. He is currently pursuing a Ph.D. at Zhejiang University. His research interests include blockchain security, graph neural network, and deep learning.\n\\end{IEEEbiography}\n\n\\vspace{-4em}\n\\begin{IEEEbiography}[{\\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photo/wangxiaoyang.png}}]{Xiaoyang Wang}\nreceived the BSc and MSc degrees in computer science from Northeastern University, China, in 2010 and 2012, respectively, and the PhD degree from the University of New South Wales, Australia, in 2016. He is a professor in Zhejiang Gongshang University, Hangzhou, China. His research interest includes query processing on massive graph data.\n\\end{IEEEbiography}\n\n\\vspace{-4em}\n\\begin{IEEEbiography}[{\\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photo/zhuangyuan.png}}]{Yuan Zhuang}\nreceived her PhD from the College of Computer Science and Technology (CCST), Jilin University, China. Her research interests include blockchain security, machine learning, big data processing and distributed computing\n\\end{IEEEbiography}\n\n\\vspace{-4em}\n\\begin{IEEEbiography}[{\\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photo/qiulin.png}}]{Lin Qiu}\n is a PhD candidate at the Department\nof Information Systems and Analytics, National University of Singapore, Singapore. Before\nthat, she obtained her bachelor degree from Xiamen University, China. Her research interests lie in deep learning, healthcare, and blockchain.\n\\end{IEEEbiography}\n\n\\vspace{-4em}\n\\begin{IEEEbiography}[{\\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{photo/wangxun.png}}]{Xun Wang}\nis currently a professor at the School of Computer Science and Information Engineering, Zhejiang Gongshang University, China. He received his BSc in mechanics, Ph.D. degrees in computer science, all from Zhejiang University, China, in 1990 and 2006, respectively. His  research interests include intelligent information processing  and computer vision. He has published over 100 papers in high-quality journals and conferences. He is a member of the IEEE and ACM, and a distinguished member of CCF.\n\\end{IEEEbiography}\n\n\\iffalse\n\\begin{IEEEbiographynophoto}{Jane Doe}\nBiography text here.\n\\end{IEEEbiographynophoto}\n\\fi\n\n\\fi\n\n\\end{document}\n</paper 2>\n\n<paper 3>\n\\title{VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts by Multimodal Learning with Graph Neural Network and Language Model}\n\n\\begin{document}\n\n\\begin{frontmatter}\n\n\\title{VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts by Multimodal Learning with Graph Neural Network and Language Model}\n\n\\author[inst1,inst2]{Phan The Duy}\\ead{duypt@uit.edu.vn}\n\\author[inst1,inst2]{Nghi Hoang Khoa}\\ead{khoanh@uit.edu.vn}\n\\author[inst1,inst2]{Nguyen Huu Quyen}\\ead{quyennh@uit.edu.vn}\n\\author[inst1,inst2]{Le Cong Trinh}\\ead{19522404@gm.uit.edu.vn}\n\\author[inst1,inst2]{Vu Trung Kien}\\ead{19521722@gm.uit.edu.vn}\n\\author[inst1,inst2]{Trinh Minh Hoang}\\ead{19521548@gm.uit.edu.vn}\n\\author[inst1,inst2]{Van-Hau Pham}\\ead{haupv@uit.edu.vn}\n\n\\affiliation[inst1]{organization={Information Security Laboratory, University of Information Technology},%Department and Organization\n            city={Ho Chi Minh city},\n            country={Vietnam}}\n\n\\affiliation[inst2]{organization={Vietnam National University Ho Chi Minh City},%Department and Organization\n            city={Hochiminh City},\n            country={Vietnam}}\n\n\\begin{abstract}\nThis paper presents VulnSense framework, a comprehensive approach to efficiently detect vulnerabilities in Ethereum smart contracts using a multimodal learning approach on graph-based and natural language processing (NLP) models. Our proposed framework combines three types of features from smart contracts comprising source code, opcode sequences, and control flow graph (CFG) extracted from bytecode. We employ Bidirectional Encoder Representations from Transformers (BERT), Bidirectional Long Short-Term Memory (BiLSTM) and Graph Neural Network (GNN) models to extract and analyze these features. The final layer of our multimodal approach consists of a fully connected layer used to predict vulnerabilities in Ethereum smart contracts. Addressing limitations of existing vulnerability detection methods relying on single-feature or single-model deep learning techniques, our method surpasses accuracy and effectiveness constraints. We assess VulnSense using a collection of 1.769 smart contracts derived from the combination of three datasets: Curated, SolidiFI-Benchmark, and Smartbugs Wild. We then make a comparison with various unimodal and multimodal learning techniques contributed by GNN, BiLSTM and BERT architectures. The experimental outcomes demonstrate the superior performance of our proposed approach, achieving an average accuracy of 77.96\\% across all three categories of vulnerable smart contracts.\n\\end{abstract}\n\n\\begin{keyword}\nVulnerability Detection \\sep Smart Contract \\sep Deep Learning \\sep Graph Neural Networks \\sep Multimodal\n\\end{keyword}\n\n\\end{frontmatter}\n\n\\section{Introduction}\nThe Blockchain keyword has become increasingly more popular in the era of Industry 4.0 with many applications for a variety of purposes, both good and bad. For instance, in the field of finance, Blockchain is utilized to create new, faster, and more secure payment systems, examples of which include Bitcoin and Ethereum. However, Blockchain can also be exploited for money laundering, as it enables anonymous money transfers, as exemplified by cases like Silk Road \\cite{Ghimiray_2023}. The number of keywords associated with blockchain is growing rapidly, reflecting the increasing interest in this technology. A typical example is the smart contract deployed on Ethereum. Smart contracts are programmed in Solidity, which is a new language that has been developed in recent years. When deployed on a blockchain system, smart contracts often execute transactions related to cryptocurrency, specifically the ether (ETH) token. However, the smart contracts still have many vulnerabilities, which have been pointed out by Zou et al. \\cite{wei_chall_opport}. Alongside the immutable and transparent properties of Blockchain, the presence of vulnerabilities in smart contracts deployed within the Blockchain ecosystem enables attackers to exploit flawed smart contracts, thereby affecting the assets of individuals, organizations, as well as the stability within the Blockchain ecosystem.\n\nIn more detail, the DAO attack \\cite{Meh_dao_attack} presented by Mehar et al. is a clear example  of the severity of the vulnerabilities, as it resulted in significant losses up to \\$50 million. To solve the issues, Kushwaha et al. \\cite{Kush_ETH_review} conducted a research survey on the different types of vulnerabilities in smart contracts and provided an overview of the existing tools for detecting and analyzing these vulnerabilities. Developers have created a number of tools to detect vulnerabilities in smart contracts source code, such as Oyente \\cite{bar_smart2contract}, Slither \\cite{Kush_ETH_review}, Conkas \\cite{Nveloso}, Mythril \\cite{Consensys}, Securify \\cite{Tsan_secfy}, etc. These tools use static and dynamic analysis for seeking vulnerabilities, but they may not cover all execution paths, leading to false negatives. Additionally, exploring all execution paths in complex smart contracts can be time-consuming. Current endeavors in contract security analysis heavily depend on predefined rules established by specialists, a process that demands significant labor and lacks scalability.\n \n Meanwhile, the emergence of Machine Learning (ML) methods in the detection of vulnerabilities in software has also been explored. This is also applicable to smart contracts, where numerous tools and research are developed to identify security bugs, such as ESCORT by Lutz \\cite{lutz2021escort}, ContractWard by Wang \\cite{wang_contractward} and Qian \\cite{qian_auto_squen_mol}. The ML-based methods have significantly improved performance over static and dynamic analysis methods, as indicated in the study by Jiang \\cite{jiang_sur_smartcontr}. \n\n However, the current studies do exhibit certain limitations, primarily centered around the utilization of only a singular type of feature from the smart contract as the input for ML models. To elaborate, it is noteworthy that a smart contract's representation and subsequent analysis can be approached through its source code, employing techniques such as NLP, as demonstrated in the study conducted by Khodadadi et al. \\cite{khodadadi2023hymo}. Conversely, an alternative approach, as showcased by Chen et al. \\cite{Chen_defec_check_2022}, involves the usage of the runtime bytecode of a smart contract published on the Ethereum blockchain. Additionally, Wang and colleagues \\cite{wang_contractward} addressed vulnerability detection using opcodes extracted through the employment of the Solc tool \\cite{Solidity} (Solidity compiler), based on either the contract's source code or bytecode.\n\nIn practical terms, these methodologies fall under the categorization of unimodal or monomodal models, designed to exclusively handle one distinct type of data feature. Extensively investigated and proven beneficial in domains such as computer vision, natural language processing, and network security, these unimodal models do exhibit impressive performance characteristics. However, their inherent drawback lies in their limited perspective, resulting from their exclusive focus on singular data attributes, which lack the potential characteristics for more in-depth analysis.\n\nThis limitation has prompted the emergence of multimodal models, which offer a more comprehensive outlook on data objects. The works of Jabeen and colleagues \\cite{summaira2022review}, Tadas et al. \\cite{Tadas2019_multimodal_survey}, Nam et al. \\cite{nam2023survey}, and Xu \\cite{xu2023_multimodal_trans_sur} underscore this trend. Specifically, multimodal learning harnesses distinct ML models, each accommodating diverse input types extracted from an object. This approach facilitates the acquisition of holistic and intricate representations of the object, a concerted effort to surmount the limitations posed by unimodal models. By leveraging multiple input sources, multimodal models endeavor to enrich the understanding of the analyzed data objects, resulting in more comprehensive and accurate outcomes.\n\n Recently, multimodal vulnerability detection models for smart contracts have emerged as a new research area, combining different techniques to process diverse data, including source code, bytecode and opcodes, to enhance the accuracy and reliability of AI systems. Numerous studies have demonstrated the effectiveness of using multimodal deep learning models to detect vulnerabilities in smart contracts. For instance, Yang et al. \\cite{novel_ai_smartcontract} proposed a multimodal AI model that combines source code, bytecode, and execution traces to detect vulnerabilities in smart contracts with high accuracy. Chen et al. \\cite{khodadadi2023hymo} proposed a new hybrid multimodal model called HyMo Framework, which combines static and dynamic analysis techniques to detect vulnerabilities in smart contracts. Their framework uses multiple methods and outperforms other methods on several test datasets.\n \nRecognizing that these features accurately reflect smart contracts and the potential of multimodal learning, we employ a multimodal approach to build a vulnerability detection tool for smart contracts called VulnSense. Different features can provide unique insights into vulnerabilities on smart contracts. Source code offers a high-level understanding of contract logic, bytecode reveals low-level execution details, and opcode sequences capture the execution flow. By fusing these features, the model can extract a richer set of features, potentially leading to more accurate detection of vulnerabilities. The main contributions of this paper are summarized as follows:\n\n\\begin{itemize}\n    \\item First, we propose a multimodal learning approach consisting of BERT, BiLSTM and GNN to analyze the smart contract under multi-view strategy by leveraging the capability of NLP algorithms, corresponding to three type of features, including source code, opcodes, and CFG generated from bytecode. \n\n    \\item Then, we extract and leverage three types of features from smart contracts to make a comprehensive feature fusion. More specifics, our smart contract representations which are created from real-world smart contract datasets, including Smartbugs Curated, SolidiFI-Benchmark and Smartbugs Wild, can help model to capture semantic relationships of characteristics in the phase of analysis.\n    \n    \\item Finally, we evaluate the performance of VulnSense framework on the real-world vulnerable smart contracts to indicate the capability of detecting security defects such as Reentrancy, Arithmetic on smart contracts. Additionally, we also compare our framework with a unimodal models and other multimodal ones to prove the superior effectiveness of VulnSense.\n\\end{itemize}\nThe remaining sections of this article are constructed as follows. Section \\ref{related_work} introduces some related works in adversarial attacks and countermeasures. The section \\ref{Background} gives a brief background of applied components. Next, the threat model and methodology are discussed in section \\ref{methodology}. Section \\ref{experiments} describes the experimental settings and scenarios with the result analysis of our work. Finally, we conclude the paper in section \\ref{conclusion}.\n\n\\section{Background} \\label{Background}\n\\subsection{Bytecode of Smart Contracts}\nBytecode is a sequence of hexadecimal machine instructions generated from high-level programming languages such as C/C++, Python, and similarly, Solidity. In the context of deploying smart contracts using Solidity, bytecode serves as the compiled version of the smart contract's source code and is executed on the blockchain environment.\nBytecode encapsulates the actions that a smart contract can perform. It contains statements and necessary information to execute the contract's functionalities. Bytecode is commonly derived from Solidity or other languages used in smart contract development. When deployed on Ethereum, bytecode is categorized into two types: creation bytecode and runtime bytecode.\n\\begin{enumerate}\n    \\item \\textbf{Creation Bytecode:} The creation bytecode runs only once during the deployment of the smart contract onto the system. It is responsible for initializing the contract's initial state, including initializing variables and constructor functions. Creation bytecode does not reside within the deployed smart contract on the blockchain network.\n    \\item \\textbf{Runtime Bytecode:} Runtime bytecode contains executable information about the smart contract and is deployed onto the blockchain network.\n\\end{enumerate}\nOnce a smart contract has been compiled into bytecode, it can be deployed onto the blockchain and executed by nodes within the network. Nodes execute the bytecode's statements to determine the behavior and interactions of the smart contract.\n\nBytecode is highly deterministic and remains immutable after compilation. It provides participants in the blockchain network the ability to inspect and verify smart contracts before deployment.\n\nIn summary, bytecode serves as a bridge between high-level programming languages and the blockchain environment, enabling smart contracts to be deployed and executed. Its deterministic nature and pre-deployment verifiability contribute to the security and reliability of smart contract implementations.\n\n\\subsection{Opcode of Smart Contracts}\n\nOpcode in smart contracts refers to the executable machine instructions used in a blockchain environment to perform the functions of the smart contract. Opcodes are low-level machine commands used to control the execution process of the contract on a blockchain virtual machine, such as the Ethereum Virtual Machine (EVM).\n\nEach opcode represents a specific task within the smart contract, including logical operations, arithmetic calculations, memory management, data access, calling and interacting with other contracts in the Blockchain network, and various other tasks. Opcodes define the actions that a smart contract can perform and specify how the contract's data and state are processed. These opcodes are listed and defined in the bytecode representation of the smart contract.\n\nThe use of opcodes provides flexibility and standardization in implementing the functionalities of smart contracts. Opcodes ensure consistency and security during the execution of the contract on the blockchain, and play a significant role in determining the behavior and logic of the smart contract.\n\n\\subsection{Control Flow Graph}\n\nCFG is a powerful data structure in the analysis of Solidity source code, used to understand and optimize the control flow of a program extracted from the bytecode of a smart contract. The CFG helps determine the structure and interactions between code blocks in the program, providing crucial information about how the program executes and links elements in the control flow.\n\nSpecifically, CFG identifies jump points and conditions in Solidity bytecode to construct a control flow graph. This graph describes the basic blocks and control branches in the program, thereby creating a clear understanding of the structure of the Solidity program. With CFG, we can identify potential issues in the program such as infinite loops, incorrect conditions, or security vulnerabilities. By examining control flow paths in CFG, we can detect logic errors or potential unwanted situations in the Solidity program.\n\nFurthermore, CFG supports the optimization of Solidity source code. By analyzing and understanding the control flow structure, we can propose performance and correctness improvements for the Solidity program. This is particularly crucial in the development of smart contracts on the Ethereum platform, where performance and security play essential roles.\n\nIn conclusion, CFG is a powerful representation that allows us to analyze, understand, and optimize the control flow in Solidity programs. By constructing control flow graphs and analyzing the control flow structure, we can identify errors, verify correctness, and optimize Solidity source code to ensure performance and security.\n\n\\section{Related work} \\label{related_work}\n\nThis section will review existing works on smart contract vulnerability detection, including conventional methods, single learning model and multimodal learning approaches.\n\n\\subsection{Static and dynamic method} \n\nThere are many efforts in vulnerability detection in smart contracts through both static and dynamic analysis. These techniques are essential for scrutinizing both the source code and the execution process of smart contracts to uncover syntax and logic errors, including assessments of input variable validity and string length constraints. Dynamic analysis evaluates the control flow during smart contract execution, aiming to unearth potential security flaws. In contrast, static analysis employs approaches such as symbolic execution and tainting analysis. Taint analysis, specifically, identifies instances of injection vulnerabilities within the source code.\n\nRecent research studies have prioritized control flow analysis as the primary approach for smart contract vulnerability detection. Notably, Kushwaha et al. \\cite{Tool_review_SC} have compiled an array of tools that harness both static analysis techniques—such as those involving source code and bytecode—and dynamic analysis techniques via control flow scrutiny during contract execution. A prominent example of static analysis is Oyente \\cite{oyente}, a tool dedicated to smart contract examination. Oyente employs control flow analysis and static checks to detect vulnerabilities like Reentrancy attacks, faulty token issuance, integer overflows, and authentication errors. Similarly, Slither \\cite{slither}, a dynamic analysis tool, utilizes control flow analysis during execution to pinpoint security vulnerabilities, encompassing Reentrancy attacks, Token Issuance Bugs, Integer Overflows, and Authentication Errors. It also adeptly identifies concerns like Transaction Order Dependence (TOD) and Time Dependence.\n\nBeyond static and dynamic analysis, another approach involves fuzzy testing. In this technique, input strings are generated randomly or algorithmically to feed into smart contracts, and their outcomes are verified for anomalies. Both Contract Fuzzer \\cite{contractFuzzer} and xFuzz \\cite{xFuzz} pioneer the use of fuzzing for smart contract vulnerability detection. Contract Fuzzer employs concolic testing, a hybrid of dynamic and static analysis, to generate test cases. Meanwhile, xFuzz leverages a genetic algorithm to devise random test cases, subsequently applying them to smart contracts for vulnerability assessment.\n\nMoreover, symbolic execution stands as an additional method for in-depth analysis. By executing control flow paths, symbolic execution allows the generation of generalized input values, addressing challenges associated with randomness in fuzzing approaches. This approach holds potential for overcoming limitations and intricacies tied to the creation of arbitrary input values.\n\nHowever, the aforementioned methods often have low accuracy and are not flexible between vulnerabilities as they rely on expert knowledge, fixed patterns, and are time-consuming and costly to implement. They also have limitations such as only detecting pre-defined fixed vulnerabilities and lacking the ability to detect new vulnerabilities.\n\n\\subsection{Machine Learning method}\n\nML methods often use features extracted from smart contracts and employ supervised learning models to detect vulnerabilities. Recent research has indicated that research groups primarily rely on supervised learning. The common approaches usually utilize feature extraction methods to obtain CFG and Abstract Syntax Tree (AST) through dynamic and static analysis tools on source code or bytecode. Th\nese studies \\cite{GCN, SC_GNN} used a sequential model of Graph Neural Network to process opcodes and employed LSTM to handle the source code. Besides, a team led by Nguyen Hoang has developed Mando Guru \\cite{MandoGuru}, a GNN model to detect vulnerabilities in smart contracts. Their team applied additional methods such as Heterogeneous Graph Neural Network, Coarse-Grained Detection, and Fine-Grained Detection. They leveraged the control flow graph (CFG) and call graph (CG) of the smart contract to detect 7 vulnerabilities. Their approach is capable of detecting multiple vulnerabilities in a single smart contract. The results are represented as nodes and paths in the graph. Additionally, Zhang Lejun et al. \\cite{anovelSC} also utilized ensemble learning to develop a 7-layer convolutional model that combined various neural network models such as CNN, RNN, RCN, DNN, GRU, Bi-GRU, and Transformer. Each model was assigned a different role in each layer of the model.\n\n\\subsection{Multimodal Learning}\n The HyMo Framework \\cite{hymo}, introduced by Chen et al. in 2020, presented a multimodal deep learning model used for smart contract vulnerability detection illustrates the components of the HyMo Framework. This framework utilizes two attributes of smart contracts, including source code and opcodes. After preprocessing these attributes, the HyMo framework employs FastText for word embedding and utilizes two Bi-GRU models to extract features from these two attributes.\n \nAnother framework, the HYDRA framework, proposed by Chen and colleagues \\cite{hydra}, utilizes three attributes, including API, bytecode, and opcode as input for three branches in the multimodal model to classify malicious software. Each branch processes the attributes using basic neural networks, and then the outputs of these branches are connected through fully connected layers and finally passed through the Softmax function to obtain the final result.\n\nAnd most recently, Jie Wanqing and colleagues have published a study \\cite{2023novel} utilizing four attributes of smart contracts (SC), including source code, Static Single Assigment (SSA), CFG, and bytecode. With these four attributes, they construct three layers: SC, BB, and EVMB. Among these, the SC layer employs source code for attribute extraction using Word2Vec and BERT, the BB layer uses SSA and CFG generated from the source code, and finally, the EVMB layer employs assembly code and CFG derived from bytecode. Additionally, the authors combine these classes through various methods and undergo several distinct steps.\n\nThese models yield promising results in terms of Accuracy, with HyMo \\cite{hymo} achieving approximately 0.79\\%, HYDRA \\cite{hydra} surpassing it with around 0.98\\% and the multimodal AI of Jie et al. \\cite{2023novel}. achieved high-performance results ranging from 0.94\\% to 0.99\\% across various test cases. With these achieved results, these studies have demonstrated the power of multimodal models compared to unimodal models in classifying objects with multiple attributes. However, the limitations within the scope of the paper are more constrained by implementation than design choices. They utilized word2vec that lacks support for out-of-vocabulary words. To address this constraint, they proposed substituting word2vec with the fastText NLP model. Subsequently, their vulnerability detection framework was modeled as a binary classification problem within a supervised learning paradigm. In this work, their primary focus was on determining whether a contract contains a vulnerability or not. A subsequent task could delve into investigating specific vulnerability types through desired multi-class classification.\n\nFrom the evaluations presented in this section, we have identified the strengths and limitations of existing literature. It is evident that previous works have not fully optimized the utilization of Smart Contract data and lack the incorporation of a diverse range of deep learning models. While unimodal approaches have not adequately explored data diversity, multimodal ones have traded-off construction time for classification focus, solely determining whether a smart contract is vulnerable or not.\n\nIn light of these insights, we propose a novel framework that leverages the advantages of three distinct deep learning models including BERT, GNN, and BiLSTM. Each model forms a separate branch, contributing to the creation of a unified architecture. Our approach adopts a multi-class classification task, aiming to collectively improve the effectiveness and diversity of vulnerability detection. By synergistically integrating these models, we strive to overcome the limitations of the existing literature and provide a more comprehensive solution.\n\n\\section{Methodology} \\label{methodology}\nThis section provides the outline of our proposed approach for vulnerability detection in smart contracts. Additionally, by employing multimodal learning, we generate a comprehensive view of the smart contract, which allows us to represent of smart contract with more relevant features and boost the effectiveness of the vulnerability detection model.\n\n\\begin{figure*}[h]\n\\centering\n\\includegraphics[width=0.9\\textwidth]{Images/Multimodal_Vulnsense.jpg}\n\\caption{The overview of VulnSense framework.} \\label{generalmodel}\n\\end{figure*}\n \n\\subsection{An overview of architecture}\nOur proposed approach, VulnSense, is constructed upon a multimodal deep learning framework consisting of three branches, including BERT, BiLSTM, and GNN, as illustrated in \\textbf{Figure \\ref{generalmodel}}. More specifically, the first branch is the BERT model, which is built upon the Transformer architecture and employed to process the source code of the smart contract. Secondly, to handle and analyze the opcode context, the BiLSTM model is applied in the second branch. Lastly, the GNN model is utilized for representing the CFG of bytecode in the smart contract.\n\nThis integrative methodology leverages the strengths of each component to comprehensively assess potential vulnerabilities within smart contracts. The fusion of linguistic, sequential, and structural information allows for a more thorough and insightful evaluation, thereby fortifying the security assessment process. This approach presents a robust foundation for identifying vulnerabilities in smart contracts and holds promise for significantly reducing risks in blockchain ecosystems.\n\n\\subsection{Bidirectional Encoder Representations from Transformers (BERT)}% Phần của Hoàng ( Hoàng chưa bỏ phần chi tiết dô nhá)\n\\begin{figure}[h] \n\\centering\n\\includegraphics[width=0.4\\textwidth]{Images/BertComponent.png}\n\\caption{The architecture of BERT component in VulnSense} \\label{fig:bert_model}\n\\end{figure}\n\nIn this study, to capture high-level semantic features from the source code and enable a more in-depth understanding of its functionality, we designed a BERT network which is a branch in our Multimodal.\n\nAs in \\textbf{Figure \\ref{fig:bert_model}}, BERT model consists of 3 blocks: Preprocessor, Encoder and Neural network. More specifically, the Preprocessor processes the inputs, which is the source code of smart contracts. The inputs are transformed into vectors through the input embedding layer, and then pass through the $positional\\_encoding$  layer to add positional information to the words. Then, the $\\mathbf{preprocessed}$ values are fed into the encoding block  to compute relationships between words. The entire encoding block consists of 12 identical encoding layers stacked on top of each other. Each encoding layer comprises two main parts: a self-attention layer and a feed-forward neural network. The output $\\mathbf{encoded}$ forms a vector space of length 768. Subsequently, the $\\mathbf{encoded}$ values are passed through a simple neural network. The resulting $\\mathbf{bert\\_output}$ values constitute the output of this branch in the multimodal model. Thus, the whole BERT component could be demonstrated as follows:\n\\begin{equation} \n    \\mathbf{preprocessed} = positional\\_encoding(\\mathbf{e}(input))\n    \\label{preprocessed}\n\\end{equation}\n\\begin{equation}\n    \\mathbf{encoded} = Encoder(\\mathbf{preprocessed})\n    \\label{encoded}\n\\end{equation}\n\\begin{equation}\n    \\mathbf{bert\\_output} = NN(\\mathbf{encoded})\n    \\label{nn}\n\\end{equation}\nwhere, (\\ref{preprocessed}), (\\ref{encoded}) and (\\ref{nn}) represent the Preprocessor block, Encoder block and Neural Network block, respectively.\n\n\\subsection{Bidirectional long-short term memory (BiLSTM)}\n\\label{subsec_lstm}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.4\\textwidth]{Images/BiLSTMComponent.png}\n\\caption{The architecture of BiLSTM component in VulnSense.} \\label{bilstm}\n\\end{figure}\nToward the opcode, we applied the BiLSTM which is another branch of our Multimodal approach to analysis the contextual relation of opcodes and contribute crucial insights into the code's execution flow. By processing Opcode sequentially, we aimed to capture potential vulnerabilities that might be overlooked by solely considering structural information. \n\nIn detail, as in \\textbf{Figure \\ref{bilstm}}, we first tokenize the opcodes and convert them into integer values. The opcode features tokenized are embedded into a dense vector space using an $embedding$ layer which has 200 dimensions.\n\\begin{equation}\\label{embedded}\n\\begin{split}\n    \\mathbf{token} = Tokenize(\\mathbf{opcode}) \\\\\n    \\mathbf{vector\\_space} = Embedding(\\mathbf{token})\n\\end{split}\n\\end{equation}\n\nThen, the opcode vector is fed into two BiLSTM layers with 128 and 64 units respectively. Moreover, to reduce overfitting, the Dropout layer is applied after the first BiLSTM layer  as in (\\ref{bilstm1}).\n\\begin{equation}\\label{bilstm1}\n\\begin{split}\n    \\mathbf{bi\\_lstm1} = Bi\\_LSTM(128)(\\mathbf{vector\\_space}) \\\\\n    \\mathbf{r} = Dropout(dense(\\mathbf{bi\\_lstm1})) \\\\\n    \\mathbf{bi\\_lstm2} = Bi\\_LSTM(128)(\\mathbf{r})\n\\end{split}\n\\end{equation}\n\nFinally, the output of the last BiLSTM layer is then fed into a dense layer with 64 units and ReLU activation function as in (\\ref{bilstm2}).\n\\begin{equation}\\label{bilstm2}\n\\begin{split}\n    \\mathbf{lstm\\_output} = Dense(64, relu)(\\mathbf{bi\\_lstm2})\n\\end{split}\n\\end{equation}\n\n\\subsection{Graph Neural Network (GNN)}\nTo offer insights into the structural characteristics of smart contracts based on bytecode, we present a CFG-based GNN model which is the third branch of our multimodal model, as shown in \\textbf{Figure \\ref{fig:gnncomponent}}. \n\\begin{figure}[hpt]\n\\centering\n\\includegraphics[width=0.4\\textwidth]{Images/GNNComponent.jpg}\n\\caption{The architecture of GNN component in VulnSense} \\label{fig:gnncomponent}\n\\end{figure}\n\nIn this branch, we firstly extract the CFG from the bytecode, and then use OpenAI's embedding API to encode the nodes and edges of the CFG into vectors, as in (\\ref{encodeOpenAI}).\n\\begin{equation}\n    \\mathbf{encode} = Encoder(edges, nodes)\n    \\label{encodeOpenAI}\n\\end{equation}\n\nThe encoded vectors have a length of 1536. These vectors are then passed through 3 GCN layers with ReLU activation functions (\\ref{GCNencode}), with the first layer having an input length of 1536 and an output length of a custom hidden\\_channels ($hc$) variable.\n\n\\begin{equation}\n\\begin{split}\n    \\mathbf{GCN1} = GCNConv(1536, relu)(\\mathbf{encode})\n    \\\\\n    \\mathbf{GCN2} = GCNConv(hc, relu)(\\mathbf{GCN1})\n    \\\\\n    \\mathbf{GCN3} = GCNConv(hc)(\\mathbf{GCN2})\n    \\label{GCNencode}\n\\end{split}\n\\end{equation}\n\nFinally, to feed into the multimodal deep learning model, the output of the GCN layers is fed into 2 dense layers with 3 and 64 units respecitvely, as described in (\\ref{outGNN}). \n\\begin{equation}\n\\begin{split}\n    \\mathbf{d1\\_gnn} = Dense(3, relu)(\\mathbf{GCN3})\\\\\n    \\mathbf{gnn\\_output} = Dense(64, relu)(\\mathbf{d1\\_gnn})\n    \\label{outGNN}\n\\end{split}\n\\end{equation}\n\n\\subsection{Multimodal}\nEach of these branches contributes a unique dimension of analysis, allowing us to capture intricate patterns and nuances present in the smart contract data. Therefore, we adopt an innovative approach by synergistically concatinating the outputs of three distinctive models including BERT $\\mathbf{bert\\_output}$ (\\ref{nn}), BiLSTM $\\mathbf{lstm\\_output}$ (\\ref{bilstm2}), and GNN $\\mathbf{gnn\\_output}$ (\\ref{outGNN}) to enhance the accuracy and depth of our predictive model, as shown in (\\ref{Concatenate}):\n\\begin{equation}\n\\begin{split}\n   \\mathbf{c} = \\mathrm{Concatenate}([\\mathbf{bert\\_output}, \\\\\\mathbf{lstm\\_output}, \\mathbf{gnn\\_output}])\n    \\label{Concatenate}\n\\end{split}\n\\end{equation}\n\nThen the output $\\mathbf{c}$ is transformed into a 3D tensor with dimensions (batch\\_size, 194, 1) using the Reshape layer (\\ref{Reshape}):\n\\begin{equation}\n    \\mathbf{c\\_reshaped} = \\mathrm{Reshape}((194, 1))(\\mathbf{c})\\label{Reshape}\n\\end{equation}\n\nNext, the transformed tensor $\\mathbf{c\\_reshaped}$ is passed through a 1D convolutional layer (\\ref{Conv1D}) with 64 filters and a kernel size of 3, utilizing the rectified linear activation function:\n\\begin{equation}\n    \\mathbf{conv\\_out} = \\mathrm{Conv1D}(64, 3, \\mathrm{relu})(\\mathbf{c\\_reshaped}) \\label{Conv1D}\n\\end{equation}\n\nThe output from the convolutional layer is then flattened (\\ref{Flatten}) to generate a 1D vector:\n\\begin{equation}\n    \\mathbf{f\\_out} = \\mathrm{Flatten}()(\\mathbf{conv\\_out}) \\label{Flatten}\n\\end{equation}\n\nThe flattened tensor $\\mathbf{f\\_out}$ is subsequently passed through a fully connected layer with length 32 and an adjusted rectified linear activation function as in (\\ref{fcn}):\n\\begin{equation}\n \\mathbf{d\\_out} = \\mathrm{Dense}(32, \\mathrm{relu})(\\mathbf{f\\_out}) \\label{fcn}\n\\end{equation}\n\nFinally, the output is passed through the softmax activation function (\\ref{sMax}) to generate a probability distribution across the three output classes:\n\\begin{equation}\n    \\mathbf{\\widetilde{y}} = \\mathrm{Dense}(3, \\mathrm{softmax})(\\mathbf{d\\_out}) \\label{sMax}\n\\end{equation}\n\nThis architecture forms the final stages of our model, culminating in the generation of predicted probabilities for the three output classes. \n\n\\section{Experiments and Analysis} \\label{experiments}\n\n\\subsection{Experimental Settings and Implementation}\nIn this work, we utilize a virtual machine (VM) of Intel Xeon(R) CPU E5-2660 v4 @ 2.00GHz x 24, 128 GB of RAM, and Ubuntu 20.04 version for our implementation. Furthermore, all experiments are evaluated under the same experimental conditions. The proposed model is implemented using Python programming language and utilized well-established libraries such as TensorFlow, Keras.\n\nFor all the experiments, we have utilized the fine-tune strategy to improve the performance of these models during the training stage. We set the batch size as 32 and the learning rate of optimizer Adam with 0.001. Additionally, to escape overfitting data, the dropout operation ratio has been set to 0.03.\n\n\\subsection{Performance Metrics}\n\nWe evaluate our proposed method via 4 following metrics, including Accuracy, Precision, Recall, F1-Score. Since our work conducts experiments in multi-classes classification tasks, the value of each metric is computed based on a 2D confusion matrix which includes True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN).\n\n\\textit{Accuracy} is the ratio of correct predictions $TP,~TN$ over all predictions. \n\n\\textit{Precision} measures the proportion of $TP$ over all samples classified as positive. \n\n\\textit{Recall} is defined the proportion of $TP$ over all positive instances in a testing dataset.\n\n\\textit{F1-Score} is the Harmonic Mean of $Precision$ and $Recall$.\n\n\\subsection{Dataset and Preprocessing} \\label{subsec:dataset}\n\\begin{table}[h]\n    \\caption{Distribution of Labels in the Dataset}\\label{tab:dataset}\n    \\begin{center}\n    \\begin{tabular}{|c|c|}\n      \\hline Vulnerability Type  & Contracts \\\\  \\hline\n      Arithmetic & 631\\\\\n      Re-entrancy & 591\\\\\n      Non-Vulnerability & 547\\\\\n      \\hline\n    \\end{tabular}\n    \\end{center} \n\\end{table}\nIn this dataset, we combine three datasets, including Smartbugs Curated \\cite{durieux2020empirical, ferreira2020smartbugs}, SolidiFI-Benchmark \\cite{ghaleb2020effective}, and Smartbugs Wild \\cite{durieux2020empirical, ferreira2020smartbugs}. For the Smartbugs Wild dataset, we collect smart contracts containing a single vulnerability (either an Arithmetic vulnerability or a Reentrancy vulnerability). The identification of vulnerable smart contracts is confirmed by at least two vulnerability detection tools currently available. In total, our dataset includes 547 Non-Vulnerability, 631 Arithmetic Vulnerabilities of Smart Contracts, and 591 Reentrancy Vulnerabilities of Smart Contracts, as shown in \\textbf{Table \\ref{tab:dataset}}.\n\n\\subsubsection{Source Code Smart Contract}\nWhen programming, developers often have the habit of writing comments to explain their source code, aiding both themselves and other programmers in understanding the code snippets. BERT, a natural language processing model, takes the source code of smart contracts as its input. From the source code of smart contracts, BERT calculates the relevance of words within the code. Comments present within the code can introduce noise to the BERT model, causing it to compute unnecessary information about the smart contract's source code. Hence, preprocessing of the source code before feeding it into the BERT model is necessary.\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.4\\textwidth]{Images/trashSC.png}\n\\caption{An example of Smart Contract Prior to Processing} \\label{code:trashSC}\n\\end{figure}\n\nMoreover, removing comments from the source code also helps reduce the length of the input when fed into the model. To further reduce the source code length, we also eliminate extra blank lines and unnecessary whitespace. \\textbf{Figure \\ref{code:trashSC}} provides an example of an unprocessed smart contract from our dataset. This contract contains comments following the '//' syntax, blank lines, and excessive white spaces that do not adhere to programming standards. \\textbf{Figure \\ref{code:cleanSC}} represents the smart contract after undergoing processing.\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.4\\textwidth]{Images/cleanSC.png}\n\\caption{An example of processed Smart Contract} \\label{code:cleanSC}\n\\end{figure}\n\n\\subsubsection{Opcode Smart Contracts}\nWe proceed with bytecode extraction from the source code of the smart contract, followed by opcode extraction through the bytecode. The opcodes within the contract are categorized into 10 functional groups, totaling 135 opcodes, according to the Ethereum Yellow Paper \\cite{yellow_paper}. However, we have condensed them based on \\textbf{Table \\ref{tab:OpcodeSimplify}}.\n\\begin{table}[h]\n    \\caption{The simplified opcode methods}\\label{tab:OpcodeSimplify}\n    \\begin{center}\n    \\resizebox{0.3\\textwidth}{!}{\n    \\begin{tabular}{|c|c|}\n      \\hline Substituted Opcodes  & Original Opcodes \\\\  \\hline\n      DUP & DUP1-DUP16\\\\\n      SWAP & SWAP1-SWAP16\\\\\n      PUSH & PUSH5-PUSH32\\\\\n      LOG & LOG1-LOG4 \\\\\n      \\hline\n    \\end{tabular}}\n    \\end{center}\n\\end{table}\n\nDuring the preprocessing phase, unnecessary hexadecimal characters were removed from the opcodes. The purpose of this preprocessing is to utilize the opcodes for vulnerability detection in smart contracts using the BiLSTM model.\n\nIn addition to opcode preprocessing, we also performed other preprocessing steps to prepare the data for the BiLSTM model. Firstly, we tokenized the opcodes into sequences of integers. Subsequently, we applied padding to create opcode sequences of the same length. The maximum length of opcode sequences was set to 200, which is the maximum length that the BiLSTM model can handle.\n\nAfter the padding step, we employ a Word Embedding layer to transform the encoded opcode sequences into fixed-size vectors, serving as inputs for the BiLSTM model. This enables the BiLSTM model to better learn the representations of opcode sequences.\n\nIn general, the preprocessing steps we performed are crucial in preparing the data for the BiLSTM model and enhancing its performance in detecting vulnerabilities in Smart Contracts.\n\n\\subsubsection{Control Flow Graph}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.4\\textwidth]{Images/cfgextract.png}\n\\caption{Graph Extracted from Bytecode} \\label{code:cfgextract}\n\\end{figure}\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.4\\textwidth]{Images/cfg_pre.png}\n\\caption{Visualize Graph by .cgf.gv file } \\label{fig:cfg_pre}\n\\end{figure}\nFirst, we extract bytecode from the smart contract, then extract the CFG through bytecode into .cfg.gv files as shown in \\textbf{Figure \\ref{code:cfgextract}}. From this .cfg.gv file, a CFG of a Smart Contract through bytecode can be represented as shown in \\textbf{Figure \\ref{fig:cfg_pre}}. The nodes in the CFG typically represent code blocks or states of the contract, while the edges represent control flow connections between nodes.\n\nTo train the GNN model, we encode the nodes and edges of the CFG into numerical vectors. One approach is to use embedding techniques to represent these entities as vectors. In this case, we utilize the OpenAI API embedding to encode nodes and edges into vectors of length 1536. This could be a customized approach based on OpenAI's pre-trained deep learning models. Once the nodes and edges of the CFG are encoded into vectors, we employ them as inputs for the GNN model.\n\n\\subsection{Experimental Scenarios}\n\nTo prove the efficiency of our proposed model and compared models, we conducted training with a total of 7 models, categorized into two types: unimodal deep learning models and multi-modal deep learning models.\n\nOn the one hand, the unimodal deep learning models consisted of models within each branch of VulnSense. On the other hand, these multimodal deep learning models are pairwise combinations of three unimodal deep learning models and VulnSense, utilizing a 2-way interaction. Specifically:\n\\begin{itemize}\n    \\item \\textbf{Unimodal}:\n    \\begin{itemize}\n        \\item BiLSTM\n        \\item BERT\n        \\item GNN\n    \\end{itemize}\n    \\item \\textbf{Multimodal}:\n    \\begin{itemize}\n        \\item Multimodal BERT - BiLSTM (\\textbf{M1})\n        \\item Multimodal BERT - GNN (\\textbf{M2})\n        \\item Multimodal BiLSTM - GNN (\\textbf{M3})\n        \\item \\textbf{VulnSense} (as mentioned in \\textbf{Section \\ref{methodology}})\n    \\end{itemize}    \n\\end{itemize}\n\\begin{table*}[h]\n\\centering\n\\caption{The performance of 7 models}\n\\label{tab_multimodal_res}\n\\resizebox{0.9\\textwidth}{!}{\n\\begin{tabular}{|c|c|c|c|c|c|c|c|c|}\n\\hline\n\\textbf{Score} & \\textbf{Epoch} & \\textbf{BERT} & \\textbf{BiLSTM} & \\textbf{GNN} & \\textbf{M1} & \\textbf{M2} & \\textbf{M3} & \\textbf{VulnSense} \\\\\n\\hline\n\\multirow{3}{*}{\\textbf{Accuracy}} & \\textbf{E10} & 0.5875 & 0.7316 & 0.5960 & 0.7429 & 0.6468 & 0.7542 & \\textbf{0.7796} \\\\\n\\cline{2-9} & \\textbf{E20} & 0.5903 & 0.6949 & 0.5988 & 0.7796 & 0.6553 & 0.7768 & \\textbf{0.7796} \\\\\n\\cline{2-9} & \\textbf{E30} & 0.6073 & 0.7146 & 0.6016 & 0.7796 & 0.6525 & 0.7683 & \\textbf{0.7796} \\\\\n\\hline\n\\multirow{3}{*}{\\textbf{Precision}} & \\textbf{E10} & 0.5818 & 0.7540 & 0.4290 & 0.7749 & 0.6616 & 0.7790 & \\textbf{0.7940} \\\\\n\\cline{2-9} & \\textbf{E20} & 0.6000 & 0.7164 & 0.7209 & 0.7834 & 0.6800 & 0.7800 & \\textbf{0.7922} \\\\\n\\cline{2-9} & \\textbf{E30} & 0.6000 & 0.7329 & 0.5784 & 0.7800 & 0.7000 & 0.7700 & \\textbf{0.7800} \\\\\n\\hline\n\\multirow{3}{*}{\\textbf{Recall}} & \\textbf{E10} & 0.5876 & 0.7316 & 0.5960 & 0.7429 & 0.6469 & 0.7542 & \\textbf{0.7797} \\\\\n\\cline{2-9} & \\textbf{E20} & 0.5900 & 0.6949 & 0.5989 & 0.7797 & 0.6600 & \\textbf{0.7800} & 0.7797 \\\\\n\\cline{2-9} & \\textbf{E30} & 0.6100 & 0.7147 & 0.6017 & 0.7700 & 0.6500 & 0.7700 & \\textbf{0.7700} \\\\\n\\hline\n\\multirow{3}{*}{\\textbf{F1}} & \\textbf{E10} & 0.5785 & 0.7360 & 0.4969 & 0.7509 & 0.6520 & 0.7602 & \\textbf{0.7830} \\\\\n\\cline{2-9} & \\textbf{E20} & 0.5700 & 0.6988 & 0.5032 & 0.7809 & 0.6600 & 0.7792 & \\textbf{0.7800} \\\\\n\\cline{2-9} & \\textbf{E30} & 0.6000 & 0.7185 & 0.5107 & 0.7700 & 0.6500 & 0.7700 & \\textbf{0.7750} \\\\\n\\hline\n\\end{tabular}}\n\\end{table*}\nFurthermore, to illustrate the fast convergence and stability of multimodal method, we train and validate 7 models on 3 different mocks of training epochs including 10, 20 and 30 epochs.  \n\n\\subsection{Experimental Results}\nThe experimentation process for the models was carried out on the dataset as detailed in \\textbf{Section \\ref{subsec:dataset}}.\n\n\\subsubsection{Models performance evaluation} \\label{cmpMetric}\n\nThrough the visualizations in \\textbf{Table \\ref{tab_multimodal_res}}, it can be intuitively answered that the ability to detect vulnerabilities in smart contracts using multi-modal deep learning models is more effective than unimodal deep learning models in these experiments. Specifically, when testing 3 multimodal models including M1, M3 and VulnSense on 3 mocks of training epochs, the results indicate that the performance is always higher than 75.09\\% with 4 metrics mentioned above. Meanwhile, the testing performance of M2 and 3 unimodal models including BERT, BiLSTM and GNN are lower than 75\\% with all 4 metrics. Moreover, with the testing performance on all 3 mocks of training epochs, VulnSense model has achieved the highest F1-Score with more than 77\\% and Accuracy with more than 77.96\\%. \n\nIn addition, \\textbf{Figure \\ref{fig:c_matrixs}} provides a more detailed of the performances of all 7 models at the last epoch training. It can be seen from \\textbf{Figure \\ref{fig:c_matrixs}} that, among these multimodal models, VulnSense performs the best, having the accuracy of Arithmetic, Reentrancy, and Clean label of 84.44\\%, 64.08\\% and 84.48\\%, respectively, followed by M3, M1 and M2 model. Even though the GNN model, which is an unimodal model, managed to attain an accuracy rate of 85.19\\% for the Arithmetic label and 82.76\\% for the Reentrancy label, its performance in terms of the Clean label accuracy was merely 1.94\\%. Similarity in the context of unimodal models, BiLSTM and BERT both have gived the accuracy of all 3 labels relatively low less than 80\\%. \n\n\\begin{figure*}[h]\n  \\begin{tabular}{cccc}\n    \\subfloat[BERT]{%\n     \\includegraphics[width=0.23\\textwidth]{Images/BERT_3.png}%\n     } &\n    \\subfloat[M1]{%\n     \\includegraphics[width=0.23\\textwidth]{Images/Multi1_3.png}%\n     } & \n     \\subfloat[BiLSTM]{%\n     \\includegraphics[width=0.23\\textwidth]{Images/BiLSTM_3.png}%\n     } &\n     \\subfloat[M2]{%\n     \\includegraphics[width=0.23\\textwidth]{Images/Multi2_3.png}%\n     }\\\\\n    \\subfloat[GNN]{%\n     \\includegraphics[width=0.23\\textwidth]{Images/GNN_3.png}%\n     }&\n     \\subfloat[M3]{%\n     \\includegraphics[width=0.23\\textwidth]{Images/Multi3_3.png}%\n     }&\n     \\subfloat[VulnSense]{%\n     \\includegraphics[width=0.23\\textwidth]{Images/Multi4_3.png}%\n     }\\\\\n  \\end{tabular}\n  \\caption{Confusion matrices at the $30^{th}$ epoch, with (a), (c), (e) representing the unimodal models, and (b), (d), (f), (g) representing the multimodal models}\n  \\label{fig:c_matrixs}\n\\end{figure*}\n\nFurthermore, the results shown in \\textbf{Figure \\ref{fig:chart_performance}} have demonstrated the superior convergence speed and stability of VulnSense model compared to the other 6 models. In detail, through testing after 10 training epochs, VulnSense model has gained the highest performance with greater than 77.96\\% in all 4 metrics. Although, VulnSense, M1 and M3 models give high performance after 30 training epochs, VulnSense model only needs to be trained for 10 epochs to achieve better convergence than the M1 and M3 models, which require 30 epochs. Besides, throughout 30 training epochs, the M3, M1, BiLSTM, and M2 models exhibited similar performance to the VulnSense model, yet they demonstrated some instability. On the one hand, the VulnSense model maintains a consistent performance level within the range of 75-79\\%, on the other hand, the M3 model experienced a severe decline in both Accuracy and F1-Score values, declining by over 20\\% by the $15^{th}$ epoch, indicating significant disturbance in its performance.\n\n\\begin{figure*}[h]\n \\centering\n \\def\\twidth{1}\n \\subfloat[Accuracy]{%\n \\includegraphics[width=0.49\\textwidth]{Images/Acc.png}%\n } \\hfill\n \\subfloat[Precision]{%\n \\includegraphics[width=0.49\\textwidth]{Images/Pre.png}%\n } \\\\\n \\subfloat[Recall]{%\n \\includegraphics[width=0.49\\textwidth]{Images/Rec.png}%\n } \\hfill\n \\subfloat[F1-Score]{%\n \\includegraphics[width=0.49\\textwidth]{Images/F1S.png}%\n }\n \\caption{The performance of 7 models in 3 different mocks of training epochs.}\n \\label{fig:chart_performance}\n\\end{figure*}\n\nFrom this observation, these findings indicate that our proposed model, VulnSense, is more efficient in identifying vulnerabilities in smart contracts compared to these other models. Furthermore, by harnessing the advantages of multimodal over unimodal, VulnSense also exhibited consistent performance and rapid convergence.\n\n\\subsubsection{Comparisons of Time} \\label{cmpTrainingTime}\n\\textbf{Figure \\ref{fig:cmpTime}} illustrates the training time for 30 epochs of each model. \nConcerning the training time of unimodal models, on the one hand, the training time for the GNN model is very short, at only 7.114 seconds, on the other hand  BERT model reaches significantly longer training time of 252.814 seconds. For the BiLSTM model, the training time is significantly 10 times longer than that of the GNN model. Furthermore, when comparing the multimodal models, the shortest training time belongs to the M3 model (the multimodal combination of BiLSTM and GNN) at 81.567 seconds. Besides, M1, M2, and VulnSense involve the BERT model, resulting in relatively longer training times with over 270 seconds for 30 epochs. It is evident that the unimodal model significantly impacts the training time of the multimodal model it contributes to. Although VulnSense takes more time compared to the 6 other models, it only requires 10 epochs to converge. This greatly reduces the training time of VulnSense by 66\\% compared to the other 6 models.\n \n\\begin{figure}[h]\n    \\centering\n    \\includegraphics [width=0.4\\textwidth]{Images/training_time.png}\n    \\caption{Comparison chart of training time for 30 epochs among models}\n    \\label{fig:cmpTime}\n\\end{figure}\n\nIn addition, \\textbf{Figure \\ref{fig:cmpTimePredict}} illustrates the prediction time on the same testing set for each model. It's evident that these multimodal models M1, M2, and VulSense, which are incorporated from BERT, as well as the unimodal BERT model, exhibit extended testing durations, surpassing 5.7 seconds for a set of 354 samples. Meanwhile, the testing durations for the GNN, BiLSTM, and M3 models are remarkably brief, approximately 0.2104, 1.4702, and 2.0056 seconds correspondingly. It is noticeable that the presence of the unimodal models has a direct influence on the prediction time of the multimodal models in which the unimodal models are involved. In the context of the 2 most effective multimodal models, M3 and VulSense, M3 model gave the shortest testing time, about 2.0056 seconds. On the contrary, the VulSense model exhibits the lengthiest prediction time, extending to about 7.4964 seconds, which is roughly four times that of the M3 model. While the M3 model outperforms the VulSense model in terms of training and testing duration, the VulSense model surpasses the M3 model in accuracy. Nevertheless, in the context of detecting vulnerability for smart contracts, increasing accuracy is more important than reducing execution time. Consequently, the VulSense model decidedly outperforms the M3 model.\n\n\\begin{figure}[h]\n\\centering\n    \\includegraphics [width=0.4\\textwidth]{Images/time_predict.png}\n    \\caption{Comparison chart of prediction time on the test set for each model}\n    \\label{fig:cmpTimePredict}\n\\end{figure}\n\n\\section{Conclusion} \\label{conclusion}\n\nIn conclusion, our study introduces a pioneering approach, VulnSense, which harnesses the potency of multimodal deep learning, incorporating graph neural networks and natural language processing, to effectively detect vulnerabilities within Ethereum smart contracts. By synergistically leveraging the strengths of diverse features and cutting-edge techniques, our framework surpasses the limitations of traditional single-modal methods. The results of comprehensive experiments underscore the superiority of our approach in terms of accuracy and efficiency, outperforming conventional deep learning techniques. This affirms the potential and applicability of our approach in bolstering Ethereum smart contract security. The significance of this research extends beyond its immediate applications. It contributes to the broader discourse on enhancing the integrity of blockchain-based systems. As the adoption of smart contracts continues to grow, the vulnerabilities associated with them pose considerable risks. Our proposed methodology not only addresses these vulnerabilities but also paves the way for future research in the realm of multimodal deep learning and its diversified applications. \n\nIn closing, VulnSense not only marks a significant step towards securing Ethereum smart contracts but also serves as a stepping stone for the development of advanced techniques in blockchain security. As the landscape of cryptocurrencies and blockchain evolves, our research remains poised to contribute to the ongoing quest for enhanced security and reliability in decentralized systems.\n\n\\section*{Acknowledgment}\n\nThis research was supported by The VNUHCM-University of Information Technology's Scientific Research Support Fund.\n\n\\end{document}\n</paper 3>\n\nYour summary should follow these steps:\n- Title: Clearly state the main subject or topic of the summary.\n- Introduction: Describe the field and briefly introduce its history. Then introduce current progress and challenges.\n- Introduce the main content of each paper separately. Then summarize their commonalities and innovations.\n- Compare the results of the papers and discuss difference of the results.\n- Conclusion: Summarize the main findings and suggest future research directions.\n\n<keys>\nThe following are the key points to note:\n- If there are important data or mian equation in the given papers, remember to mention them in your summary using Markdown.\n- Use of tables to clearly compare different approaches is encouraged.\n- The first appearance of a professional term must be marked with the full English name and abbreviation.\n- Don't directly copy the papers, write the summary in your own words.\n- Do not include the titles of reference papers directly in your paper.\n</keys>\n\nTotal word count should be about 4000 words.",
    "paper": [
        "arXiv-2103.12607v1.tex",
        "arXiv-2107.11598v1.tex",
        "arXiv-2309.08474v1.tex"
    ],
    "group_id": "group_57",
    "response": "### Title: Deep Learning Approaches for Ethereum Smart Contract Vulnerability Detection\n\n### Introduction\nThe field of blockchain technology, particularly Ethereum smart contracts, has seen significant growth and interest due to its potential for creating decentralized applications and automating financial transactions. However, the deployment of smart contracts introduces new security risks, primarily due to programming flaws that can be exploited to gain financial profits. These flaws can manifest in various forms, such as reentrancy attacks, timestamp dependence, and arithmetic overflows. The security of smart contracts is paramount, as any vulnerability can have far-reaching consequences, affecting not only individual contracts but the entire blockchain network. Traditional methods for detecting these vulnerabilities, such as symbolic execution, static analysis, and dynamic testing, have limitations in terms of scalability, efficiency, and extensibility. As a result, there is a growing interest in leveraging machine learning (ML) and deep learning (DL) techniques to automate and enhance the detection process. This summary focuses on three recent research papers that explore DL-based approaches for detecting vulnerabilities in Ethereum smart contracts. These papers present innovative frameworks and methodologies that address the challenges of scalability, efficiency, and extensibility, aiming to provide a more comprehensive and adaptable solution to smart contract security.\n\nHistorically, smart contract vulnerability detection has relied on manual inspection and rule-based systems. These methods are labor-intensive and non-scalable, making it difficult to keep up with the rapid growth in the number of deployed contracts. Additionally, they often suffer from high false positive and false negative rates, as well as the inability to detect new or evolving vulnerabilities. The advent of DL techniques has introduced a new paradigm for vulnerability detection, offering the potential for automated, efficient, and extensible solutions. However, existing DL-based approaches have limitations, such as focusing on binary classification, requiring source code, or failing to capture the sequential and structural information inherent in smart contracts. The current progress in DL-based smart contract security analysis aims to overcome these limitations by integrating multiple features and models, thereby improving the detection accuracy and efficiency.\n\n### Main Content of Each Paper\n\n#### Paper 1: ESCORT (Ethereum Smart COntRacTs Vulnerability Detection using Deep Neural Network and Transfer Learning)\nESCORT is a DL-based framework designed to detect vulnerabilities in Ethereum smart contracts. The framework operates on bytecode, which is publicly available and agnostic to the programming language used. ESCORT's key innovation lies in its multi-output architecture, which consists of a common feature extractor and multiple branch structures for specific vulnerability types. This architecture allows for lightweight transfer learning, enabling the framework to adapt to new vulnerabilities with minimal retraining overhead. The feature extractor learns the semantic and syntactic information of the contract bytecode, while each branch learns to identify specific vulnerability types based on the features extracted by the feature extractor. ESCORT's modular design ensures that new branches can be added easily to accommodate new vulnerabilities, thus making the framework extensible and generalizable.\n\nESCORT's evaluation was conducted on a large dataset of 93,497 smart contracts, labeled using three existing tools: Oyente, Mythril, and Dedaub. The dataset includes six initial vulnerability types and two additional types introduced through transfer learning. ESCORT achieves an average F1 score of 95% across the initial six vulnerability types and 93% on the two new types, with a detection time of 0.02 seconds per contract. The authors also developed a toolchain, \\datatool{}, to automate the acquisition and labeling of smart contract bytecode, which will be open-sourced to encourage further research.\n\n#### Paper 2: Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection\nThis paper introduces a method that combines graph neural networks (GNNs) with expert-defined security patterns to detect vulnerabilities in Ethereum smart contracts. The method constructs a contract graph from the source code, highlighting critical nodes and edges that represent control and data flow semantics. The contract graph is then normalized to emphasize key nodes, and a temporal message propagation network (TMP) is used to extract the graph feature. Expert patterns are extracted from the source code using a feed-forward neural network (FNN) to generate the pattern feature. The pattern feature and graph feature are combined using a fusion network to output the final vulnerability detection results.\n\nThe authors conducted experiments on two datasets: \\texttt{ESC} (Ethereum Smart Contracts) and \\texttt{VSC} (VNT Chain Smart Contracts), focusing on three types of vulnerabilities: reentrancy, timestamp dependence, and infinite loop. The proposed method, CGE (Combining Graph feature and Expert patterns), outperforms existing methods and neural network-based alternatives, achieving an average F1 score of 86.41% for reentrancy, 87.75% for timestamp dependence, and 82.13% for infinite loop vulnerabilities. The authors also demonstrated the effectiveness of their method in detecting new types of vulnerabilities, such as sharing-variable reentrancy, which are difficult for existing methods to identify.\n\n#### Paper 3: VulnSense (Efficient Vulnerability Detection in Ethereum Smart Contracts by Multimodal Learning with Graph Neural Network and Language Model)\nVulnSense is a multimodal DL framework that leverages three distinct models—BERT, BiLSTM, and GNN—to detect vulnerabilities in Ethereum smart contracts. BERT processes the source code to capture high-level semantic features, BiLSTM analyzes opcode sequences to understand the execution flow, and GNN extracts structural information from the control flow graph (CFG) of the bytecode. The outputs from these three models are concatenated and fed into a final fusion network to generate vulnerability predictions. The authors utilized a dataset combining three sources: Smartbugs Curated, SolidiFI-Benchmark, and Smartbugs Wild, which includes 547 non-vulnerable contracts and 1,222 contracts with either arithmetic or reentrancy vulnerabilities.\n\nVulnSense was evaluated using accuracy, precision, recall, and F1 score metrics. The framework achieved an average F1 score of 77.50% across all vulnerability types, demonstrating superior performance compared to unimodal models and other multimodal approaches. The authors also conducted an ablation study to evaluate the contributions of each component, finding that the multimodal approach significantly improves detection accuracy and efficiency. Additionally, VulnSense showed fast convergence and stability, requiring only 10 epochs to achieve high performance, compared to the 30 epochs needed by other multimodal models.\n\n### Commonalities and Innovations\nAll three papers address the challenge of detecting vulnerabilities in Ethereum smart contracts using DL techniques. They aim to provide an efficient, scalable, and extensible solution to the problem of concurrent detection of multiple vulnerability types. However, each paper introduces unique innovations and methodologies:\n\n- **ESCORT** uses a multi-output architecture with a common feature extractor and multiple branches for specific vulnerability types. This design allows for lightweight transfer learning, enabling the framework to adapt to new vulnerabilities quickly. ESCORT also introduces \\datatool{}, a toolchain for automating dataset construction and labeling based on bytecode and existing vulnerability detection tools.\n  \n- **Combining GNN with Expert Knowledge** constructs a contract graph from the source code and normalizes it to highlight key nodes. The authors propose a TMP network to extract graph features and combine them with expert-defined security patterns. This approach explicitly models the fallback mechanism and data dependencies within smart contracts, leading to improved detection accuracy.\n  \n- **VulnSense** employs a multimodal learning approach, integrating BERT, BiLSTM, and GNN to capture different aspects of smart contract vulnerabilities. The framework combines high-level semantic features from source code, sequential opcode features, and structural information from CFG, leading to a more comprehensive representation of smart contracts. VulnSense also demonstrates fast convergence and stability, requiring fewer training epochs to achieve high performance.\n\n### Comparison of Results\nThe performance metrics of the three frameworks are summarized in Table \\ref{tab:performance_comparison}. ESCORT achieves the highest F1 scores across all vulnerability types, with an average of 95% for the initial six types and 93% for the two new types introduced through transfer learning. CGE, on the other hand, shows significant improvements over existing methods, achieving F1 scores of 86.41% for reentrancy, 87.75% for timestamp dependence, and 82.13% for infinite loop vulnerabilities. VulnSense, while not achieving the highest F1 scores, demonstrates superior efficiency and accuracy compared to unimodal models and other multimodal approaches, with an average F1 score of 77.50% across all vulnerability types.\n\n\\begin{table*}[h]\n\\centering\n\\scalebox{0.9}{\n\\begin{tabular}{|c|c|c|c|c|c|c|c|}\n\\hline\n\\textbf{Method} & \\textbf{Vulnerability Type} & \\textbf{F1 Score} & \\textbf{Detection Time (s)} & \\textbf{Training Time (s)} & \\textbf{Epochs} & \\textbf{Dataset Size} & \\textbf{Features} \\\\\n\\hline\nESCORT & Reentrancy & 95\\% & 0.02 & 5:44 & 1 & 93,497 & Bytecode \\\\\n\\hline\nESCORT & Timestamp Dependence & 95\\% & 0.02 & 5:44 & 1 & 93,497 & Bytecode \\\\\n\\hline\nESCORT & Infinite Loop & 95\\% & 0.02 & 5:44 & 1 & 93,497 & Bytecode \\\\\n\\hline\nCGE & Reentrancy & 86.41\\% & 0.02 & 2:43 & 1 & 307,396 & Source code, CFG \\\\\n\\hline\nCGE & Timestamp Dependence & 87.75\\% & 0.02 & 2:43 & 1 & 307,396 & Source code, CFG \\\\\n\\hline\nCGE & Infinite Loop & 82.13\\% & 0.02 & 2:43 & 1 & 13,761 & Source code, CFG \\\\\n\\hline\nVulnSense & Reentrancy & 78.30\\% & 7.4964 & 252.814 & 10 & 1,769 & Source code, Opcode, CFG \\\\\n\\hline\nVulnSense & Timestamp Dependence & 78.00\\% & 7.4964 & 252.814 & 10 & 1,769 & Source code, Opcode, CFG \\\\\n\\hline\nVulnSense & Arithmetic & 77.50\\% & 7.4964 & 252.814 & 10 & 1,769 & Source code, Opcode, CFG \\\\\n\\hline\n\\end{tabular}\n}\n\\caption{Performance Comparison of ESCORT, CGE, and VulnSense Frameworks}\n\\label{tab:performance_comparison}\n\\end{table*}\n\nThe differences in performance can be attributed to the distinct methodologies and features utilized by each framework. ESCORT's multi-output architecture and lightweight transfer learning capabilities enable it to achieve high accuracy and efficiency. CGE's combination of graph features and expert patterns provides a more detailed analysis of smart contract vulnerabilities, leading to improved detection accuracy. VulnSense's multimodal approach, integrating BERT, BiLSTM, and GNN, offers a comprehensive representation of smart contracts, enhancing detection accuracy and efficiency. However, VulnSense's longer training and prediction times highlight the trade-off between accuracy and computational overhead.\n\n### Conclusion\nThe three papers introduce innovative DL-based frameworks for detecting vulnerabilities in Ethereum smart contracts, each addressing the challenges of scalability, efficiency, and extensibility with unique methodologies. ESCORT's multi-output architecture and transfer learning capabilities provide a flexible and efficient solution for concurrent detection of multiple vulnerability types. CGE's combination of graph features and expert patterns offers a detailed and accurate detection approach, explicitly modeling the fallback mechanism and data dependencies. VulnSense's multimodal learning approach integrates multiple features and models, leading to a more comprehensive representation of smart contracts and improved detection performance.\n\nThese frameworks collectively demonstrate the potential of DL techniques in enhancing smart contract security. Future research could explore the integration of these frameworks with other blockchain platforms and programming languages, as well as the adaptation of these models to detect new and evolving vulnerabilities. Additionally, further investigation into the efficiency and effectiveness of these models could lead to the development of more practical and scalable solutions for smart contract security.\n\n### Acknowledgment\nThis summary is based on the provided research papers and aims to highlight the key findings and methodologies presented in each. The authors of the original papers have made significant contributions to the field of smart contract security, and their work serves as a foundation for future research and development in this area."
}