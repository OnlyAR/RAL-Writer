{
    "instruction": "You are an experienced researcher, I will give you some scientific research papers in the same field. Please read them carefully and write a summary about them.\n\nHere are the papers:\n\n<paper 1>\n\\title{Settling Payments Fast and Private: Efficient Decentralized Routing for Path-Based Transactions}\n\n\\begin{document}\n\n\\maketitle\n\n\\vspace{-1em}\n\n\\begin{abstract}\n\\footnote{This paper will appear at NDSS 2018} \nDecentralized path-based transaction (PBT)\nnetworks maintain local payment channels between participants. Pairs of users \nleverage these channels to settle payments via a path of intermediaries\nwithout the need to record all transactions in a global blockchain. \nPBT networks such as Bitcoin's Lightning Network and Ethereum's Raiden Network are the most prominent examples of\nthis emergent area of research. Both networks overcome scalability issues of widely used  \ncryptocurrencies by replacing expensive and slow on-chain blockchain operations with inexpensive and fast off-chain transfers.\n\nAt the core of a decentralized PBT network is a routing algorithm that discovers transaction paths between sender and receiver.\n In recent years, a number of routing algorithms have been proposed, \nincluding landmark routing, utilized in the decentralized IOU credit network \\cnsysname,  and Flare, a link state algorithm for the Lightning Network.\nHowever, the existing efforts lack either efficiency or privacy, \nas well as the comprehensive analysis that is indispensable to ensure the success of PBT networks in practice. \nIn this work, we first identify several efficiency concerns in existing \nrouting algorithms for decentralized PBT networks.\nArmed with this knowledge,\nwe design and evaluate \\oursys , a novel routing algorithm for decentralized PBT networks \nusing efficient and flexible embedding-based path discovery and on-demand \nefficient stabilization to handle the dynamics of a PBT network. Our simulation study,\nbased on real-world data from the currently deployed Ripple credit network, \nindicates that \\oursys reduces the overhead of stabilization by \nup to two orders of magnitude and the overhead of routing a transaction by more than a factor of two. \nFurthermore, using \\oursys maintains at least the same success \nratio as decentralized landmark routing, while providing lower delays.\nFinally, \\oursys achieves key privacy goals for routing in decentralized PBT networks.   \n\\end{abstract}\n\n\\vspace{-1em}\n\n\\section{Introduction}\n\\label{sec:intro}\n\nSince the advent of Bitcoin~\\cite{nakamoto2011bitcoin}, many other blockchain-based \npayment systems have been proposed and deployed in practice to serve a multitude \nof purposes. For instance, IOweYou (IOU) credit networks~\\cite{defigueiredo05trustdavis,Ghosh07} \nsuch as Ripple~\\cite{ripple,armknecht2015ripple} \nor Stellar~\\cite{stellar} leverage blockchain technology to enable \nreal-time gross settlements~\\cite{RTGS} between two end users  \nacross different currencies and assets significantly cheaper than the current central banking system. \nEthereum~\\cite{ethereum} builds on top of a blockchain \nto construct a platform to run fully expressive smart contracts.\n\nHowever, the growing base of users and transactions is resulting in\nblockchain scalability issues~\\cite{Croman2016, poon2015bitcoin}. Moreover, the public nature of the blockchain \nleads to demonstrable privacy breaches of sensitive data such as the identities of the transaction partners and the transaction value~\\cite{moreno2016listening, Meiklejohn2013, Kumar2017, Miller17,reid2013analysis}. \nAcademic and industry efforts are leading towards peer-to-peer (P2P) %  \npath-based transaction (PBT) networks such as the Lightning Network~\\cite{poon2015bitcoin} for Bitcoin, \nthe Raiden Network~\\cite{raiden} for Ethereum, \nSilentWhispers~\\cite{malavolta17silent} for credit networks, or InterLedger~\\cite{thomas2015protocol}  and\nAtomic-swap~\\cite{atomic-swap}\nfor inter-blockchain transactions;\n these decentralized PBT networks are promising for\naddressing scalability, efficiency, and interoperability concerns with blockchains \nthrough off-chain transactions requiring no expensive mining efforts.\nIn fact, at a recent blockchain event, the InterLedger team demonstrated a transaction through seven \nblockchains including those in Bitcoin, \nEthereum, and Ripple~\\cite{sevenledgers}.\n\nUnlike in blockchain-based PBT networks such as Ripple or Stellar,  \ntwo users $u$ and $v$ in a decentralized PBT network \\emph{locally} maintain a weighted link\n(also called a payment channel, \nstate channel, or credit link, depending on the application).\nThe link's weight characterizes the amount of funds (or assets) that one user can transfer to the other,\nthe exact nature of the link depending on the application.\nFor instance, in a credit network, the weight defines the difference between \nthe amount of credit $u$ is willing to grant $v$ and the amount $v$ already\nowes $u$.\n\nA PBT network builds on top of three key algorithms: \\emph{routing},  \n\\emph{payment} and \\emph{accountability}. The routing algorithm is in charge of finding paths with \nenough funds from sender to receiver. The payment algorithm settles the funds between \nsender and receiver along the paths connecting them. Finally, the accountability algorithm \nallows the resolution of disputes in the presence of misbehaving users. \n\nWhile frequently omitted or disregarded as \nan orthogonal problem, the design of the routing algorithm is key to the PBT network's effectiveness, \ncharacterized by the fraction of successfully resolved transactions; efficiency, characterized by the delays experienced during a transaction as well as the overhead created by transactions; and scalability, \n characterized  by the ability of a PBT network to maintain effectiveness and efficiency for \n a growing base of users and transactions. \n \nWhereas industry supposedly considers efficiency, effectiveness, and scalability to be the main concerns for designing a routing algorithm, we additionally emphasize the need for privacy. \nOtherwise, the routing algorithm might reveal sensitive information such as the transaction value, the identity of sender and receiver, and the debt of one user to another.  \nIn this paper, we stress that all of effectiveness, efficiency, scalability, and privacy\nare important to the design of a routing algorithm. \nA routing algorithm lacking any of these key properties is unlikely to be deployed.  \n\n \n\nThe few routing algorithms proposed so far for PBT networks fail to achieve either \nprivacy, efficiency, or scalability. For instance, the routing algorithm in Ripple and Stellar \nrelies on a public blockchain that logs the complete PBT network, \nthereby introducing blockchain fees and impeding privacy. \nCanal~\\cite{viswanath2012canal} relies on a single server to store the complete PBT network, \n find paths, and settle payments between users. Therefore, the server is \ntrivially aware of all links between users and their transactions. \nPrivPay~\\cite{moreno15privpay} leverages trusted hardware to encrypt the PBT \nnetwork data at the server and uses oblivious algorithms to hide the access patterns, thereby \nincreasing the privacy for the links between users and their payments. Nevertheless, PrivPay \n still suffers from a single point of failure and low scalability. Flare~\\cite{prihodko2016flare}, \n a routing algorithm for the Lightning Network, requires every user in the path from sender to \n receiver to send the current fund amounts for their payment channels to the sender, thereby leaking \n sensitive information~\\cite{prihodko2016flare}.\nThe most promising approach with regard to privacy is SilentWhispers~\\cite{malavolta17silent}, \na decentralized PBT network without a public ledger. However, as we show in this paper, \nthe routing algorithm in SilentWhispers lacks efficiency. \n\n \n\nIn this work, we present SpeedyMurmurs, a routing algorithm for PBT networks \nthat provides formal privacy guarantees in a fully distributed setting and outperforms the state-of-the-art \nrouting algorithms in terms of effectiveness and efficiency. \nSpeedyMurmurs extends VOUTE~\\cite{roos2016anonymous}, a privacy-preserving embedding-based~\\cite{papadimitriou2004conjecture} routing algorithm for message delivery in route-restricted P2P networks.  \nTargeting message transmission in undirected and unweighted networks rather than payments, VOUTE \nis unequipped for dealing with weighted links and specifically changes of these weights as a result of previous transfers.  \n\\oursys combines the underlying ideas of VOUTE with the specifics of credit networks.      \nIn particular:\n\\begin{itemize}\n\\item SpeedyMurmurs considers both the available funds and the closeness to the destination of a neighbor when routing a payment, resulting in an efficient algorithm with flexible path selection.  \n\\item SpeedyMurmurs employs an on-demand efficient stabilization algorithm that reacts to changes of links if necessary but keeps the overhead corresponding to these changes low.\n\\item SpeedyMurmurs provides an improved handling of concurrent transactions by allowing nodes to proactively allocate exactly the amount of funds required for a transaction rather than barring concurrent transactions from using a link altogether or risking failures during the subsequent payment phase.\n\\item In our simulation study, which models a credit network and transactions based on a real-world dataset of Ripple ranging from 2013 to 2016, \\oursys performs transactions at about twice the speed of \\cnsysname and reduces the communication overhead of transactions by at least a factor of two while maintaining a similar or higher effectiveness. \n\\item SpeedyMurmurs reduces the overhead of managing link changes by 2--3 orders of magnitude except for rare phases (approximately one per year) in the Ripple dataset corresponding to sudden rapid growth.\n\\item SpeedyMurmurs achieves \\emph{value privacy}, i.e., the value of a transaction remains hidden, as well as \\emph{sender} and \\emph{receiver privacy}, i.e., the identities of the two users remain hidden from the adversary.   \n\\end{itemize}\nIn summary, SpeedyMurmurs offers an effective, efficient, and scalable solution for privacy-preserving routing in PBT networks, thus being a promising candidate for upcoming deployment of such networks.  Our release of the initial results initiated a discussion about the deployment of SpeedyMurmurs or related algorithms in the context of the Lightning network.\\footnote{\\url{https://lists.linuxfoundation.org/pipermail/lightning-dev/2017-November/000798.html}}\n\n\\section{State of the Art and Limitations}\n\\label{sec:background}\n\nWe first briefly overview the notion of a PBT network. \nThen, we introduce the concepts of landmark routing and embedding-based routing, including the description \nof \\cnsysname~\\cite{malavolta17silent}, a PBT network based on landmark routing, and VOUTE~\\cite{roos2016anonymous}, an embedding-based routing algorithm, which we adapt to PBT networks in Section \\ref{sec:algo}. \n\n\\subsection{PBT Networks}\nIn a PBT network, pairs of \\emph{\\users} locally maintain links weighted with \napplication-dependent \\emph{\\money}. In the Lightning Network for instance, \ntwo \\users create a link by adding a \\emph{deposit} transaction in the blockchain \nand update such links by locally adjusting their deposit's value. \nThe Lightning Network thereby reduces the load on the blockchain and \nit has become the most promising alternative for scaling Bitcoin. \n\nThe payment operation in a PBT network involves a path of intermediate users \nwho adjust their links pairwise to effectively settle \\money between a \\sender and a \\receiver. \nIn the Lightning Network, each intermediate \\user increases her deposit's value\nwith \ntheir predecessor on the path by the transaction amount. \nSimilarly, she decreases the deposit's value \nwith her successor by the same amount. However, \na payment cannot be performed without a \\emph{routing} algorithm to find the path itself at first.\n\n\\subsection{Landmark Routing}\n\nThe landmark routing technique~\\cite{tsuchiya1988landmark} enables the computation of \na subset of paths between a sender and a receiver in a PBT network without relying\non the cost-intensive max-flow approach.\nThe key idea of landmark routing is to determine a path from sender to receiver through \nan intermediate node, called a \\emph{landmark}, usually a well-known node of high connectivity. \nUsing several such landmarks increases the number of computed paths between sender and receiver.\nWhile landmark routing does not discover all possible paths and hence might lead to a lower\nprobability for a successful payment, past work indicates that the decrease of success is small\nin comparison to the gain in performance~\\cite{viswanath2012canal,moreno15privpay}.\n\nInitially, each landmark starts two instances of the \nBreadth-First Search (BFS) algorithm, resulting in two spanning trees. In the first instance, only forward edges are considered and \nshortest paths from the landmark to each node are calculated. The second instance \nconsiders only reverse edges and results in shortest paths between each node and the landmark. \nAs PBT networks change over time, landmarks repeat this initialization process periodically.  \n \n \nThe path discovery between a sender and receiver then concatenates the path from the sender to the landmark\n(using reverse edges) and the path from the landmark to the receiver (using forward edges).   \nThe sender can send \\money along the path as long as the amount of \\money is at most as high as the available\ncredit on each link on the path. \n\nThere are two versions of landmark routing. The first version, which we call \\emph{landmark-centered}, always concatenates a path from the\nsource to a landmark and from the landmark to the destination.\nThe second version, which we call \\emph{tree-only routing},\ndiscovers the shortest path in the BFS tree, which does not necessarily contain a landmark. \n\n\\begin{figure*}[t]\n\\centering\n\\includegraphics[width=0.7\\linewidth]{routeAl}\n\n\\caption{Examples of different spanning tree routing schemes for landmark $lm$, sender $s$, receiver $r$.}\n\\label{fig:concepts-no-infer}\n\\vspace{-1em}\n\\end{figure*}\n\n\\subsubsection{Landmark Routing in SilentWhispers}\n\\cnsysname utilizes landmark-centered routing to discover multiple paths and then performs multi-party\ncomputation to determine the amount of \\money to send along each path. \nThe initialization of the landmark routing follows the above description, using multiple landmarks\nthat perform periodic BFSs. \n\nThe actual payment relies on two operations: a probe operation and the actual payment operation.\nWe here describe the probe operation as it performs the routing and decides on the credit to be transferred along each path.\nThe payment operation then merely executes the transfers suggested by the probe operation in a secure manner.  \n\nAt the core of the probe operation is a secret-sharing-based multiparty computation \nthat computes the credit available in a path. \nAfter discovering paths between sender and receiver using landmark routing, \neach pair of adjacent users in the path \nsends a share of their link's value to each of the landmarks. The sender and receiver must  \nconstruct additional shares that act as padding in order \nto hide the actual length of the path, and effectively preserve the identities of \nthe actual sender and receiver. \nWith the help of cryptographic signatures, relying on fresh keys to hide the identities of the nodes on the path,\nand using multiparty computation, the landmarks determine shares that the sender can combine to obtain the minimal available credit $z_i$ of the \\ith\\ path. \nIf the sum of the $z_i$ values \nis at least equal to the total payment amount, the sender assigns values $c_1, \\ldots , c_{\\numT}$ to the paths such that $c_i \\leq z_i$. \nThe result of the probe operation are these values $c_i$ and handles to\nthe paths,\nwhich the payment operation leverages to perform the actual transfer. \n\n\\subsubsection{Weaknesses of SilentWhispers}\nBased on the above description, we identify four issues related to the implementation of \nthe routing algorithm in SilentWhispers. \nFirst, the periodic tree creation (execution of BFS) \nfails to take into account changes in the network immediately, \nwhich can lead to significant failure rates due to outdated information. \n Moreover, periodic tree creation \n induces unnecessary overhead due to re-computation for parts of the PBT network that might not have changed.  \n\nSecond, as SilentWhispers relies on landmark-centered routing, all paths include the landmarks even if i) the \nsender and receiver of a payment are in the same branch, or \nii) there is a short path between sender and receiver but the links are not part of the spanning tree.  \nThus, the overall path used for the payment \ncan be unnecessarily long, leading to longer delays \nand a lower success ratio due to the increased chance of encountering \nat least one link without enough funds. \n\nThird, the probe operation requires that the nodes  included in a transaction path send \nshares to all landmarks. This means that the transaction overhead scales \nquadratically in the number of landmarks. \n\nFourth, \\cnsysname does not provide a suitable solution for concurrency.\nAssume that one or more probe operations aim to use the same link. \nThe probe operation can either provide the same amount of available credit for both links or block use\nof the link for some time after the first time a probe operation finds a path containing the link.\nThe former can lead to failures later on as the available credit, while sufficient for each transfer on its own, might not cover multiple transfers.  \nWhile a block prevents such complications, it increases the likelihood of failures because probe operations cannot use certain links, which might have enough credit to execute multiple transactions.   \n Hence, both approaches to concurrency have severe drawbacks. \n \nIn summary, landmark routing as used in \\cnsysname has various weaknesses that we aim to overcome in this work. \n\n\\subsection{Embedding-based Routing}\n\\label{sec:embedding}\n\nPeer-to-peer PBT networks differ from common peer-to-peer networks as the connections between peers are predefined and cannot be changed to improve the quality of the routing. Due to their fixed structure, peer-to-peer PBT networks are route-restricted and hence are closely related to Friend-to-friend (F2F) networks, which restrict connections to peers sharing a mutual trust relationship. As a consequence, we summarize the state-of-the-art approach to routing in F2F networks, namely embedding-based routing~\\cite{papadimitriou2004conjecture,roos2016anonymous}. \n\nEmbeddings rely on assigning coordinates to nodes in a network and having nodes forward packets based on the distances between coordinates known to that node and a destination coordinate.\nGreedy embeddings are similar to landmark routing in that they assign coordinates based on a node's position in a spanning tree. However, greedy embeddings disregard the spanning tree  after assigning the coordinates and in particular discover shorter paths using links that are not in the spanning tree. We refer to links that are not contained in the tree but are used during routing as \\emph{shortcuts}. When a node $v$ forwards a message  addressed to a destination coordinate,\n$v$ chooses the neighbor with the coordinate closest to the destination coordinate to forward the message to. Hence,  $v$ might either use a link in the spanning tree (forwarding to a child or parent), or a shortcut. \n\nDespite the fact that routes can contain shortcuts, there is no guarantee that routes with shortcuts exist. Hence, the links in the trees provide the guarantee that the routing works and removing any such links likely leads to failures. In the absence of shortcuts, embedding-based routing is identical to tree-only routing. As a consequence, it is important to adapt the tree when the nodes or links change. \n\nPrefix Embedding~\\cite{hofer2013greedy} is a greedy embedding that enables routing of messages in F2F overlays. \nAs illustrated in \\cref{fig:concepts-no-infer}, \nPrefix Embedding assigns coordinates in the form of vectors, starting with an empty vector at the landmark/root. \nEach internal node of the spanning tree enumerates its children and appends the enumeration index of a child to its coordinate to obtain the child coordinate.  \nThe distance between two such coordinates corresponds to the length of the shortest path in the spanning tree between them; i.e., the distance of two coordinates $\\id(u)$ and $\\id(v)$ with $|\\id(w)|$ denoting the coordinate length of node $w$ and  $\\var{cpl}(\\id(u),\\id(v))$ denoting the common prefix length is \n\\begin{align}\n\\label{eq:dist}\nd(\\id(u),\\id(v)) = |\\id(u)|+|\\id(v)|-2\\var{cpl}(\\id(u), \\id(v)).\n\\end{align}   \nBased on Eq.~\\ref{eq:dist}, nodes determine which neighbor is closest to the receiver in terms of their coordinates' distance and forwards a message accordingly.  \n\\cref{fig:concepts-no-infer} displays an example to illustrate the difference between various tree-based routing schemes and illustrates the coordinate assignment in Prefix Embedding. \n\n\\subsubsection{Prefix Embeddings in VOUTE}\nVOUTE~\\cite{roos2016anonymous} is a routing algorithm building upon Prefix Embedding with the goal of anonymous and efficient message delivery for a dynamic route-restricted network; i.e., a network that does not allow the establishment of links between arbitrary nodes.\nWe quickly describe how VOUTE addresses the issues of privacy and dynamics. \n\nPrefix Embedding reveals the unique coordinate of the receiver. In contrast, VOUTE allows nodes to provide \n\\emph{anonymous return addresses} instead of their original coordinates. A receiver generates a return address by padding its coordinate to a fixed length and generating keyed hashes of the coordinate's elements. The anonymous return address is then \ncomposed of the tuple (keyed hashes, key), where the key allows forwarding nodes to determine the common prefix length required in Eq.~\\ref{eq:dist}.  \nBased on the common prefix length of the receiver's coordinate $\\id(r)$ and a neighbor's coordinate $\\id(u)$, forwarding nodes can compute $d(\\id(u), \\id(r))+\\Delta$ with $\\Delta$ corresponding to the constant length of coordinates after the padding.\nHence, they can forward the message along the same path as when using clear-text coordinates, while maintaining the privacy of the receiver's true coordinates.\n\nThe original Prefix Embedding coordinates reflect an enumeration and hence have little entropy. As a consequence, VOUTE replaces the enumeration index with random $b$-bit numbers; e.g., for $b=128$. In this manner, guessing the coordinate of an unknown node becomes computationally unfeasible for an adversary.    \n\nRather than periodically reconstructing the spanning tree, VOUTE addresses dynamics with an on-demand stabilization algorithm. \nWhen constructing the tree, nodes send invitations to all neighbors stating their coordinate and offering to become a parent. \nEach node accepts one such invitation but keeps the most recent invitation of all neighbors to quickly react to network dynamics. \nIf nodes establish a new link, nodes already contained in the spanning tree offer invitations to their new neighbors. If a node is not yet part of the tree, it accepts the invitation. Otherwise, it stores it for future consideration.\nOn the other hand, if a link in the spanning tree ceases to exist, the child node and all its descendants choose a new parent based on their remaining invitations. They then disseminate their new coordinate to all neighbors.\nIn this manner, spanning trees and embeddings have an on-demand repair mechanism rather than periodic full re-computation as in landmark routing.  \n \n\n\\subsubsection{Limitations of VOUTE}\nVOUTE has not been defined in the context of PBT networks and therefore \npresents several limitations that must be overcome before considering \nit as a routing algorithm in PBT networks.\nIn particular, VOUTE has incompatible assumptions with regard to the nature of links and topology dynamics in a PBT network.  \n\nFirst, VOUTE considers \\emph{undirected} and \\emph{unweighted} links between pairs of users. In a PBT network instead, \nlinks are directed and weighted, as are payments. \nWhile all links allow message transfer in VOUTE, a link in a PBT network might not hold enough \\money\nto perform a payment. \nThe directed nature of the links indicates that VOUTE's construction algorithm is insufficient as it is unclear how to deal\nwith unidirectional links. If unidirectional links are part of the spanning tree, a node (and it descendants) might only be able to send\nor receive \\money but not both. \nThe weighted nature of links and the impossibility to use links for all payments contradicts one of the key assumptions of VOUTE's algorithm, namely that in the absence of link failures, all links can transfer messages. Therefore, to apply VOUTE in the context of PBT networks,\nit is necessary to design algorithms that deal with weighted links and transfers. \n\nSecond, VOUTE considers dynamics in the form of nodes joining and leaving the network. However, in PBT networks, the weights of the links are the main source of change. In particular, each successful transaction might change several links. A variant of VOUTE for PBT networks would likely be inefficient if it reacts to all of these changes. Deciding on when and how to adapt to changes of links is important for the design of such a variant.   \n\nFinally, VOUTE does not have to deal with concurrency issues. While concurrent message transfers might increase delay and congestion, they do not change the capacity of links and transmitting a message does not affect the ability of the link to transmit future messages. \nHowever, separated probe and payment operations as in \\cnsysname , creates concurrency issues. \\cnsysname provides insufficient solutions here, so we require a new concurrency algorithm.     \n\nIn summary, although VOUTE presents an interesting alternative to landmark routing as \nimplemented in SilentWhispers for the routing operation, its application in PBT network  \nscenarios is not straightforward. \n\\section{System Model and Goals}\n\\label{sec:model}\n\nWe start with a generic system model for distributed routing algorithms, followed by our privacy goals and our performance metrics. \n\n\\subsection{Our Model}\n\\label{sec:system-model}\n\nWe model a distributed \\paysys $(G,\\weight)$ as a \ndirected graph $G=(V,E)$ and a weight function $\\weight$ on the set of edges.  \nThe set of nodes $V$ corresponds to the participants of the \\paysys.\nA link (edge) from node $u$ to $v$ exists if $u$ can transfer funds to $v$. \nWe define the set of outgoing neighbors of a node $v$ as $N_{\\textit{out}}(v)=\\{u \\in V: (v,u) \\in E\\}$. Correspondingly, \nwe define the set of incoming neighbors of a node $v$ as $N_{\\textit{in}}(v)=\\{u \\in V: (u,v) \\in E\\}$. \nFurthermore, a path $\\pathvar$ is a sequence of links $e_1 \\ldots e_\\pathlength$ with $e_i=(v_{i}^1, v_{i}^2)$, \nand $v_{i}^2=v_{(i+1)}^1$ for $1\\leq i \\leq \\pathlength-1$. \nMoreover we denote by $\\lm=\\{\\lmid_1, \\ldots , \\lmid_{\\numT}\\}$ a set of nodes, called landmarks, \nthat are well known to other users in the \\paysys. We denote by $|\\lm|$ the size of the \nset $\\lm$.\n\n \nThe function $\\weight$ describes the amount of \\money that can be transferred between two nodes \nsharing an edge. We thereby abstract from the specific implementation of the function $\\weight$.  \nFor instance, in the Bitcoin Lightning Network, the function $\\weight: E \\rightarrow \\mathbb{R}$ defines the number of bitcoins\n$u$ can  transfer to $v$ in a payment channel opened between them. \n\nWe define the \\money available in a path $e_1, \\ldots, e_\\pathlength$ as the \\emph{minimum} $\\weight(e_i)$. \nMoreover, we define the the net balance of a node $v$ as \n$\\displaystyle{\\cnode(v)=\\sum_{u \\in N_{\\textit{in}}(v)} \\weight(u,v) - \\sum_{u \\in N_{\\textit{out}}(v)} \\weight(v,u)}$.\n\n\\subsubsection{Operations}\n\\label{sec:paysys-operations}\nRouting  in a \\paysys consists of a tuple of algorithms (\\setRoute, \\setC, \\routePay) defined as follows: \n\\begin{asparadesc}\n\\item $\\setRoute(\\lm)$: Given the set \n$\\lm=\\{\\lmid_1, \\ldots, \\lmid_{\\numT}\\}$ of landmarks, $\\setRoute$ initializes the routing information required by \neach node in the \\paysys. \n\n\\item $\\setC(c,u,v)$: Given the value $c$ and the nodes $u$ and $v$, $\\setC$ sets $\\weight(u,v) = c$. In addition, $\\setC$ might alter the routing information initially generated by \\setRoute. \n\n\\item $((\\pathvar_1, c_1), \\ldots, (\\pathvar_{|\\lm|}, c_{|\\lm|})) \\gets \\routePay(c,u,v)$. Given a value $c$, a sender $u$ and a receiver $v$, $\\routePay$ returns a set of \ntuples $(\\pathvar_i, c_i)$, denoting that $c_i$ \\money are routed through the path \ndescribed by $\\pathvar_i$. \n\\end{asparadesc}\n\n\\paragraph{Correctness}\nA key property of a PBT network is correctness. Intuitively, correctness indicates that the routing algorithm i) suggests to spend  the desired \\money $c$ rather than a higher value and ii) suggests paths that indeed have sufficient \\money.  \nLet $(\\setRoute, \\setC, \\routePay)$ be the routing operations \nof a \\paysys and let $\\pathlength_i$ denote the length of the \\ith\\ discovered path. \nWe say that the \\paysys is \\emph{correct} if for all results \n $((\\pathvar_1, c_1), \\ldots, (\\pathvar_{|\\lm|}, c_{|\\lm|}))$ of  \n$\\routePay(c,u,v)$, the following two conditions hold: \n\\begin{itemize}\n\\item $\\sum_{i} c_i \\leq c$\n\\item For each $\\pathvar_i := e_{i}^1, \\ldots, e^{\\pathlength_i}_i$ and each $e^{j}_i$, \n$c_i \\leq \\weight(e^{j}_i)$. \n\\end{itemize}\n\nWe note that the $\\routePay$ operation could return paths that contribute \n$\\sum_i c_i < c$, and it is still considered correct. This accounts for the cases \nwhere the \\paysys does not provide enough liquidity between the \nsender and receiver to perform a transaction. \n\n\\subsection{Attacker Model}\n\\label{sec:attacker-model}\n\nWe consider a fully distributed network.\nOur primary attack scenario is companies and individuals interested in a user's\nfinancial situation rather than governmental security agencies.\n The adversary controls a subset of the nodes in the network\neither by inserting its own nodes or corrupting existing nodes. \nWe assume that the adversary cannot choose the set of users at will, as some users will\nbe harder to corrupt by social engineering or malware attacks.  \nIn general, we assume that the attacker does not know \\emph{all} links and nodes in the network and\nin particular cannot access routing information locally stored at non-compromised nodes. \nThe assumption that the attacker does not know the complete topology of a large-scale distributed\nsystem with participants from a multitude of regions and countries seems realistic for our attack\nscenario. If we indeed have an adversary that knows the full topology, we might not be able to hide\nthe identities of sender and receiver but can still hide the transaction value. \n \nOur adversary aims to undermine the privacy rather than perform a large-scale denial-of-service attack.\nWe argue that the primary defense against denial-of-service attacks is detection and expulsion of\nmalicious nodes. While related to routing, different operations are required\nfor realizing detection and expulsion, and they are out of scope for this paper. \n\n While our overall adversary model limits the adversary's capacities, \n we nonetheless define our value privacy goals for an attacker that has a global view of the topology, \n indicating that we can still achieve some privacy against a stronger adversary. \n\n\\subsection{Privacy Goals}\n\\label{sec:privacy-goals}\nThe hope that cryptography and decentralization might ensure robust privacy \nwas among the strongest drivers of Bitcoin's and blockchains' early success. \nWe expect businesses and customers employing the PBT networks to be interested \nin hiding their transactions from competitors and even service providers. \nTherefore, ensuring privacy for path-based transactions is important.\n\nLike PrivPay~\\cite{moreno15privpay}, SilentWhispers~\\cite{malavolta17silent}, Fulgor~\\cite{malavolta17PCN}, and Rayo~\\cite{malavolta17PCN}, we aim to hide values (\\textit{value privacy}), \nand the identities of sender and receiver (\\emph{sender/receiver privacy}) of\npath-based transactions.  We use the term \\emph{transaction privacy} to\nrefer to meeting all three of these notions.\nNext, we informally describe these privacy properties for PBT networks, and refer the readers to the PrivPay paper~\\cite{moreno15privpay}\nfor the formalized versions defined in the context of credit networks.\n\n\\paragraph*{Value Privacy} \nA PBT network achieves value privacy if\nit is not possible for any adversary to determine the total\nvalue of a transaction between non-compromised users\nas long as none of the employed intermediate nodes is compromised.\n\nLet $s$ and $r$ be two non-compromised users, and let $(\\pathvar_1, c_1),\n\\ldots, (\\pathvar_{|\\lm|}, c_{|\\lm|})$ be the result of a $\\routePay(c,s,r)$ operation. \nIf for every path $\\pathvar_i$, \nall nodes on that path are non-compromised, \nthe adversary (even a global passive adversary) \nobtains no information about the transaction value $c$. \n\nNotice that, as elaborated in Section~\\ref{sec:privacy},\nwe can provide a weaker form of value privacy even when the adversary compromises some intermediate nodes\nas long as all nodes on at least one of the employed paths remain non-compromised.\n\n\\paragraph*{Sender Privacy} \nA PBT network achieves sender privacy if\nit is not possible for any adversary to determine the sender \nin a path-based transaction between non-compromised users.\n\nIn particular, for two non-compromised users $s$ and $r$, \nthe attacker should not be able to determine the sender $s$ of any routing operation $\\routePay(z,s,r)$,\nunless she has complete knowledge of $s$'s incoming links %local topology and can eavesdrop on all those links;\ni.e., she knows the set $N_{\\textit{in}}(s)$ though not necessarily the funds of the links  $e \\in N_{\\textit{in}}(s)$.\n\nNote that although the local attacker without a global view of the network might know (and even control) all nodes in $N_{\\textit{in}}(s)$,\nshe might not be aware that she does control {\\em all} such nodes. As a consequence, similar to P2P anonymity systems \\cite{Crowds,AP3,ShadowWalker}, \ncontrolling all neighbors does not automatically mean she can be sure that \n$s$ did initiate the routing.\nTherefore, we expect the sender privacy to hold even when the attacker controls all nodes in $N_{\\textit{in}}(s)$ \nfor the sender $s$ but does not know that she does control the whole set.\n\n\\textit{Receiver Privacy} is defined analogously to sender privacy, and the adversarial assumptions also remain the same except that instead of \nneighboring nodes  $N_{\\textit{in}}(s)$  of the sender $s$, now for receiver privacy, we  consider  $N_{\\textit{out}}(r)$  of the receiver $r$.\n\n\\subsection{Performance Metrics}\nIn this section, we describe the performance goals to be achieved by a routing algorithm, which we \ndenote generically by $\\TA$. In the following, \nwe denote by $(G_t, \\weight_t)$ the snapshot of a \\paysys at time $t$. Note that although \nwe abstract away the payment and accountability algorithms in this work, a \\paysys must \nimplement them and therefore a \\paysys is dynamic. Let $\\{(t_i,c_i,s_i,r_i)\\}$\nbe a set of payment requests from $s_i$ to $r_i$ for an amount $c_i$ at time $t_i$. \n\nThe performance of a routing algorithm $\\TA$ is characterized by the following four metrics:\n\\begin{itemize}\n\\item \\textbf{Success ratio}: \nLet $((\\pathvar_1, c_1), \\ldots,$ $(\\pathvar_{|\\lm|}, c_{|\\lm|}))$ be the set of paths \nreturned by $\\routePay(c, s, r)$ as implemented in $\\TA$. We consider the transaction successful \nonly if $\\sum_i c_i = c$.  The success ratio describes the fraction of transactions  \nthat are successful.\\footnote{This inherently assumes a payment algorithm that always succeeds \nafter a route with enough credit has been found. We thereby abstract away the details of the \npayment algorithm.} \n \n\\item \\textbf{(Hop) Delay}: The delay of $\\TA$ with regard to a transaction $(t_i,c_i,s_i,r_i)$ is the difference between the time of termination and the initiation time $t_i$. In the absence of a concrete implementation including realistic computation and communication latencies, we provide an abstract measurement of the delay as follows. Let $m_1$ and $m_2$ be messages sent by $\\TA$. We say $m_2$ is \\emph{subsequent} to $m_1$ if a node sends $m_2$ as a result of receiving $m_1$. The hop delay is the length of the longest chain of subsequent messages sent by $\\TA$.\n\\item \\textbf{Transaction Overhead}: Nodes exchange messages to execute a transaction $(t_i,c_i,s_i,r_i)$. The transaction overhead denotes the number of exchanged bits. \nAs before, in the absence of a concrete implementation, we abstract it by assuming equal-sized messages for each implementation and stating the number of messages as the overhead. \n\\item \\textbf{Stabilization Overhead}: Analogously to the transaction overhead, the stabilization overhead corresponds to the number of bits sent within a certain time interval to maintain necessary state information, \nas required by the implementation of the operation $\\setRoute()$ in $\\TA$. Again, we abstract from the concrete implementation by stating the number of messages instead of the number of bits. \n\\end{itemize}\nThe first two metrics heavily impact the perceived quality of service while the latter two directly relate to network congestion and hence impact the delay. Furthermore, the overhead determines the load on the user devices.  \n\n \n\n \n\n \n \n\n\\section{Our Construction}\n\\label{sec:algo}\n\nIn this section, we first describe the key ideas of our design and then detail  the three operations in our routing algorithm. We present pseudocode for centralized versions of the algorithms, which allows presenting the algorithms in a linear compact manner. We then describe how the distributed versions used within a PBT network differ from the centralized version. \n\n\\subsection{Assumptions}  \nEach user in the \\paysys locally maintains the information of the links with her neighbors. We \nfurther assume that users sharing a link can send messages to each other through an \nauthenticated and confidential communication channel. Moreover, we assume that there exist \na set of nodes, called landmarks, that are well known to other users in the \n\\paysys. We note that these assumptions are in tune with other distributed \\paysyss such as \nSilentWhispers.\n\nThroughout this section, we refer to links that have non-zero funds in both directions, i.e., links $(u,v)$ and $(v,u)$\nwith $\\weight(u,v)>0$ and $\\weight(v,u)>0$ as bidirectional. $u$ and $v$ have a unidirectional link if one of the two links does not exist or has zero funds. \n\n\\subsection{Overview and Key Ideas}\n\nWe here describe the key ideas of \\oursys with regard to the operations \\setRoute, \\setC, and \\routePay.\nIn particular, we focus on the predominant differences to existing algorithms. \n\n\\paragraph*{\\setRoute}  \nIn this algorithm, we construct multiple embeddings, one for each landmark. \nAs mentioned in Section~\\ref{sec:embedding}, VOUTE offers an algorithm for BFS-based coordinate assignment that assumes unweighted and undirected links. We modify this algorithm by dividing it into two phases.\nFirst, we only add bidirectional links. In the second phase of the algorithm, nodes that are not yet part of the spanning tree join by adding unidirectional links to the spanning tree.  \n \n\n\\paragraph*{\\setC} We first change the weight of the link and then adapt the embedding accordingly. \nVOUTE does not provide any guidance on how to react to changes of weights. In agreement with \\setRoute , we decided to only initiate changes if the two nodes i) established a new link of non-zero weight (or set the value of link from 0 to a non-zero value), and ii) removed a non-zero link (or set its value to 0). \nIf they established a new link, one of the nodes can choose the other as a parent if it does not have a parent or the link to its current parent only has credit in one direction. In contrast, if a link is removed, one of the nodes has to select a new parent (and coordinate) if the other node previously was its parent. Furthermore, any descendants of the affected node have to change coordinates.   \n\n\\paragraph*{\\routePay} The routing consists of three steps: i) the receiver generates anonymous return addresses and sends them to the sender,\nii) the sender randomly splits the transaction value on $|\\lmid|$ paths, one for each landmark, and iii)\nVOUTE's routing algorithm finds a path between sender and receiver, restricted to links that have sufficient funds.  \nOur algorithm allows a flexible choice of routes, preferring paths with high funds. Determining the \\money transferred along each path beforehand enables nodes to block a certain amount of credit during the probe operation and ensure that the subsequent payment succeeds without blocking all of the link's funds.  \n \n\n \n\n\\subsection{Detailed Description}\n\n\\paragraph*{\\setRoute}  \nIn the initialization phase, described in Algorithm~\\ref{algo:embedCen}, we derive the embeddings. \nIterating over all landmarks, Algorithm~\\ref{algo:embedCen} assigns the landmark coordinate to be the empty vector (Line~\\ref{algo:initEmpty}) and appends the landmark to a  queue (Line~\\ref{algo:queueL}). The main loop of the algorithm then processes the queue. In each step, the algorithm removes a node from the queue (Line~\\ref{algo:removeHead}) and considers all its neighbors. If a neighbor $n$ does not have a coordinate yet and is eligible to have one, the algorithm integrates $n$ into the spanning tree, assigns a coordinate by concatenating the parent coordinate and a random $b$-bit number, and appends it to the queue (Lines~\\ref{algo:parent}-\\ref{algo:queueN}).   \nThe criterion determining the eligibility to be part of the spanning depends on the phase of the algorithm: Initially ($\\var{bi}=\\var{true}$, Line~\\ref{algo:bi}), a node is eligible if the available credit on the link to and from its potential parent is non-zero. In the second phase of the algorithm ($\\var{bi}=\\var{false}$), triggered by an empty queue (Lines~\\ref{algo:uni}--\\ref{algo:endif}),  all nodes can join the spanning tree. Note that Algorithm~\\ref{algo:embedCen} does not prevent a child from choosing a parent such that they do not have funds in either direction. As such links do not serve any purpose in a PBT network, we assume that the network does not allow them. Alternatively, Algorithm~\\ref{algo:embedCen} can check if the funds on a unidirectional link is non-zero before allowing a parent-child relation.  \nThe algorithm terminates once the queue is empty, indicating that all nodes in a connected graph have coordinates. \n\n\\begin{algorithm}[t]\n\\caption{\\setRoute}\n\\label{algo:embedCen}\n\\begin{algorithmic}[1]\n\\STATE \\# Input: Graph $G$, landmarks $\\lmid_1, \\ldots ,\\lmid_{\\numT}$\n\\FOR{$i=1$ \\TO $\\numT$ } \n\\STATE $\\id_i(\\lmid_i)=()$ \\label{algo:initEmpty}\n\\STATE $q=$ empty queue\n\\STATE add $\\lmid_i$ to $q$ \\label{algo:queueL}\n\\STATE $\\var{bi}=\\var{true}$ \\# first consider nodes with links in both directions  \\label{algo:bi}\n\\WHILE{$q$ is not empty}\n\\STATE $\\var{node} =$ remove head of $q$ \\label{algo:removeHead}\n\\FORALL{$n$: neighbors of node}\n\\STATE $n$ stores $\\id_i(\\var{node})$\n\\STATE \\# Assign coordinate if $n$ does not have one  \n\\IF{$\\id_i(n)$ is not set}\n\\IF{($\\weight(\\var{node},n)>0$ \\AND $\\weight(n,\\var{node})>0$) \\OR\n$!\\var{bi}$}\n\\STATE $\\var{parent}_i(n)=node$ \\label{algo:parent}\n\\STATE $n$ chooses random $b$-bit number $r$\n\\STATE $\\id_i(n)=\\var{concatenate}(\\id_i(\\var{node}), r)$ \n\\STATE add $n$ to $q$ \\label{algo:queueN}\n\\ENDIF\n\\ENDIF\n\\ENDFOR\n\\STATE \\# Add nodes with unidirectional links \\label{algo:uni} \n\\IF{$q$ is empty \\AND $\\var{bi}$}\n\\STATE $\\var{bi}=\\var{false}$\n\\STATE add all nodes $n$ with $\\id_i(n)$ set to $q$ \n\\ENDIF \\label{algo:endif} \n\\ENDWHILE\n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\nIn a distributed scenario, there are no central queues. Rather, nodes send messages to their neighbors when they join a spanning tree. Each message includes the index $i$ of the tree and the coordinate $\\id_i(\\var{node})$ of the potential parent.\nStarting the second phase is tricky in a distributed scenario and will not be simultaneous for all nodes. Rather, we choose a time limit $\\tau$ that represents an upper limit on the time the initialization should take. If a node $n$ receives a message of the form  $(i,\\id_i(\\var{node}))$ from a neighbor $node$ with only one link of non-zero weight, $n$ waits for time $\\tau$. If none of $n$'s neighbors with bidirectional links to $n$ indicate that they are potential parents until the waiting period ends, $n$ selects $node$ as its parent. \n\n\\paragraph*{\\setC}\n\n\\setC\\ reacts to a pair of nodes $(u,v)$ that want to change the value of their shared link to $c$. \nAlgorithm~\\ref{algo:setC} first determines if the value change should lead to coordinate changes.\nIn total there are three situations that indicate a need for a coordinate change:\n\\begin{enumerate}\n\\item New non-zero unidirectional link: One of the nodes is not yet part of the tree and should hence choose the other as their parent (Lines~\\ref{algo:unsetSt}--\\ref{algo:unsetEnd}) to be able to participate in the routing.\n\\item New non-zero bidirectional link: $u$ and $v$ share a bidirectional non-zero link and (without loss of generality) $u$ has only a unidirectional link to its current parent. Then $u$ should change its parent to $v$ if $v$ has a bidirectional link to its parent (Lines~\\ref{algo:uniSt}--\\ref{algo:uniEnd}). In this manner, a bidirectional connection replaces a unidirectional link in the spanning tree and increases the likelihood of successfully transferring \\money. \n\\item Removed link: $u$ is a child of $v$ or $v$ is a child of $u$ (Lines~\\ref{algo:rmSt}--\\ref{algo:rmEnd}). The child node should select a new parent to increase the number of non-zero links in the spanning tree and the likelihood of transferring \\money. \n\\end{enumerate}\n\n\\begin{algorithm}[t]\n\\caption{$\\setC$}\n\\label{algo:setC}\n\\begin{algorithmic}[1]\n\\STATE \\# Input: Graph $G$, $u,v \\in V$, new value $c$\n\\STATE $\\var{old} = \\weight(u,v)$ \\# Previous value of $\\weight(u,v)$\n\\STATE \\# check if coordinate change necessary \n\\FOR{$i=1$ \\TO $\\numT$ }\n\\STATE $\\var{reset}=\\var{null}$ \\# node whose coordinate should change \n\\STATE \\# case:add link\n\\IF{$old==0$ \\AND $c>0$}\n\\STATE \\# If one node does not have a coordinate \\label{algo:unsetSt}\n\\IF{$\\id_i(v)$ is not set and $\\id_i(u)$ is set}\n\\STATE $\\var{reset}=v$\n\\ENDIF \n\\IF{$\\id_i(u)$ is not set and $\\id_i(v)$ is set}\n\\STATE $\\var{reset}=u$\n\\ENDIF \\label{algo:unsetEnd}\n\\STATE \\# One node has unidirectional link to parent \\label{algo:uniSt}\n\\IF{$\\var{reset}=\\var{null}$}\n\\IF{$\\weight(u,v)>0$ \\AND $\\weight(v,u)>0$}\n\\STATE $a_1=$ $\\big(\\weight(u, \\var{parent}_i(u))==0$ \\OR\\\\ \\hspace{2.5em} $\\weight(\\var{parent}_i(u),u)==0\\big)$\n\\STATE $a_2=$ $\\big(\\weight(v, \\var{parent}_i(v))==0$ \\OR\\\\ \\hspace{2.5em} $\\weight(\\var{parent}_i(v),v)==0\\big)$\n\\IF{$a_1$ \\AND $!a_2$}\n\\STATE $\\var{reset}=v$\n\\ENDIF\n\\IF{$a_2$ \\AND $!a_1$}\n\\STATE $\\var{reset}=u$\n\\ENDIF\n\\ENDIF\n\\ENDIF \\label{algo:uniEnd}\n\\ENDIF\n\\STATE \\# case:remove link\n\\IF{$\\var{old}>0$ \\AND $c==0$}\n\\IF{$\\var{parent}_i(u)==v$} \\label{algo:rmSt}\n\\STATE $\\var{reset}=u$\n\\ENDIF\n\\IF{$\\var{parent}_i(v)==u$} \n\\STATE $\\var{reset}=v$\n\\ENDIF \\label{algo:rmEnd}\n\\ENDIF\n\\STATE \\# change coordinates\n\\IF{$\\var{reset}$ != $\\var{null}$}\n\\STATE delete coordinates of $\\var{reset}$ and descendants\n\\STATE have nodes choose new parent\n\\ENDIF \n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\nIf one of $u$ or $v$ changes its parent, all descendants remove their coordinates and inform their neighbors of the removal. \nAfterwards, they all choose a new parent and corresponding coordinate. In agreement with the initialization \\setRoute , nodes first consider only neighbors to whom they have non-zero links in both directions. However, if a node does not have such links to any neighbor, it considers links in one direction. If they have several suitable parents, they choose their parent randomly from those candidates with the shortest coordinates, as having short routes to the landmark reduces the lengths of paths~\\cite{roos2016anonymous}. \nAfter choosing a new coordinate, nodes forward the new coordinate and the tree index to all their neighbors. We do not present the pseudocode, as it is very similar to Algorithm~\\ref{algo:embedCen}.\n\nThe distributed variant of Algorithm~\\ref{algo:setC} follows the same principles but requires the exchange of messages for nodes to communicate information. $u$ and $v$ exchange information about the link to their parents. Each of them then individually decides if they want to add or remove the other as a parent. \nStarting from the node $\\var{reset}$ that aims to reset its coordinate, all descendants inform their neighbors first that they remove their old coordinate for the tree $i$. Children of a node in turn remove their own coordinate and send the respective messages. In the second phase, nodes select their new coordinates and inform their neighbors. \nAs the two phases are likely to run in parallel in the distributed setting, nodes have to ensure that they do not choose a previous descendant as a parent before the descendant chooses a new coordinate. However, the nature of the coordinates makes it easy to prevent such cycles in the tree by disallowing a node $v$ from choosing a parent whose coordinate contains $v$'s previous coordinate as a prefix. \n\n\\paragraph*{\\routePay}\n\\routePay\\ discovers a set of paths from the sender to the receiver. It corresponds to the probe operation in \\cnsysname. Algorithm~\\ref{algo:route} divides the process into three steps: i) generation of receiver addresses (Lines~\\ref{algo:addSt}--\\ref{algo:addEnd}), ii) splitting the total transaction value $c$ randomly on $\\numT$ paths, and iii) finding paths for all embeddings that can transmit the required value. \n\nFirst, the receiver generates anonymous return addresses $\\var{add}_1, \\ldots , \\var{add}_{\\numT}$ for all landmarks and sends them to the sender (Lines~\\ref{algo:addSt}--\\ref{algo:addEnd}).\nSecond, the sender splits the transaction value randomly between all paths (Line~\\ref{algo:split}). By defining a per-path value before routing, we i) avoid the costly multiparty computation of \\cnsysname and ii) allow the algorithm to choose between several possible routes. Avoiding the multiparty computation of the minimum also removes a privacy leakage, as knowing the minimum value of funds available on the complete path naturally reveals information about the individual links.  \n\nThird, the route discovery starts at $v$ and each node selects a neighbor to be the next node on the route. In VOUTE, each node would select the neighbor with the coordinate closest to the destination, using the function $\\tilde{d}$ that compares a coordinate with an anonymous return address.  \n However, such a choice might not be suitable for routing \\money as the link might have insufficient available credit. As a consequence, the routing only considers links $(v,u)$ with \\emph{guaranteed} available credit $\\weight_A(v,u)$ of at least $c_i$ (Line~\\ref{algo:CSt}). We differentiate between available credit $\\weight(v,u)$ and  \\emph{guaranteed} available credit to deal with concurrency. $\\weight_A(v,u)$ is a lower bound on the available credit if ongoing probe operations succeed.\nInitially, $\\weight_A$ equals the actual available credit $\\weight$. We do not include the initialization in Algorithm~\\ref{algo:route} as multiple concurrent executions of \\routePay\\ can impact $\\weight_A(v,u)$ and the algorithm might start with $\\weight_A(v,u)<\\weight(v,u)$.  \nIf a probe operation indicates that a payment will transmit \\money $c_i$ along a link $(v,u)$, \nwe proactively decrease the \\emph{guaranteed} available credit by $c_i$ (Line~\\ref{algo:potA}) to keep future routings from using the link unless they require at most the guaranteed available credit. \nIf the routing fails, we add $c_i$ to $\\weight_A(v,u)$ again (Lines~\\ref{algo:rePotSt}--\\ref{algo:rePotEnd}). \nThe routing fails if a node $v$ cannot find a neighbor with a coordinate closer to the destination than $v$'s coordinate and a link of sufficient guaranteed available credit.     \n\n   \n\n\\begin{algorithm}[t]\n\\caption{\\routePay}\n\\label{algo:route}\n\\begin{algorithmic}[1]\n\\STATE \\# Input: Graph $G$, sender $\\var{src}$, receiver $\\var{dst}$, value $c$\n\\STATE \\# get addresses \\label{algo:addSt}\n\\FOR{$i=1$ \\TO $\\numT$ } \n\\STATE use VOUTE's algorithm to generate return address $\\var{add}_i(\\var{dst})$ \n\\STATE $\\var{dst}$ sends $\\var{add}_i(\\var{dst})$ to $\\var{src}$\n\\ENDFOR \\label{algo:addEnd}\n\\STATE \\# value shares for each path \n\\STATE $\\var{src}$ splits $c$ into shares $c_1, \\ldots , c_{\\numT}$ \\label{algo:split}\n\\STATE \\# routing \\label{algo:rSt}\n\\STATE $\\var{path}_i =$ empty list of links \n\\FOR{$i=1$ \\TO $\\numT$ } \n\\STATE $v=\\var{src}$\n\\STATE $\\var{fail}=\\var{false}$\n\\WHILE{$!\\var{fail}$ \\AND $v$ != $\\var{dst}$}\n\\STATE $C=\\{u \\in N(v): \\tilde{d}(\\id_i(u), \\var{add}_i(\\var{dst}))< \\tilde{d}(\\id_i(u), \\var{add}_i(\\var{dst})), \\weight_A(v,u)\\geq c_i\\}$ \\label{algo:CSt}\n\\IF{$C$ not empty}\n\\STATE $\\var{next}=$ $u$ in $C$ with minimal $\\tilde{d}(\\id_i(u), \\var{add}_i(dst))$ \\label{algo:CEnd}\n\\STATE $\\weight_A(v,u)=\\weight_A(v,u)-c_i$ \\label{algo:potA}\n\\STATE $v=\\var{next}$\n\\ELSE\n\\STATE $\\var{fail}=\\var{true}$ \\# Routing failed\n\\ENDIF\n\\ENDWHILE \\label{algo:rEnd}\n\\ENDFOR\n\\IF{routing failed} \\label{algo:rePotSt}\n\\FORALL{$i=1\\ldots \\numT$, $e \\in \\var{path}_i$}\n\\STATE $\\weight_A(e)=\\weight_A(e)+c_i$\n\\ENDFOR\n\\ENDIF \\label{algo:rePotEnd}\n\\end{algorithmic}\n\\end{algorithm}\n\nAlgorithm~\\ref{algo:route} achieves correctness, as defined in Section~\\ref{sec:model}, because i) $\\sum_{i=1}^{\\numT} c_i = c$ and ii) nodes always select links $e$ with $\\weight(e)\\geq\\weight_A(e)\\geq c_i$ on the \\ith\\ path.   \n\nIn the distributed variant of Algorithm~\\ref{algo:route}, nodes send messages to the next node on the path, which contain the address $\\var{add}_i$ and the partial value $c_i$. Nodes report failures and successes to the sender by sending messages along the reverse path. \nTo account for messages getting lost, nodes also reset $\\weight_A$ if a payment operation does not follow a probe operation within a certain time. \n\n\\subsection{Parameters}\nSeveral parameters govern the performance of the above routing algorithm. First, the number $\\numT$\nof landmarks determines the number of returned paths. The transaction and stabilization overhead increases roughly linearly with $\\numT$ as routing and stabilization is required for each landmark. Similarly, the delay corresponds to the longest route in any embedding and hence is likely to increase with $\\numT$. \nThe impact of $\\numT$ on the success ratio highly depends on the scenario. \nThe second parameter is $\\numA$, the number of transaction attempts. \nA sender $s$ can attempt to perform a transaction up to $\\numA$ times.\nOnly if all attempts fail, $s$ considers the transaction failed. \n$s$ chooses the interval between two consecutive attempts uniformly at random within an interval of length $\\tl$.\nA repeated transaction attempt executes the above routing algorithm for the same sender, receiver, and value but uses different shares $c_1, \\ldots , c_{\\numT}$. \nIn addition to the parameters $\\numT$, $\\numA$, and $\\tl$, the choice of the landmarks impacts the performance.\nCommonly, landmarks are nodes corresponding to financial institutions and hence have a large number of links, possibly leading to spanning trees of a lower depth and a higher performance. \nWe characterize the impact of these parameters in our performance evaluation.  \n\n   \n\\subsection{Privacy Analysis}\n\\label{sec:privacy}\n\nNext, we argue that \\oursys achieves the privacy goals \nproposed in~\\cref{sec:privacy-goals}. \n\n\\paragraph*{Value Privacy} Informally, we say that a \\paysys achieves value privacy if \nthe adversary cannot determine the value $c$ of a $\\routePay(c,u,v)$ operation between \ntwo non-compromised users $u$ and $v$, if the adversary is not sitting in any of the \ninvolved routing paths. \n\n\\oursys is a distributed \\paysys and, in particular, the $\\routePay$ is defined \nsuch that only users in the paths  \nbetween the sender and receiver are involved. Therefore, if the adversary does not \ncompromise any such users, she does not get any information about the \nrouted value (because the point-to-point communications are encrypted) and thereby value privacy is achieved.   \n\nAn alternative scenario appears when the adversary corrupts users \nin some of the paths between sender and receiver, but not all. \nIn such a case, we cannot prevent the adversary from estimating $c$. As we have $c_i\\geq 0$ for all $i=1\\ldots \\numT$, knowing a subset of these values naturally reveals information about the total value $c$, namely that $c \\geq c_i$. Moreover, as  \\oursys shares the value $c$ uniformly among the paths and uses \nonly positive shares, an adversary can estimate $c$ as $\\numT * c_i$ upon observing $c_i$. \n\n\\paragraph*{Sender Privacy} Informally, we say that a \\paysys achieves sender privacy if an adversary \ncannot determine the sender $u$ in a $\\routePay(c,u,v)$ operation. The adversary might compromise intermediate users\non the paths discovered by $\\routePay(c,u,v)$ but does not compromise $u$ or $v$.   \n\nAn attacker sitting on the path between sender $s$ and receiver $r$ might receive an anonymous \nrouting address $add_i$ (e.g., the adversary managed to corrupt the sender's neighbor). \nNevertheless, as \\oursys is a distributed \\paysys, \nthe adversary cannot determine whether the actual sender is $s$ or \nanother user $s'$ connected to $s$ through a direct link or a path of non-compromised users.\nSender privacy follows from the corresponding proofs for VOUTE~\\cite{roos16voute}. \n\n\\paragraph*{Receiver Privacy} Informally, we say that a \\paysys achieves receiver privacy if an adversary \ncannot determine the receiver $v$ in a $\\routePay(c,u,v)$ operation. The adversary might compromise intermediate users\non the paths discovered by $\\routePay(c,u,v)$ but does not compromise $u$ or $v$.   \n\nAs before, the adversary compromising the \\user before the receiver $r$ might relay\nto $r$  \nan anonymous return address. Nevertheless, as shown in\nthe \nevaluation of VOUTE, \nan anonymous return address does not \nleak the corresponding user in the network. Therefore, \nthe adversary cannot fully determine yet if \n$r$ is the actual receiver, or the routing message is intended for another receiver $r'$ connected \nto $r$ through a direct link or a path of non-compromised users.\n\n \n\n\\subsection{Summary}\n\nIn this section, we introduced \\oursys , which proposes a privacy-preserving routing algorithm for PBT networks. Our key contributions in modifying VOUTE to the scenario of credit networks are i) the use of a two-phase construction algorithm to account for the existence of unidirectional links (Algorithm~\\ref{algo:embedCen}), ii) the identification of criteria on when to apply on-demand maintenance (Algorithm~\\ref{algo:setC}), iii) the design of a path discovery algorithm that can adaptively choose links based on both the available credit and the coordinates of the neighboring nodes and can handle concurrency (Algorithm~\\ref{algo:route}).\nApart from using embedding-based routing, \\oursys distinguishes itself from \\cnsysname by splitting the credit between paths before the path discovery. In this manner, nodes can base their forwarding decisions on the amount of credit they should forward rather than only their neighbors' distances to the destination.  On the other hand, distributing funds before the path discovery prevents the algorithm from taking the overall available funds on the path into consideration. In the next section, we evaluate the impact of our design decisions on efficiency and effectiveness, analyzing in particular how the order of routing and fund distribution relates to the success ratio. \n\n\\section{Performance Evaluation}\n\\label{sec:simu}\n\nIn this section, we evaluate the performance of \\oursys in comparison to the related work, in particular \\cnsysname ' landmark-centered routing.\n\nMore precisely, we aim to answer the following research questions:\n\\begin{itemize}%[leftmargin=*]\n\\item How do \\oursys and \\cnsysname perform with regard to success ratio, delay, and overhead using a real-world dataset?\n\\item \\oursys and \\cnsysname differ in three major areas---routing algorithm, random credit assignment, and dynamic stabilization.  What is the impact of each of these modifications on the above performance criteria?\n\\item How do these results compare to the performance of other approaches? \n\\item What is the impact of the landmark selection, the number of trees, and the number of transaction attempts?\n\\item How does the long-term evolution of the credit network affect the performance? \n\\end{itemize}\n\nWe start by describing our simulation model and datasets. Afterwards, we specify the parameters of our simulation. \nFinally, we present and discuss our results. \n\nGenerally, our simulation executes the routing algorithm and performs the payment (if successful). \nWe include the payment to realistically assess the stabilization overhead due to link changes.  \nHowever, we did not implement any security measures that are usually part of the payment because they do not affect the routing algorithm and its performance. \nIn particular, we do not execute the link setup algorithm that ensures that neighboring nodes agree on the value of their link and later can settle disputes by providing signed statements of the changes. \n\n\\subsection{Simulation Model}\n\nWe extended GTNA~\\cite{schiller2013gtna}, a framework for graph analysis, to include our credit transaction mechanisms.\nIn particular, GTNA offers templates for routing algorithms and performance metrics.\nWe added functionality specific to PBT networks, in particular the functionality to dynamically update link weights.\n\nInitially, our simulation constructs a credit network with nodes and links according to a provided description. \nAfterwards, we simulate a sequence of events in the credit network.\nA list of transactions, changes to links, and periodic re-computations of the spanning tree (only required for \\cnsysname), ordered\nby their temporal occurrence, determined the sequence of events. \nIn the absence of realistic latency and bandwidth models, we did not model concurrency in our simulation.\nThe simulation executed each event, including resulting changes to the spanning trees, before starting the next event.\n\nWe implemented two simulation modes. First, we considered a static credit network. In each step, the simulation executed a transaction and subsequently repaired the spanning tree if dynamic stabilization was applied. Afterwards, it returned the credit network to its original state. \nSecond, we considered a dynamic network evolving over time. Transactions, node churn, and modifications of the extended credit changed\nthe structure of the network and the weights on the links. \nWhile the second mode was more realistic, it prevented a straightforward comparison of different approaches for individual transactions due to the differences in state at the time of the transaction.\n\nWe implemented the routing and stabilization algorithms of \\cnsysname and \\oursys as specified in Sections~\\ref{sec:background} and \\ref{sec:algo}, respectively. \nHowever, we disregard the cryptographic details\nfor our evaluation, as they do not affect our performance metrics. Instead, the \\sender and \\receiver both send only one message to each landmark forwarded by all nodes on the shortest path to the landmark. \nIn our implementation of \\cnsysname , each landmark then sends a message to all remaining landmarks, which is forwarded along the shortest paths, to account for the multi-party computation.\nWhen combining embedding-based routing with multi-party computation, the \\receiver sends messages to all landmarks.\nIn addition to enabling the evaluation of each individual modification, the alignment of the two designs also resulted in a fairer comparison of overheads, as the original \\cnsysname sends all elements of a signature chain individually and thus results in a higher overhead as compared to sending them in one message.\nAs \\cnsysname ' authors do not specify how the \\sender decides on the amount of partial credit $c_i$ assigned to the \\ith\\ path, \nwe decided to divide the total credit randomly between paths in agreement with the available minimum. In other words, if the sum of all minimal values was at least equal to the total transaction value $c$, we first divided $c$ randomly upon the paths.  We then randomly re-assigned all credit that exceeds the minimal value along a path to the remaining paths. We repeated the re-assignment step until the partial credit of each path was at most equal to the minimal credit on the path. \nDuring the simulation, we recorded all information necessary to derive the performance metrics described in Section~\\ref{sec:model}.\n\nFor \\oursys and \\cnsysname , we consider the following parameters: i) the number of trees $\\numT$, ii) the number of attempts $\\numA$ that nodes try to perform a transaction before declaring it failed, iii) the maximal interval $\\tl$ between two attempts for the same transaction, and iv) the interval $\\epoch$\nbetween two periodic re-computations of the trees for \\cnsysname .\nFor comparison, we expressed the stabilization overhead for \\oursys in stabilization messages per $\\epoch$.\nIn addition to the above parameters, we provided two approaches for choosing landmarks: choosing the nodes of maximal degree or choosing random nodes.\nHere, we define the maximal degree of a node as the number of connections with positive available credit in both directions. For the evolving credit network, we chose the nodes with the highest initial degree.\n\nWe implemented distributed versions of the\nFord-Fulkerson max-flow algorithm~\\cite{ford1956maximal} and tree-only routing for comparison. Tree-only routing only uses links in the spanning tree but chooses the shortest path rather than always passing through the landmarks.  \nFor Ford-Fulkerson, we replaced the centralized computation with a distributed version that discovers residual flows using a breadth-first search. \nBy adding tree-only routing, we evaluate all three tree-based routing schemes displayed in Figure \\ref{fig:concepts-no-infer}, with SilentWhisper being an instance of landmark-centered routing and SpeedyMurmurs representing embedding-based routing.  \n \n\n  \n\n\\subsection{Dataset}\n\\label{sec:dataset}\n\nWe obtained datasets from crawling the PBT network Ripple~\\cite{armknecht2015ripple}. In particular, we obtained crawls of the complete network from November 2016 and all link modifications and transactions since its creation in January 2013.\nBased on these crawls, we derive datasets for both our simulation modes, the static and evolving network.\nIn the following, we first describe our crawling method, followed by post-processing of the crawled data. Last, we present properties of the resulting datasets. \n\n\\paragraph*{Dataset Processing} We restricted our evaluation to funded accounts: a Ripple account is {\\em funded} when it owns a certain amount of XRP.\\footnote{XRP is the symbol of the\nRipple currency.}  In April 2017, a user needed 20~XRP to fund an account. \nIn this paper, we disregard transferring credit from one currency to another. Hence, we converted all values to US dollars and deleted all links and transactions in non-fiat currencies.\nAfter cleaning the dataset according to these three rules, we derived the credit network $C'_{Nov16}$ for November 2016 and lists of both transactions and link value changes, sorted in temporal order. \nBased on the resulting transaction and link modifications lists, we then generated the credit network $C'_0$ at the time of the first transaction as a starting point of our second mode, the evolving network. \nAs our data does not reveal when nodes join and leave the network, we included all crawled nodes and links in our initial credit network but set the weight of links $(u,v)$ that come into existence at a later point to $0$.\nDuring the spanning tree construction, such links are ignored. \n\nWe resolved three inconsistencies between our model and the datasets.\nIn rare cases, Ripple exhibits invalid credit arrangements; i.e., links $(u,v)$ such that their weight exceeds the upper limit of granted credit. Usually, such occurrences result from changes to the extended credit agreement. We deleted all such links from the dataset.  \nFurthermore, we removed  self-transactions from the dataset, as they do not require routing algorithms according to our model.\nLast, landmark routing requires paths between all nodes and the landmarks, so that we restricted our evaluation to the giant component.\nThese processing steps turned the initial snapshots $C'_{Nov16}$ and $C'_0$ into our processed datasets $C_{Nov16}$ and $C_0$. \nWe obtained the final datasets by restricting the previous lists to entries involving only nodes in the final snapshots. \n\n\\paragraph*{Final Datasets} $C_0$ contained 93,502 nodes and a total of 331,096 links, whereas $C_{Nov16}$ contained 67,149 nodes and 199,574 links. The reason for the disparity is that $C_0$ contained all active links and their adjacent nodes for a period of more than 3 years, whereas $C_{Nov16}$ was a snapshot of the network on one particular date. \nOur final transaction lists had 970,472 and 692,737 entries for $C_0$ and $C_{Nov16}$, respectively.  We recorded a total of 652,216 link modifications for the evolving network $C_0$. \nThe datasets and the code are publicly available.\\footnote{\\url{https://crysp.uwaterloo.ca/software/speedymurmurs/}}\n\n\\begin{table*}[t]\n\\centering\n\\begin{small}\n\\caption{Performance of different transaction schemes in the static scenario, varying the routing algorithm (LM-Landmark, GE-greedy embedding, TO-Tree-only), the stabilization method (PER-periodic, OND-on-demand), the assignment of credit on paths (MUL-multi-party computation, RAND-random), and the landmark selection (HD-highest degree, RL-random landmark) for five metrics: success ratio: fraction of successful transactions (higher is better), delay: longest chain of messages (lower is better), transaction: messages sent per transaction (lower is better), path length: length of discovered paths between sender and receiver (lower is better), stabilization: messages for stabilizing the trees sent per epoch (lower is better).\nSilentWhispers corresponds to the setting LM-MUL-PER whereas SpeedyMurmurs is GE-RAND-OND.}\n\\begin{tabular}{@{}l|d{3}@{\\hskip 0.05cm}c@{\\hskip 0.2cm}d{3}|d{3}@{\\hskip 0.05cm}c@{\\hskip 0.2cm}d{3}|d{2}@{\\hskip 0.05cm}c@{\\hskip 0.2cm}d{2}|d{3}@{\\hskip 0.05cm}c@{\\hskip 0.2cm}d{3}|d{0}@{\\hskip 0.2cm}c@{\\hskip 0.2cm}d{0}}\nSetting & \\multicolumn{3}{c|}{Success Ratio} & \\multicolumn{3}{c|}{Delay} & \\multicolumn{3}{c|}{Transaction} &   \\multicolumn{3}{c|}{Path Length} & \\multicolumn{3}{c}{Stabilization}\\\\ \n & \\multicolumn{3}{c|}{} & \\multicolumn{3}{c|}{(Hops)} & \\multicolumn{3}{c|}{(Messages)} &   \\multicolumn{3}{c|}{(Hops)} & \\multicolumn{3}{c}{(Messages)} \\\\ \\hline\n\\rowcolor{Gray}\n\\textbf{SilentWhispers-HD} & 0.651 & $\\pm$ &  0.005 & 15.01 & $\\pm$ &  0.08 & 82.0 & $\\pm$ &  0.2 & 5.30 & $\\pm$ &  0.01 & 598722 & $\\pm$ &  0 \\\\\nLM-MUL-OND-HD & 0.62 & $\\pm$ & 0.03 & 14.7 & $\\pm$ & 0.5 & 81 & $\\pm$ & 2 & 5.3 & $\\pm$ & 0.1 & 8000000 & $\\pm$ & 2000000\\\\\n\\rowcolor{Gray}\nLM-RAND-PER-HD & 0.09 & $\\pm$ & 0.01 & 8.3 & $\\pm$ & 0.1 & 35.1 & $\\pm$ & 0.5 & 3.23 & $\\pm$ & 0.05 & 598722 & $\\pm$ & 0\\\\\nLM-RAND-OND-HD & 0.09 & $\\pm$ & 0.09 & 9 & $\\pm$ & 1 & 37 & $\\pm$ & 4 & 3.4 & $\\pm$ & 0.4 & 2000 & $\\pm$ & 2000\\\\\n\\rowcolor{Gray}\nGE-MUL-PER-HD & 0.908 & $\\pm$ & 0.001 & 11.52 & $\\pm$ & 0.03 & 49.0 & $\\pm$ & 0.1 & 1.951 & $\\pm$ & 0.003 & 598722 & $\\pm$ & 0\\\\\nGE-MUL-OND-HD & 0.905 & $\\pm$ & 0.004 & 11.5 & $\\pm$ & 0.2 & 49.0 & $\\pm$ & 0.5 & 1.954 & $\\pm$ & 0.007 & 4000 & $\\pm$ & 4000\\\\\n\\rowcolor{Gray}\nGE-RAND-PER-HD & 0.913 & $\\pm$ & 0.001 & 6.016 & $\\pm$ & 0.009 & 18.30 & $\\pm$ & 0.04 & 1.867 & $\\pm$ & 0.003 & 598722 & $\\pm$ & 0\\\\\n\\textbf{SpeedyMurmurs-HD} & 0.906 & $\\pm$ & 0.006 & 6.02 & $\\pm$ & 0.04 & 18.3 & $\\pm$ & 0.1 & 1.87 & $\\pm$ & 0.01 & 300 & $\\pm$ & 300\\\\\n\\hline \n\\rowcolor{Gray}\nTO-SW-HD & 0.863 & $\\pm$ & 0.003 & 15.9 & $\\pm$ & 0.1 & 81.9 & $\\pm$ & 0.3 & 3.17 & $\\pm$ & 0.01 &598722 & $\\pm$ & 0\\\\\nTO-SM-HD & 0.54 & $\\pm$ & 0.04 & 6.7 & $\\pm$ & 0.3 & 23.5 & $\\pm$ & 0.7 & 2.01 & $\\pm$ & 0.07 & 5000 & $\\pm$ & 5000\\\\\n\\rowcolor{Gray}\nFord-Fulkerson & 1.00 & $\\pm$ & 0.00 & 49500 & $\\pm$ & 900 & 49500 & $\\pm$ & 900 & 3.2 & $\\pm$ & 0.1 & 0 & $\\pm$ & 0\\\\\n\\hline\nSilentWhispers-RL & 0.1 & $\\pm$ & 0.2 & 15 & $\\pm$ & 2 & 130 & $\\pm$ & 10 & 7.6 & $\\pm$ & 0.6 & 598722 & $\\pm$ & 0\\\\\n\\rowcolor{Gray}\nSpeedyMurmurs-RL & 0.912 & $\\pm$ & 0.007 & 5.99 & $\\pm$ & 0.06 & 18.2 & $\\pm$ & 0.2 & 1.863 & $\\pm$ & 0.009 & 1000  & $\\pm$ & 1000\\\\\n\\end{tabular}\n\\label{tab:algos}\n\\end{small}\n\n\\end{table*}  \n\n\\subsection{Simulation Setup}\n\nOur first simulation setup realized the static simulation mode on the basis of the snapshot $C_{Nov16}$. \nWe repeated simulations 20 times, using a different set of 50,000 transaction for each run.\nWe chose these transactions pseudorandomly, seeded by the run number, from all transactions that were successful using Ford-Fulkerson, a total of 331,642 transactions. \nWe then evaluated all 8 possible combinations of routing algorithms (landmark routing or embedding-based), credit assignments to paths (multi-party computation or random assignment), and stabilization algorithms (periodic or on-demand) for the parameters $\\numT=3$ and $\\numA=2$.  \nWe chose $\\epoch=1000$, meaning we recomputed spanning trees each 1000 transactions. We choose the re-queuing interval as $\\tl=2\\cdot\\epoch$. For the landmark selection, we considered both options: random and highest degree. Note that random choices were deterministic in the run number, ensuring comparability of all approaches under the same circumstances.\nFor comparison with related approaches, we evaluated two versions of tree-only routing, using \\cnsysname' multi-party computation and periodic stabilization for the first version and \\oursys ' random credit assignment and on-demand stabilization for the second. \nWe then evaluated the impact of the different parameters for \\cnsysname and \\oursys . We vary the number of landmarks $\\numT$ between 1 and 7 and the number of attempts $\\numA$ between 1 and 10. \n\nOur second simulation setup realized the evolution of the network under different algorithms: Ford-Fulkerson, \\cnsysname , and \\oursys .\nStarting from the initial network $C_0$, the simulation initiated the transactions and changes link values according to the dataset.\nFor \\cnsysname and \\oursys , we set $\\numT=3$, $\\numA=2$, $\\epoch=1000\\delta_{Av}$, and $\\tl=2\\delta_{Av}$\nwith $\\delta_{Av}$ denoting the average time between two transactions. In this manner, an epoch roughly corresponds to a day. \nWe chose landmarks of the highest degree for \\oursys and \\cnsysname.\nAs Ford-Fulkerson is a deterministic algorithm, we only executed it once but averaged our results for \\oursys and \\cnsysname over 20 runs.\n     \n     \n\n\\subsection{Results}\n\nWe start by comparing a wide range of algorithms for the static simulation setup.\nTable~\\ref{tab:algos} displays the results for different combinations of the three proposed modifications to \\cnsysname  as well as our implementations of tree-only routing and Ford-Fulkerson. \nNote that Ford-Fulkerson is a deterministic algorithm but its delays and overheads vary as the set of transactions varies between runs. \n\n\\paragraph*{Impact of Design Decisions} \nAs expected, greedy embeddings led to shorter paths due to finding shortcuts between different branches of the tree. Hence, all settings using greedy embeddings, i.e., rows starting in ``GE-'' and SpeedyMurmurs, exhibited lower delays and transaction overheads than the corresponding landmark-based algorithms. Indeed, greedy embeddings reduced the path length and the transaction overhead by nearly a factor of 2.\nGreedy embeddings also increased the success ratio due to the shorter paths and the lower probability of encountering a link with low available credit.\n\nThe impact of the random assignment of credit, used by SpeedyMurmurs and all algorithms with ``RAND'' in their name, was less clear-cut: While removing the need to involve landmarks into the routing process reduced the delay and the transaction overhead for all parameter settings, the impact on the success ratio differed between embedding-based and landmark routing. \nWhen combined with landmark routing, random credit assignments resulted in a definite drop in success from more than 60\\% to only 8\\%. The reason for the low success ratio was the high probability of encountering at least one link with insufficient credit to satisfy the random assignment.\nIn contrast, greedy embeddings exhibited much shorter paths and the flexibility to potentially choose between several neighbors. These two properties negated the disadvantageous impact of the random credit assignment, so that greedy embedding in combination with random assignment resulted in the same success ratio of 91\\% as in combination with multi-party computation. \n\nOn-demand stabilization reduced the stabilization overhead (abbreviated by Stabilization in Table~\\ref{tab:algos})\ndrastically: While rebuilding the spanning trees periodically, as applied by SilentWhispers and all algorithms with ``PER'' in their name, resulted in more than half a million messages per epoch, on-demand stabilization only required a few thousands of messages,\nas shown in the last column of Table~\\ref{tab:algos}. \nOn-demand stabilization induced high variance because the value of links close to the root of a spanning tree rarely drops to 0 but incurred enormous overhead in these rare occurrences. \nThe simulation showed a clear advantage of on-demand stabilization. \nWe admit that the considerable advantage of on-demand stabilization is partially due to lack of link value changes and actual dynamics in the static simulation. In the second part of this section, we therefore evaluate the stabilization overhead in a dynamic environment.\n \n\n\\begin{figure*}[t]\n\\centering\n\\subfloat[Success Ratio : Trees (Higher is Better)]{\\label{fig:treesSR}\\includegraphics[width=0.33\\linewidth]{treesSR}}\n\\subfloat[Delay : Trees (Lower is Better)]{\\label{fig:treesDelay}\\includegraphics[width=0.33\\linewidth]{treesDelay}}\n\\subfloat[Success Ratio : Attempts (Higher is Better)]{\\label{fig:attSR}\\includegraphics[width=0.33\\linewidth]{attsSR}}\n\\caption{\\cnsysname vs.\\ \\oursys: Impact of number of parallel trees and attempts at performing a transaction}\n\\label{fig:parameter}\n\\vspace{-2em}\n\\end{figure*}\n\n\\begin{figure*}[t]\n\\centering\n\\subfloat[Events/Epoch]{\\label{fig:events}\\includegraphics[width=0.33\\linewidth]{events}}\n\\subfloat[Stabilization (Lower is Better)]{\\label{fig:stab}\\includegraphics[width=0.33\\linewidth]{stabs}}\n\\subfloat[Success (Higher is Better)]{\\label{fig:succ}\\includegraphics[width=0.33\\linewidth]{succs-50}}\n\\caption{Comparing \\oursys and \\cnsysname in a dynamic setting based upon Ripple transaction and link changes from 2013 to 2016 on per-epoch scale; success is computed as the ratio of the actual success ratio and the success ratio of the Ford-Fulkerson algorithm as a baseline; for c),  we present moving averages over 50 epochs to increase readability}\n\\label{fig:dynamic}\n\\vspace{-1em}\n\\end{figure*}\n\n \n\n\\paragraph*{Comparison to Other Algorithms} We compared \\cnsysname and \\oursys with tree-only routing and Ford-Fulkerson based on the results in Table~\\ref{tab:algos}.\nAs expected, Ford-Fulkerson exhibited prohibitive delays and transaction overheads. The fact that Ford-Fulkerson also results in a longer average path length seems counterintuitive at first. However, the result was a side effect of Ford-Fulkerson discovering long paths to maximize the available credit that the other approaches failed to discover. \nAs illustrated in Fig.~\\ref{fig:concepts-no-infer} and detailed in Sec.~\\ref{sec:background}, tree-only routing finds the shortest route in the spanning tree,\npossibly without passing a landmark, but does not include links that are not contained in the tree.\nThus, tree-only routing is a compromise between \\cnsysname' routing algorithm and embedding-based routing. \nAs a consequence, the performance results when using only tree links are in between the performance of \\cnsysname and \\oursys .\n\n\\paragraph*{Impact of $\\numT$ and $\\numA$} Next, we evaluate the impact of different configuration parameters on the performance. \nAs indicated in the last two rows of Table~\\ref{tab:algos}, choosing random landmarks did not considerably affect the performance of \\oursys but reduced the performance of \\cnsysname due to the existence of longer paths to a landmark with few connections. \nIn contrast, increasing the number of trees $\\numT$ affected the success ratio of \\oursys negatively and \\cnsysname positively, as Fig.~\\ref{fig:treesSR} indicates. \nThe reason for the observed decrease in success was the increased likelihood that at least one path did not have sufficient credit. \nAn increased $\\numT$ further increased the delays, as shown in Fig.~\\ref{fig:treesDelay}. The impact was more pronounced for \\cnsysname because landmarks had to wait until all messages for the multi-party computation arrived.   \nThe number of attempts $\\numA$ had a slight positive effect on the success ratio, as shown in Fig.~\\ref{fig:attSR}. Yet, as the transaction overhead is linear in the number of attempts, the slight increase may not warrant multiple attempts.  \n\nFor all algorithms but Ford-Fulkerson, the success ratio was considerably below 100\\%. It stands to reason that a lot of users might not be willing to accept a failure rate of 10\\% or more. Note that a failure to route does not reduce the funds of any user, so there is no loss in funds associated with a routing failure.  \nFurthermore, in a non-static environment, users can retry the transaction at a later point in time after the network has sufficiently changed for it to work.  \nIf neither failure nor waiting is an option, we could apply Ford-Fulkerson on failure. By reducing the transactions that require Ford-Fulkerson to 10\\%, we still considerably improve the efficiency in comparison to a network relying exclusively on Ford-Fulkerson at the price of a slight increase in delay due to the preceding use of \\oursys. \nIn addition, we hope that with increasing popularity, both the connectivity of the PBT networks and the amount of available funds increase beyond the current state of the Ripple network, which is bound to entail a higher probability of success.\n\n\\paragraph*{Impact of Dynamics} We evaluated the impact of dynamics on the performance of \\oursys and \\cnsysname . As stated above, the impact of dynamics is particularly of interest to decide if on-demand stabilization is indeed more efficient than periodic stabilization. \nTo better comprehend the reasons underlying our results, Fig.~\\ref{fig:events} displays the number of transactions and link changes per epoch for the Ripple dataset.\nWhile the number of transactions did not vary greatly over the period of three years, link creations and modifications were frequent in some short intervals but rare during the remaining observation period. The frequency of link changes directly relates to the stabilization overhead of \\oursys , as indicated by Fig.~\\ref{fig:stab}. Whereas the stabilization overhead was usually below 100 messages per epoch, the overhead increased to about $10^9$ messages during periods of frequent change. Note that only the first two of the four batches of link changes resulted in a drastically increased need for stabilization. After the first two batches, spanning trees had formed and new link additions mostly created shortcuts that did not require changes to the trees. \nIn contrast, the stabilization overhead of \\cnsysname only depended on the number of edges in the network and hence increased as the graph grows over time. During intervals of frequent change, the stabilization overhead of \\cnsysname was considerably lower than \\oursys ' stabilization overhead. However, during `normal' operation, \\cnsysname' stabilization overhead exceeded the overhead of \\oursys by more than 2 orders of magnitude.  \nWe evaluated the success in relation to Ford-Fulkerson and hence  divided the actual success ratio of each epoch by the success ratio of Ford-Fulkerson for the corresponding epoch. \nAs can be seen from Fig.~\\ref{fig:succ}, the success could exceed 1 if an alternative routing algorithm exhibited a higher success ratio. Note that higher success ratios were indeed possible due to the fact that different routing algorithms resulted in different payments and hence different network states. Different network states implied a different set of possible transactions, so that a transaction could fail for Ford-Fulkerson but succeed for \\cnsysname or \\oursys. \nIn comparison, \\oursys and \\cnsysname achieved similar success ratios for most of the time; however, at the end of the simulation interval, \\cnsysname outperformed \\oursys . The sudden increase in success correlates with the addition or change of many links, as can be seen from Fig.~\\ref{fig:events}. The additional links increase the density of the graph, leading to shorter paths, and hence a higher success probability. The fact that \\cnsysname achieves a higher success ratio than \\oursys could be due to the tree structure: \\cnsysname maintains breadth-first search trees whereas \\oursys initially constructs breadth-first search trees but does not change the parent of a node if a new neighbor offers a shorter path to the root. The longer paths to the root could have negative effects on the probability of success. \nAs the actual success ratio of all considered algorithms is low during later epochs, e.g., frequently below $5$\\%, the result might be an artifact of our dataset and post-processing method. \n\nWe hence answered our five initial research questions: \n\\begin{itemize}%[leftmargin=*]\n\\item \\oursys achieved a higher performance than \\cnsysname with regard to all considered metrics for the static  scenario. \n\\item On-demand stabilization and embedding-based routing had a positive effect on all 5 performance metrics. In contrast, the use of random credit assignment might decrease the success ratio slightly. However, when used in combination with embedding-based routing, the effect was mostly negated.\n\\item As expected, Ford-Fulkerson usually achieved a higher success than both \\oursys and \\cnsysname . However, the algorithm resulted in an enormous transaction overhead, exceeding the overhead of the other algorithms by 2 to 3 orders of magnitude. \n\\item An increased number of trees or attempts to perform a transaction did not considerably increase the success ratio  of \\oursys but incurred increased overheads.\n\\item The evolution of the PBT network affects the performance of SpeedyMurmurs considerably. Stabilization overhead and success ratio vary considerably depending on the frequency of transactions and link changes. \n\\end{itemize}\n The dynamic evaluation suggests working on the design of an alternative spanning tree maintenance algorithm.\n In particular, the results raise the question of suitable criteria for dynamically switching between on-demand and periodic stabilization. Indeed, as \\cnsysname is more efficient during periods of frequent change but results in higher overhead otherwise, such a switching mechanism could further reduce the communication overhead and hence increase scalability.\n \n   \n\n\\section{Related Work}\n\\label{sec:related}\n\nMaximizing the set of possible transactions in a credit network is NP-hard~\\cite{Ghosh07}. \nInstead, many existing systems have opted for considering one transaction at a time and \napplying the max-flow approach~\\cite{ford1956maximal} as a routing algorithm.   \nNevertheless, existing algorithms~\\cite{max-flow-v2} run in $O(V^3)$ or $O(V^2 \\log(E))$ time and \nhence do not scale to a growing number of \\users and transactions~\\cite{viswanath2012canal, post2011bazaar}. \n\nThe pioneering credit networks Ripple and Stellar maintain their entire PBT networks on public blockchain ledgers. \nAlthough this information can be leveraged to \nperform routing efficiently, it also trivially leaks sensitive information such as %transitive relations in the form of \ncredit links/relationships and financial activity in the form of transactions.  Instead, current proposals rely  \non a decentralized PBT network requiring no public log.\n\nPrihodko et al.\\ recently proposed Flare~\\cite{prihodko2016flare}, a routing algorithm for the \n Lightning Network, \na network of Bitcoin payment channels among Bitcoin \\users that enables off-chain transactions~\\cite{poon2015bitcoin}.\nIn Flare, all nodes keep track of their $k$-neighborhood; i.e., nodes at a hop distance of at most $k$ and all links between them. In addition, each node maintains paths to a set of nearby \\emph{beacon} nodes.\n\nThis routing algorithm reveals the weight of all links in the $k$-neighborhood, usually for $k\\geq 3$. \nThis results in\na privacy concern as the weight of a link between two users is exposed to users other than those two.\nFurthermore, nodes spread all updates to the $k$-neighborhood, meaning each credit change results in possibly hundreds of messages, which is highly inefficient for frequent transactions and hence changes in available credit. \n\nCanal~\\cite{viswanath2012canal} presents the first efficient implementation of tree-only routing applied to \nlooking for paths in credit networks. A trusted central party computes the shortest paths in the spanning trees between sender and receiver. If these paths provide enough credit to settle a transaction, the routing terminates successfully. Otherwise, it fails. \nIn the face of network dynamics, the central server re-computes spanning trees constantly. \nDue to maintaining a central server, Canal~\\cite{viswanath2012canal} has severe privacy and security drawbacks. \n\nPrivPay~\\cite{moreno15privpay} increases the privacy of Canal by using trusted hardware at the central server. However, PrivPay relies on a \nsimilar landmark technique as Canal and is also a centralized solution, therefore the scalability is still low and the issue of a single point of failure remains unsolved. \nAdditionally, the PrivPay paper introduces for the first time the notions of \nvalue privacy and sender/receiver privacy for payments in a credit network.\nIn this work, we define the privacy notions for routing in a \\paysys as a building \nblock not only for credit networks but also for any \\paysys. \n\nSilentWhispers~\\cite{malavolta17silent} uses landmark routing in a fully distributed credit network. \nBoth \\sender and \\receiver send messages in the direction of the landmarks, \nwhich constitute rendezvous nodes. In other words, \npaths in SilentWhispers are concatenations of the \\sender's path to a landmark and the path \nfrom said landmark to the \\receiver. \nAll paths pass a landmark, even if \\sender and \\receiver happen to be in the same branch, potentially leading to performance issues. However, as we discuss throughout this paper, SpeedyMurmurs, the routing \nalgorithm proposed in this work, outperforms the routing approach proposed in SilentWhispers while \nachieving the privacy notions of interest.\n\nMalavolta et al.~\\cite{malavolta17PCN}\nrecently proposed Rayo and Fulgor, two payment-channel \nnetworks (i.e., \\paysyss) \nthat provide a necessary tradeoff between privacy and concurrency. Their  \nstudy of concurrency could be leveraged to extend how \nconcurrency is handled in \\oursys. Nevertheless, they\ndo not tackle the path selection problem. Thus, \n\\oursys is an excellent candidate to complement Rayo and Fulgor. \n\n\\subsubsection*{Summary} Existing routing approaches often disregard privacy. Most of them require centralization or shared public information; SilentWhispers is the only existing distributed PBT network focusing on privacy. However, it relies on a distributed landmark routing technique that is potentially inefficient. Our in-depth performance and privacy evaluation \nshows that SpeedyMurmurs provides higher overall \nperformance \nwhen compared to state-of-the-art routing approaches, while \nachieving the privacy notions of interest.\n\\section{Conclusion and Future Work}\n\\label{sec:conc}\n\nIn this work, we design \\oursys, an efficient routing algorithm for completely decentralized PBT networks.\nOur extensive simulation study and analysis indicate that \\oursys is highly efficient and achieves a high probability of success\nwhile still providing value privacy as well as \\sender/\\receiver privacy against a strong network adversary.\nAs these privacy notions are essential for PBT applications,\n\\oursys is an ideal routing algorithm for decentralized credit networks and payment channel networks, as well as for emerging inter-blockchain algorithms.\n\nAs our results indicate that on-demand and periodic stabilization are suitable for different phases of a PBT network's evolution, future work can extend upon our results by investigating the option of dynamically switching between on-demand and periodic stabilization. \n \n\n\\vspace{-1em}\n\n\\section*{Acknowledgements}\nThis work benefited from the use of the CrySP RIPPLE Facility at \nUniversity of Waterloo and is partially supported by an Intel/CERIAS RA and NSERC grant\nRGPIN-2017-03858. \n\n\\vspace{-1em}\n\n\\balance\n\n\\end{document}\n</paper 1>\n\n<paper 2>\n\\title{A DoS Attack on Off-Chain Networks\\\\and A Design Tradeoff}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\nOff-chain transaction networks can mitigate the scalability\nissues of today's trustless electronic cash systems such as Bitcoin. \nHowever, these peer-to-peer networks also introduce a new attack surface which is not well-understood today.\nThis paper identifies and analyzes,  a novel Denial-of-Service attack\nwhich is based on route hijacking, i.e., \nwhich exploits the way transactions are routed and executed along \nthe created channels of the network.\nThis attack is conceptually interesting as even a limited attacker that manipulates the topology through the creation of new channels\ncan navigate tradeoffs related to the way it attacks the network. \nFurthermore, the attack also highlights a fundamental design tradeoff for the defender\n(who determines its own routes): \nto become less predictable and hence secure, a rational node has to pay higher fees to nodes that forward its payments.\nWe find that the three most common implementations for payment channels in Bitcoin (lnd, C-lightning, Eclair) approach routing differently. We begin by surveying the current state of the Lightning network and explore the routes chosen by these implementations. We find that in the current network nearly 60\\% of all routes pass through only five nodes, while 80\\% go through only 10 nodes. Thus, a relatively small number of colluding nodes can deny service to a large fraction of the network. \n\nWe then turn to study an external attacker who creates links to the network and draws more routes through its nodes by asking for lower fees. We find that just five new links are enough to draw the majority (65\\% - 75\\%) of the traffic regardless of the implementation being used.  The cost of creating these links is very low.\n\nWe discuss the differences between implementations and eventually derive our own suggested routing policy, which is based on a novel combination of existing approaches. \n\\end{abstract}\n\n\\section{Introduction}\\label{sec:intro}\nEmerging decentralized ledger and blockchain technologies bear the promise to\nstreamline business, governance and non-profit activities, by\neliminating intermediaries and authorities.\nA main hurdle toward such more decentralized applications however\nremains scalability~\\cite{bamert2013have,decker2015fast,sompolinsky2013accelerating}. The typical example is that Bitcoin can only support\ndozens of transactions per second, compared to several thousands\nin deployed payment services such as Visa~\\cite{trillo2013stress}. \n\nOff-chain peer-to-peer networks (a.k.a.~payment channel networks) \nare a promising approach to mitigate\nthis scalability problem: by allowing participants to \nmake payments directly through a network of payment channels,\nthe overhead of global consensus protocols and committing transactions \\emph{on-chain} \ncan be avoided.\nThis not only improves transaction throughput\nbut also avoids the blockchain's transaction latency;\nideally, in a payment channel network, most transactions are done using bidirectional payment\nchannels that only require direct communications between a handful of nodes, while the blockchain is used only rarely, to establish or terminate channels. \nAs an incentive to participate in others' transactions, the nodes obtain a small fee from every transaction that was routed through their channels.\nOver the last few years, payment channel networks such as Lightning~\\cite{poon2016bitcoin}, Ripple~\\cite{armknecht2015ripple}, and Raiden~\\cite{network2018cheap}\nhave been implemented, deployed and have started growing.\n\nThis paper is concerned with the \\emph{routing} mechanisms which lie at the heart\nof payment channel networks:\nan important feature of payment channel networks is that they\nalso support transactions between participants without direct channels, \nusing \\emph{multihop} routing~\\cite{malavolta2019anonymous,poon2016bitcoin}.\nHowever, the design tradeoffs and security implications of such multi-hop routing\nare not well-understood today.\nIn fact, routing in payment channel networks is \nfairly different from routing in traditional communication networks: \nin traditional communication networks, routing algorithms typically\naim to find short and low-load paths in a network whose links are subject\nto fixed capacity constraints. In a payment channel network, \nlink capacities represent\npayment balances, which can be highly dynamic: every transaction changes the payment balance initially\nset up for the channel. \nWhat is more, both the establishment as well as the use of payment\nchannels is an inherently strategic decision, and subject to complex\nincentives and the extent to which a participant thinks she or he can benefit from\ndifferent behaviors. \nIn fact, a participant may not only try to strategically maximize her or his\nprofit, but may also be \\emph{malicious}.\n\n\\subsection{Our Contributions}\n\nThis paper is motivated by the question whether and how malicious players\ncan strategically influence and \\emph{exploit} the way transactions are routed\nin off-chain networks. \nOur main contribution is the identification, analysis, and evaluation of a novel\nDenial-of-Service attack which is based on the\nhijacking of transaction routes. To this end,\nwe examine different existing\nimplementations (which turn out to differ significantly),\nand we provide empirical insights into the structure and properties\nof payment channel networks. \n\nMore specifically, we find that there exists a group of 10 nodes that participates in 80\\% of the routes, and 30 nodes that participate in more than 95\\% of the routes. On the other hand, we find that by creating 5 new \\emph{new} channels, an attacker can hijack about 65\\% of the routes, and with 30 channels, it can hijack 80\\% of the routes of every implementation.\nFurthermore, we find that existing clients differ in their\nobjectives and hence introduce trade-offs in route selection. Finally, we find only \nlimited evidence that users configure their nodes to extract high rewards. Nodes typically use default values or set minimal fees and contribute cheap routes to the network.\nBoth aspects can potentially be exploited by selfish and malicious\nplayers. \n\nReasoning about more secure solutions, we find that the underlying\nrouting problem exhibits a fundamental design tradeoff, related to how\nunpredictable a rational player aims to be:\nby behaving less predictably (i.e., choosing alternative routings), \na rational player can become more secure\nagainst attacks, however, such behaviors induce a higher fee for the player. \nWe investigate this novel tradeoff (the price of predictability) and discuss strategies both for\nthe attacker as well as the defender to optimally invest its resources. \n\nAn additional tradeoff that we discuss \nregards the times nodes must be online \n(how often they need to check the network to make sure funds are not stolen from them) \nand the time it takes live channels to reset. Network defaults currently allow nodes relatively long periods of\noffline time, which implies that connection attempts that are hijacked are not retried quickly. \n\nThis paper investigates additional tradeoffs and gives intuition on their impact on the network. One of these tradeoffs regards the fee rate of the channels. On the one hand, if we  let the nodes determine the fee by themselves (in an open market), then it will increase the vulnerability to attacks in which the attacker will exploit the nodes' selfish routing and offer very low fees in order to hijack traffic. On the other hand, if the system  determines the fees for the channels, then the system may suffer from incentives problems; too low fees will cause the channels to be non-profitable, which may cause them to close (which affects the network connectivity); too high fees will decrease the incentives of the nodes to perform transactions.\n\nIn order to ensure reproducibility and in order to facilitate followup work,\nwe share our source code (python3.7) with the research community at https://github.cs.huji.ac.il/saart/saart-lightning.\n\n\\subsection{Organization}\n\nThe remainder of this paper is organized as follows.\nIn Section~\\ref{sec:attack}, we will present our DoS attack\nand explore different hijack possibilities.\nSection~\\ref{sec::feasibility} examines the state-of-the-art\nrouting algorithms, and then provides an overview of the experiments we conducted. We then describe in Section~\\ref{sec:preliminaries} a model resulting from our attack\nas well as the algorithms that we used in our experiments. In Section~\\ref{sec::suggested_solution} we explore methods to decrease this vulnerability through both a game theoretic model and suggestions on future weight implementation. Related work will be presented in\nSection~\\ref{sec:relwork}.\nFinally, we present conclusions and discuss future work in Section~\\ref{sec:conclusion}.\n\n\\section{DoS Attack Via Route Hijacking}\\label{sec:attack}\n\nThis section uncovers a potential vulnerability, based on route hijacking,\nwhich may be used for\na Denial-of-Service (DoS) attack on off-chain networks.\nWe will first provide an explanation of the key elements of the protocol,\nthen present the basic attack and finally\ndescribe how this attack may be amplified.\nIn the next sections, we will then explore the feasibility of this attack empirically,\nin a state-of-the-art payment channel network, \nevaluate it and reason about optimization opportunities both for the attacker\nand the defender.\n\n\\subsection{Context of the Attack}\nTo be more concrete, we consider the Lightning network\nas a case study in the following. However, the concepts are similar\nin other networks as well. \nIn the Lightning off-chain network, the \\emph{\\textbf{channels}} are established\nby the nodes for secure payments. \nEvery two nodes that are willing to create such a channel,\nneed to make a commitment: they need to execute a Bitcoin transaction that locks\nmoney (i.e., liquidity) for this channel\\footnote{Note that this means that every channel is backed-up with a real Bitcoin's transaction, therefore no one can spoof channels}.\nA transaction is then simply an agreement between the two end-points\nof the channel, which leads to a different split of the money. \nThe intermediate states resulting from this transaction\ndo not have to be committed to the blockchain: Once they will commit the state into the blockchain, the channel will be closed (because it ``wastes\" the original transaction). Until this occurs, the channel can remain operational and the internal split of funds can be adjusted by the participants. \nAs the intermediate states of channels are built, older states are ``revoked'': if one tries to commit an old state, the other participant can claim funds back. This recovery of funds can only be done within a certain pre-set period of time. This setup thus requires each of the participants in a channel to occasionally check the blockchain and make sure that the other party did not close the channel using an old state. \n\nOff-chain networks such as Lightning however do not only support transactions between\nnodes that have a direct channel, but also allow chaining paths to connect nodes \\emph{indirectly}. \nThis is achieved by allowing two nodes to find a path along multiple existing channels that \nconnect the nodes: in order to realize such a ``multi-hop transaction'',\na transaction is executed on each direct channel along the path. \n\nThe technique used to chain paths together but still guarantee that funds are not stolen by intermediate nodes is based on ``hash \\& time lock contracts\", or HTLCs, which are essentially contracts awarding nodes a slightly different split of the money in each channel if a secret is revealed. Paths are then created by establishing a chain of channels with HTLCs conditioned on the release of the same secret, and the transfer is finally executed as the recipient node releases the secret (additional details can be found in~\\cite{poon2016bitcoin}).\nHTLCs must additionally posses an expiration time which specifies the timeout of each lock. This timeout is the timeout of the next node in the path plus some small delay specified by the preceding node. These decreasing delays ensure that intermediate nodes never reach a situation where they might have an outgoing payment without being compensated by an incoming payment (due to an earlier timeout of the incoming channel). \nThis small difference between HTLC timeouts is called \\emph{\\textbf{delay}} and is expressed by a number of blocks in the blockchain (as timestamps on blocks are considered unreliable, and block height is the fundamental way to meassure the progress of time in blockchains).\n\nTo motivate nodes to allow routing transactions, nodes are allowed to specify a  \\emph{\\textbf{fee}} for forwarding transactions.\nThis fee that the nodes performing a transaction have to pay to the nodes that hold the channels that they use,\nis published when the channel is created. It consists of a \\emph{base fee} \nand a \\emph{proportional fee}; the latter is relative to the transaction size. \nFor example, to use a channel that has base fee of 100 millisatoshis, and a proportional fee of 1 per million, \na 1 million millisatoshis transaction will pay a fee of 101, and a \n2 million millisatoshis transaction will pay a fee of 102.\n\nIn order to find such a path, nodes leverage the knowledge of the channel graph which is\ncontinuously gossiped about by nodes in the network. \nGiven this knowledge of the network graph, nodes utilize \\emph{source routing} to pick their path. As we will see, different implementations use different \nrouting algorithms for path selection, optimizing different measures (e.g. fee, delay, security, etc.).\n\n\\subsection{Basic Attack: A Rerouting Vulnerability}\n\n    \\begin{figure}\n    \t\\centering\n    \t\\includegraphics[scale=0.22]{explain_attack_general_directed_devil.png}\n    \t\\caption{The routing vulnerability: an adversary creates edges that decrease the weight for many nodes.}\n    \t\\label{figure::attack_ilustration}\n    \\end{figure}\n    \n\nThe fact that nodes can strategically choose transaction paths \nintroduces a potential vulnerability. In the following,\nwe model the off-chain network as a graph, \nwhere nodes represent the Lightning nodes of the network and \nedges represent payment channels. \nIn the basic attack, an \nadversary (either selfish or malicious) can aim to establish a set of edges \nin this graph which put it in a topologically important location,\nas well as to announce a low fee.\nAs a consequence, other nodes are likely to route transactions\nthrough the adversarial node. As route establishment is done via an onion-routing approach, and intermediary node may drop the payload and fail to follow through on the establishment of the rest of the path. In this case, the payment does not take place, and the sender must wait for the original HTLC to expire before attempting to re-send the payment. \n\nBy maximizing its \\emph{centrality}, the adversary can\nhijack a large number of transaction paths, which in turn allows it to launch a Denial-of-Service\nattack. Even if payments are re-sent, route selection may yet again cause the path to go through one of the attacker's nodes. \n\nFor an illustration, consider Figure~\\ref{figure::attack_ilustration}.\nFirst, ignore the red node and its edges. In the blue network, \nthere are then two groups of nodes that communicate\nthrough a single link with a high fee of 10. \nIf an adversary (indicated as red node) now introduces \nthe two red edges of low fee, it essentially creates \na shortcut between some of the nodes, hijacking \nthe transactions that aim to minimize the fee.\n\nWhile we will analyze the algorithmic problem underlying\nboth the adversary's and the defender's optimization more formally only later,\nwe note that counteracting this attack is non-trivial.\nEssentially, there are two options:\n\\begin{enumerate}\n    \\item  One may consider introducing mechanisms\n    which quickly alert nodes about interrupted channels.\n    However, this can also be problematic as it may be exploited\n    by adversaries to make false reports.\n    \\item If the source node does not know which specific channels were stopped, \n    it may only heuristically invalidate nodes or channels from the original path \n    (which may disconnect the network or lead to higher fees), \n    and/or hope that a newly (randomly?) chosen path may reestablish\n    connectivity.\n\\end{enumerate}\n\nNote that every node can create channels to most of the nodes that it chooses:\nthe default behaviour in all the implementations is to accept every channel suggestions. This willingness to connect can be attributed to the perceived low risk in doing so: the construction guarantees that none of the funds in the channel is at risk of theft. Given the attack that we propose, it may be wise to accept channel connections only from known and trusted entities.\n\n\\subsection{Amplified Attack: Delay Vulnerability}\n\nThe basic attack may be further amplified\nby exploiting the delay mechanism. \n    If the attacker participates in path establishment, \n    but stops participating during the transaction itself, then the other \n    nodes may already have locked their money for the channel\n    and will be able to free it only after a timeout.\n    This means that a higher delay will lock the money of the nodes in the path for a longer time, \n    and potentially prevent from the source node to execute another transaction's attempt for a longer period. We explore this aspect as well in our evaluation. \n    \n\\section{Feasibility and Case Studies}\\label{sec::feasibility}\n\nWe now explore the feasibility of the attack identified\nabove. To this end, we consider different Lightning network implementations\nand also conduct an empirical study on today's\nnetwork topology, its fees and other parameters, which may be of independent interest.\nWe also report on our experimental evaluation results.\n\n\\subsection{Implementation Details} \\label{sec::imp_details}\n\nIn order to investigate the feasibility of our attack,\nas a case study, we consider the three \nmain implementations of the Lightning network: \n\\emph{lnd} (implemented in Golang), \\emph{C-lightning} (implemented in C) and \n\\emph{Eclair} (implemented in Scala).\nThe implementations differ in the way they operate relative to aspects not covered\nin the BOLTs~\\cite{BOLT} which make up the Lightning network's standard. Specifically, the standard does not dictate any routing behavior, leaving each implementation to set its own (as there is no real need for path finding to be identical between implementations). In our experiments, we use the default parameters of every implementation.\n\n\\subsubsection{lnd}\n\\emph{lnd} chooses the path of minimum weight, \ncalculated using the following recursive formula, \nwhere $p$ is the list of channels in this path, \nand $ams$ is the list of amounts the go\nthrough each channel (changes depending on the fees):\\footnote{References can be found in the methods \\emph{FindRoutes} and \\emph{findPath} in lnd.routing.router.go and pathfind.go}\n$$ fee = ams[i+1] \\cdot p[i].propFee + p[i].baseFee $$\n\\begin{align*}\n    weight[i] = &ams[i+1] \\cdot p[i].delay \\cdot riskFactor \\\\\n                &+ fee\n\\end{align*}\nFor default $riskFactor = 15 / \\num{1000000000}$\n\nNote that lnd changed this weight function in March~2019, in commit 6b70791. The authors added\\footnote{References can be found in routing/missioncontrol.go:261 and routing/pathfind.go:531} a new phrase to the channel's weight: $+ \\frac{100}{edgeProbability}$.\nThis parameter is an aggregated success score over the previous routing through this channel. If the node has no prior knowledge about the channel, then it uses the default value that is relative to the a-priori failing rate in the network. Otherwise, the penalty considers only the time of the last failure. In the first hour, the probability is $0$, and then it increases exponentially with the formula: $0.6 - \\frac{0.6}{2^t}$ (when using the default arguments).\nWe note that lnd looks only at the last failure to discount channels, so if the time until failure is long enough, then it will effectively choose between at most two channels in the network, both with low weight (quite similarly to Eclair's ``top 3\" approach). This is not in itself sufficient to bypass the attacker, as it is easy for it to be on both routes (just like we show for Eclair). Additionally, the decay rate of the penalty on failures needs to be low in order to remain relevant as the previous HTLC contract times out. At last, an attacker that completes the route as requested, but delays the HTLC secret release until the very last moment, will delay the transfer significantly and will not suffer the penalty at all.\n\n\\subsubsection{C-lightning}\n\n\\emph{C-lightning} multiplies \nthe fee by a fuzz that is \nrandomly calculated (and is within configured range), and gives a\npenalty for delays.\nDenote by $h$ the hash that was calculated using siphash24 \non a random string that the user generated (before every path selection) and the short channel id. Denote $fuzz$ to be the configured fuzz factor ($0.05$ by default).\\footnote{References can be found in the methods bfg\\_one\\_edge and find\\_route in the file gossipd/routing.c}\n$$ scale = 1 + fuzz \\cdot (2 \\cdot \\frac{h}{2^{64}-1} - 1) $$\n$$ fee = scale \\cdot (ams[i+1] \\cdot p[i].propFee + p[i].baseFee) $$\n\\begin{align*}\n    weight[i] = &(ams[i+1] + fee) \\cdot (p[i].delay \\cdot riskFactor) \\\\\n                &+ 1\n\\end{align*}\nfor a configurable $riskFactor$, which is 10 by default.\n\n\\subsubsection{Eclair} \\label{subsubsec::imp_eclair}\n\n\\emph{Eclair} multiplies \nthe fee by a proportional factor depending on the channel properties: \ndelay, capacity, and height (while assuming upper and lower bound for each of them).\nIn addition to the above, Eclair also randomizes \nthe selected paths uniformly, from the 3 (a parameter) best routes.\\footnote{References can be found in: eclair-core/src/main/resources/reference.conf, and the methods FindRoute, edgeWeight in the files eclair/router/Router.scala, Graph.scala}\n\n$$ fee = ams[i+1] \\cdot p[i].propFee + p[i].baseFee $$\n\\begin{align*}\n weight[i] = fee \\cdot &(normalizedDelay \\cdot delayRatio \\\\\n &+ normalizedCapacity \\cdot capacityRatio \\\\\n &+ normalizedHeight \\cdot ageRatio) \n\\end{align*}\nFor upper and lower bounds\\footnote{8640 is the number of Bitcoin's blocks in two months}: \n\\begin{align*}\n    9 &< delay < \\num{2016} \\quad delayRatio = 0.15 \\\\\n    \\num{1000} &< capacity < 2 ^{24} \\quad capacityRatio = 0.5 \\\\\n    0 &< height < \\num{8640} \\quad ageRatio = 0.35\n\\end{align*}\n\n\\subsection{First Empirical Insights}\n\nWe first provide some general insights into the empirical\nproperties of today's Lightning network.\nWhile these insights are not directly related to \nrouting, they provide insights into the behavior\nof the network users, and what this implies\nfor the vulnerability of the network.\n\n\\subsubsection{Methodology}\n\nThe following results are based on measurement data we collected using \na live Lightning node (lnd) \nthat is connected to the mainnet through bitcoind.\nWe used the CLI command $lncli~ describegraph$ in order to extract the network structure,\nand mongodb to store and query the different paths (different implementations, and different parameters).\nWe use information that was dumped from a live mainnet Lightning node at July 24th 2019 17:00 UTC.\n\nNote that using this method, we can examine only public channels;\nour analysis omits private channels.\nWe argue that since these channels are private,  nodes which are not directly part of the private channel are typically not aware of them and will not route through them. \nThus most routing, by design, relies primarily on the public network.\n\n\\subsubsection{Network Analysis}\n\n    The network is composed of\n    4,300 nodes, 33,600 channels, \n    with an average channel capacity of 0.028BTC and an average node capacity of 0.238BTC.\n    \n    \n    Figures~\\ref{figure::base_fee}, \\ref{figure::prop_fee}, \\ref{figure::delay}, \\ref{figure::capacity}, and \\ref{figure::degree} show some basic properties on the Lightning network.\n    In particular, Figure~\\ref{figure::base_fee} reveals that the base fee across channels has two highly common values:\n    most channels simply use the default value, which is 1000.\n    Interestingly, however, the second most frequent value,\n    and the most frequent non-default value, is the minimum possible fee.\n    This provides two main insights: first,  most\n    users do not configure the software beyond the default values,\n    and second, most of those who do, do it in a way which \\emph{supports} the network.\n    Thus, we hardly find any evidence for selfish optimizations of fees in the current network.\n    Both properties may influence a potential attacker.\n    \n    Figure~\\ref{figure::prop_fee} shows the corresponding distribution\n    for the proportional fee, the transaction fee.\n    Here, the default value is 1/1000, which is also by far the most frequent value.\n    Interestingly, however, the value 1 is also frequent; we conjecture that this may be due\n    to a confusion with the base fee, or with units (satoshis vs millisatoshis). \n    Other high values also appear, which one may interpret as an attempt to profit from the network---but this is unlikely: the values are still very small. Given the network scale,\n    nodes are unlikely to be able to benefit from such fees~\\cite{lightning2018paylittle}. This figure also suggests that there are altruistic nodes in the network, which are willing to hold channels without taking fees. Indeed, out of the channels with base fee 0, we obtain that the percentage of channels with 0 proportional fee is about twice the percentage in the whole network (about 40\\% comparing to 24\\%).\n    \n        \\begin{figure}\n    \t\\centering\n    \t\\includegraphics[scale=0.6]{percentage_graphs/base_fee_bar.pdf}\n    \t\\caption{Channels by base fees}\n    \t\\label{figure::base_fee}\n    \\end{figure}\n\n    \\begin{figure}\n    \t\\centering\n    \t\\includegraphics[scale=0.6]{percentage_graphs/prop_fee_bar.pdf}\n    \t\\caption{Channels by proportional fees}\n    \t\\label{figure::prop_fee}\n    \\end{figure}\n    \n    Similarly to the other figures, Figure~\\ref{figure::delay} shows that most of the channels in the network use the defaults. In this case, we see that 144 blocks (a full day), are used as delay by most of the channels. Note that this percentage is similar to the percentage of the default configuration in Figures~\\ref{figure::base_fee} and \\ref{figure::prop_fee}.\n    \n    \\begin{figure} \n    \t\\centering\n    \t\\includegraphics[scale=0.6]{percentage_graphs/delays.pdf}\n    \t\\caption{The delay of the channels (144 blocks is $\\sim 24$ hours)}\n    \t\\label{figure::delay}\n    \\end{figure}\n    \n    \n\nFigure~\\ref{figure::capacity} provides another interesting insight:\nthe capacities of the channels are surprisingly large:\naround 5\\% of the nodes invest a full Bitcoin into a channel.\nOne could interpret this result as quite a high level of commitment to the network. This also corresponds well with the\nsurprisingly low fees observed above. \n\n    \\begin{figure}\n    \t\\centering\n    \t\\includegraphics[scale=0.6]{percentage_graphs/capacities_bar.pdf}\n    \t\\caption{Channels by capacities}\n    \t\\label{figure::capacity}\n    \\end{figure}\n\nFigure~\\ref{figure::degree} shows the number of channels per node.\nWe find that approximately \n5\\% of the nodes are end-points (are of degree 1), and\n25\\% have degree 2.\nThe distribution is highly heavy-tailed and some nodes\nexhibit very high degrees. Furthermore, about 88\\% of the channels are connected to a node with degree higher than 600, and 90\\% of the rest have the default configurations of base and proportional fee. This suggests that most of the channels that were created by the more sophisticated nodes, are almost always connected to the ``central'' nodes.\n\n    \n    \\begin{figure}\n    \t\\centering\n    \t\\includegraphics[scale=0.6]{percentage_graphs/degree_bar.pdf}\n    \t\\caption{number of channels per node}\n    \t\\label{figure::degree}\n    \\end{figure}\n\n    \n    \\begin{figure} \n    \t\\centering\n    \t\\includegraphics[scale=0.6]{degree_vs_capacity.png}\n    \t\\caption{Every point is a single node (5\\% of the nodes was trimmed).}\n    \t\\label{figure::degree_vs_capacity}\n    \\end{figure}\n    \n    \n\\subsubsection{Evaluation of Routing Properties}\n    \nWe next take a deeper dive into routing properties. \nIn particular, we examine the paths that are selected by the \ndifferent routing algorithms used in the three main implementations. \nFor every two nodes we determine the paths for \ntransactions of size 1 satoshi (1000 millisatoshis).\nFigure~\\ref{figure::path_lengths} highlights the impact \nof the different routing algorithms nicely:\nthe path length distribution is affected by the specific algorithm. \n\n    \\begin{figure} \n    \t\\centering\n    \t\\includegraphics[scale=0.6]{percentage_graphs/path_lengths_combined_bar.pdf}\n    \t\\caption{Number of edges in each path for each implementation (for transactions of size 1000 millisatoshis)}\n    \t\\label{figure::path_lengths}\n    \\end{figure}\n\nFigure \\ref{figure::fee_requested} shows the fee volume for the different implementations. We can see that Eclair is the ``cheapest'' implementation, and the reason is clear from the pseudo code; This is the only implementation that multiplies the channel's properties with the fee itself, where the others multiply by the total amount (transaction size + fee). \n    \n\\begin{figure} \n\t\\centering\n\t\\includegraphics[scale=0.6]{percentage_graphs/fee_for_1000.pdf}\n\t\\caption{The fee volume for a transaction of size 1000 satoshis}\n\t\\label{figure::fee_requested}\n\\end{figure}\n    \nIn Figure~\\ref{figure::degree_to_apparences} we see the correlation between the degree of the nodes and the percentage of transactions that route through it. We see that in the lower degrees, there is a high variance in the percentage of paths. On the other hand, the variance decreases in the higher degrees, and the percentage of routes increases respectively.\n    \n\\begin{figure} \n\t\\centering\n\t\\includegraphics[scale=0.65]{degree_to_apparences_3.png}\n\t\\caption{The correlation between the degree and the number of occurrences in paths. The nodes in this graph are ordered according to their degree.}\n\t\\label{figure::degree_to_apparences}\n\\end{figure}\n\n\\subsection{Feasibility of the Attack} \\label{sec::hijack_analysis}\n\nWe now evaluate the feasibility of a DoS attack in two main scenarios:\n\n\\begin{itemize}\n    \\item \\textbf{Collusion by existing central nodes:} We consider the case that a small number of highly central nodes collude and jointly launch a DoS attack using their existing resources and connections.  \n    \\item \\textbf{External attacker:} An attacker joins the network, creates new channels to existing nodes and ``hijacks'' routing using low fees and other channel properties, competing with existing paths.\n\\end{itemize}\n\nIn what follows, let us assume that all pairs of nodes in the network connect \nto one another to transfer $1$ and $1000$ satoshis exactly once. For our analysis,\nwe count the number of disrupted pairs of transactions.\n\n    \n\\subsubsection{Colluding Nodes}\n\nFigure~\\ref{figure::bribe_existing} plots the nodes' centrality:\nthe number of paths going through the $k$ most central nodes (cumulative).\nWe can see that the five highest ranked nodes can disrupt roughly 60\\% of all pair connections, and that differences between different implementations are relatively minor. \nClearly, \nif these nodes collude and start a \nDoS attack, they will cause major disruptions to the network.\n    \nAs Eclair's implementation chooses uniformly between the best three routes, we dive deeper with respect to that implementation. If some of the three top paths between a given pair of nodes do not pass through the attacker, there is a chance that a connection will form.\nTherefore, in Figure~\\ref{figure::bribe_existing_eclair},\nwe examine 3 metrics: (i) The fraction of hijacked best routes (lowest weight route of the 3 options), \n(ii) the fraction of pairs for which we hijack \\textbf{\\emph{all}} the top 3 routes, in order to build an attack that always works,\nand (iii) the \\emph{expected} fraction of hijacked routes from the top 3. \nThe main lesson from the figure is that all metrics are very similar. Thus Eclair's randomization between the top 3 routes helps very little to avoid attackers. \n\nDigging deeper, the figure shows that \n(iii) yields the highest hijack rate, then (i), and the last is (ii). We try to illustrate an explanation in Figure~\\ref{figure::explain_bribe_existing_eclair}.\n    \n    \\begin{figure} \n    \t\\centering\n    \t\\includegraphics[scale=0.6]{percentage_graphs/bribe_attack.pdf}\n    \t\\caption{percentage of paths that go through the most common nodes (assuming transaction sizes of 1000 millisatoshis).}\n    \t\\label{figure::bribe_existing}\n    \\end{figure}\n    \n    \n    \n    \\begin{figure} \n    \t\\centering\n    \t\\includegraphics[scale=0.63]{percentage_graphs/bribe_attack_eclair_types.pdf}\n    \t\\caption{Percentage of paths that go through the most common nodes. Average - increase the probability of hijack a created path, Worst - increase the probability to hijack nodes (every possible paths between the two).}\n    \t\\label{figure::bribe_existing_eclair}\n    \\end{figure}\n    \\begin{figure} \n    \t\\centering\n    \t\\includegraphics[scale=0.28]{explain_eclair_types_directed_devil.png}\n    \t\\caption{If the attacker creates the red edges, the best 3 routes are illustrated in blue dashed lines. The approach to ``hijack the best path\" results in the value $0.5$ (1 of 2 best paths pass through the attacker).\n    \tThe approach ``hijack all the top 3\" results in $0$ (as one path does not pass through the attacker, and ``hijack as many from the top 3\" in $0.66$.}\n    \t\\label{figure::explain_bribe_existing_eclair}\n    \\end{figure}\n    \n\\subsubsection{An External Attacker}\n\nWe now consider attacks by an external attacker that creates links to the network. \nOur discussion will focus on an attacker that tries to maximize the number of hijacked paths out of the the paths between all pairs of nodes, and not necessarily to maximize the fees it collects. \n    \nFigure~\\ref{figure::hijack_attack} examines an attacker that creates new channels in order to attack the network. We used Algorithm~\\ref{alg::implementation} that adds edges one by one, in a greedy approach, and calculated the percentage of the hijacked paths. We compared the attack impact between the different implementations. We added a control group, that was created by selecting connecting nodes uniformly and checking the hijack percentage in lnd. This graph is one of our main results. It shows the consequences of an attack on the network and compares between the different implementations.\n\n    \\begin{figure} \n    \t\\centering\n    \t\\includegraphics[scale=0.6]{percentage_graphs/add_links_attack.pdf}\n    \t\\caption{Number of channels that we need to create (with zero fees and minimum delay) in order to hijack the paths of transaction sizes of 1000 millisatoshis.}\n    \t\\label{figure::hijack_attack}\n    \\end{figure}\n    \nAlternatively, we can consider the hijacked routes as part of the number of paths in the context of all the available connections between two nodes. Figure~\\ref{figure::hijack_attack_new_paths} shows that the attack actually creates new available paths sometimes between nodes who were not previously connected. These new paths are now available \nas the route weight and hops are decreased (below the threshold of lnd).\n    \\begin{figure} \n    \t\\centering\n    \t\\includegraphics[scale=0.6]{percentage_graphs/add_links_attack_news.pdf}\n    \t\\caption{Creating channels in the context of connecting new nodes (lnd).}\n    \t\\label{figure::hijack_attack_new_paths}\n    \\end{figure}\n    \nFigure~\\ref{figure::hijack_attack_fuzz_impact} shows the effectiveness of the weight-fuzzing method of C-lightning. We used the weight function without any fuzzing in order to greedily find the channels that the attacker should create, and then we evaluated our results against routing with the default fuzz parameter. We repeated this 4 times with different fuzz rates. The figure indicates that the re-introduction of the default fuzz ($\\pm 5 \\%$) does not prevent the attack. Our suggested explanation is that the fuzz multiplies\nonly the channel's fee, which is very low in this attack, and thus does not substantially change routing decisions. \n    \n    \\begin{figure} \n    \t\\centering\n    \t\\includegraphics[scale=0.7]{percentage_graphs/c_attack_trained_and_exploits_by_fuzz.pdf}\n    \t\\caption{The hijack percentage in the trained sampling (with no fuzz) \n    \tcompared to the percentage in other samples with fuzz = 5\\% (default).}\n    \t\\label{figure::hijack_attack_fuzz_impact}\n    \\end{figure}\n    \n\\subsection{Amplified Attack With Delays}\n\nThis subsection discusses a way to amplify the DoS attack, by increasing the time that the attacker holds the hijacked transaction (the delay parameter). Here, we suggest the following enhancement: the attacker will report a high delay value for his node, which will then affect the delay of all preceeding HTLCs in the path (recall that delays must accumulate in the reverse order of the path to guarantee intermediary nodes that the outgoing HTLCs expire before the incoming ones).\n\nNote that there is a trade-off for the attacker, because this delay is part of the channel's properties that are used in order to calculate the weight, so higher delay means a stronger effect on fewer nodes. Figure~\\ref{figure::delay_attack} shows the hijack rate when the attacker increases the delay of the 30 channels that were created in the previous subsection. Note that there is a big drop around the delay of 144 blocks, which correlates with the fact that many nodes use this as their parameter (Figure~\\ref{figure::delay}). \n\n\\begin{figure} \n\t\\centering\n\t\\includegraphics[scale=0.6]{percentage_graphs/delay_to_hijack.pdf}\n\t\\caption{The hijack percentage when we create edges for increasing delays, using the top 30 new links from Figure~\\ref{figure::hijack_attack_new_paths}}\n\t\\label{figure::delay_attack}\n\\end{figure}\n    \n\\section{Analysis and Optimization\\\\of Attacker Strategy}\\label{sec:preliminaries}\n\nHaving demonstrated the feasibility of the attacks empirically,\nwe now explore the optimization problems  underlying the attack\nfrom an algorithmic perspective. To this end, we propose\nan analytical model for the adversary.\nIn particular, we will show that while determining the best adversarial\nstrategy is an NP-hard problem, efficient polynomial-time approximation\nalgorithms exist. To this end, we establish an interesting connection\nto centrality theory, which turns out to come with a twist in our setting.\n\n\\subsection{Preliminaries}\n\nLet $V$ be the nodes that participate in the network and $E$ be the channels, \ni.e., $(u,v) \\in E \\subseteq V \\times V$ are nodes with established channel\\footnote{Note that we \nare not interested in the P2P network itself, but only the channels graph.}. \nA valid path from a source node $s \\in V$ to a target node $t \\in V$ is a list of edges $((u_1, v_1), \\cdots, (u_n, v_n)) \\in E^*$ where $u_1 = s, v_n = t$ and $v_i = u_{i+1}$ for all $i$. \n\nPath selection algorithm $\\alg_W$ is an algorithm with the inputs: source node, target node, and the channels' graph.\nIt returns a valid path from the source to the target. \n\nThe centrality of a channel $e$ is the percentage of the network's transactions \nthat pass through this channel. In the same way, define the centrality of a set of channels $e_1, \\cdots, e_n$ (note: this is not necessarily the sum). Denote this function with $\\cent: 2^E \\longrightarrow \\mathbb{R}$. \nNote that although this is a close notion to the \\emph{betweeness centrality}\nin the literature, we consider here routing algorithms that do not necessarily choose the shortest path (lowest weight), like Eclair's top-k randomization. \n\n\\subsection{Attacker's Algorithms}\n    \nIn general, computing an optimal attack is hard,\nas the problem of computing optimal link\nadditions is already NP-hard for shortest paths,\ni.e., betweenness centrality~\\cite{bergamini2018improving}.\nWe hence explore the possibility of polynomial-time\napproximation algorithms: algorithms which are fast\nenough to scale at least to \nall the nodes and channels of the Lightning network (about 4000 nodes at the moment).\n   \n  In the following, we will explore the opportunity introduced\n  by submodularity, and consider the connection to \n  the problem of betweeness maximization with bounded budget~\\cite{bei2011bounded}.\n    \n    \\begin{lemma}\\label{lemma:cent_submodular_existing}\n        The centrality rate of \\textbf{existing edges} for a given node is a \n        non-negative, monotone, sub-modular function. That is, \n        for $\\forall A,B \\subseteq E$ it holds that $\\cent(A) + \\cent(B) \\ge \\cent(A \\cup B) + \\cent(A \\cap B)$\n    \\end{lemma}\n    \\begin{IEEEproof}\n        Recall that $\\cent(A)$ is the number of transactions that \n        go through the channels in A. The non-negative and monotone \n        properties follow directly from the definition. \n        Regarding the sub-modularity, we consider the\n        different cases:  \n        (i) Transactions that go through only \n        one of $A$ and $B$, we count exactly once \n        on both sides of the equation. (ii) Transactions that \n        do not go through $A$ or $B$, we do not count on both sides.\n        (iii) Transactions that go both through $A$ and $B$ and that are in $A \\cap B$,\n        we count twice on every side. (iv) Transactions that go both through $A$ and $B$,\n        but that are not in $A \\cap B$, we count twice on the left side, but only once on\n        the right.\n        Overall, we obtain that the left side can be larger then the right side, \n        as desired.\n    \\end{IEEEproof}\n    \\begin{remark}\n        The above lemma can be rephrased also to $A,B \\subseteq V$ (group of nodes instead of edges).\n    \\end{remark}\n    \n    \\begin{lemma}\\label{lemma:cent_submodular_new}\n        The centrality rate of creating \\textbf{new edges} for \n        a given node is a non-negative, monotone, sub-modular function. \n        I.e.~$\\forall N_1 \\subseteq N_2 \\subseteq V$ and $x \\in V - N_2$,  denote by $A,B$ the groups of new channels that connect\n        $N_1,N_2$ to a new node $v$, respectively, and $e$ that connects $x$ to $v$. \n        Then it holds that $\\cent(A \\cup \\{e\\}) - \\cent(A) \\ge \\cent(B \\cup \\{e\\}) - \\cent(B)$.\n    \\end{lemma}\n    The proof is equivalent to the proof of Theorem~5.2 in \\cite{bergamini2018improving}.\n    The key ideas are: (i) If we consider two sets of new edges $X \\subseteq Y$, then the distance between every two nodes in the graph with the new edges from $X$ is greater equal \n    the distance when adding $Y$. (ii) If all the new edges are connected to only \n    the attacker's nodes, then the attacker's centrality when adding $X$ is \n    lower than when adding $Y$. (iii) Strong inequality in (i) \n    implies strong inequality in (ii).\n    \n    Let us now consider a\n    repetitive attack, in which our goal is to attract others \n    to always route through our node. To achieve this goal, we will \n    add many edges with 0 fees and delay. Each such channel bears some costs for the attacker due to the need to lock funds by the attacker. To decrease costs we therefore wish to minimize the number of channels. \n    \n    \\begin{algorithm}\n        \\DontPrintSemicolon\n        \\SetKwProg{Fn}{Function}{:}{}\n        \n        \\SetKwFunction{FGreedy}{GreedyApproach}\n        \\Fn{\\FGreedy{$k$, $f$, $E, V$, $\\bar{v}$}}{\n             \\For{$i=1, \\cdots, k$}{\n              $e = \\arg\\max_{v \\in V} f(E \\cup \\{(v, \\bar{v})\\})$ \\;\n              $E = E \\cup \\{e\\}$ \\;\n             }\n         }\n         \\caption{Greedy perspective to find $k$ channels that maximize the function $f$}\n         \\label{alg::general_greedy}\n    \\end{algorithm}\n\n    \\begin{theorem}\n        A greedy algorithm that, given edges $E$, node $n$ and number $k$, \n        iteratively finds the edge $e$ that maximizes the centrality rate of $n$ and updates \n        $E = E \\cup \\{e\\}$ (Algorithm~\\ref{alg::general_greedy}), \n        gives a $1-(1-\\frac{1}{k})^k$ approximation.\n    \\end{theorem}\n    \\begin{IEEEproof}\n        As in Section 4 (corollary of Prop. 4.3) of \\cite{nemhauser1978analysis}, \n        we implied the greedy heuristic on the function $\\cent$ (which is a sub-modular \n        set function according to Lemmas~\\ref{lemma:cent_submodular_existing},\\ref{lemma:cent_submodular_new}).\n    \\end{IEEEproof}\n    \n    It remains to show an efficient method to calculate\n    $\\arg\\max_e f(E \\cup \\{e\\})$. \n    This can simply be achieved by dynamic programming: \n    find the best edge to add, and update the state accordingly.\n    Algorithm~\\ref{alg::implementation_naive} describes this idea.\n    \n    In our algorithm, we made some further improvements, \n    based on the fact that there are no\n    valid paths between \\textbf{all} the pairs (because of defaults of max hops or max fee). \n    See Algorithm~\\ref{alg::implementation} for details.\n    \n    \\begin{algorithm}\n        \\DontPrintSemicolon\n        \\SetKwProg{Fn}{Function}{:}{}\n        \n        \\SetKwFunction{FPreProc}{Preprocessing}\n        \\Fn{\\FPreProc{$E$, $V$}}{\n             $dbPaths = \\emptyset$ \\;\n             $dbVertexes = \\emptyset$ \\;\n             \\For{$v \\in V$}{\n                $dbPaths$.update(perform dijkstra and get shortest paths and weights to $v$) \n             }\n             $dbVertexes$.update(map between vertex to all the participated paths)\n        }\\;\n         \n        \\SetKwFunction{FFindNextNaive}{FindNextNaive}\n         \\Fn{\\FFindNextNaive{$E$, $V$, $\\bar{v}$}}{\n            $best$, $value$ = null, 0; \\;\n            \\For{$candidate \\in V$}{\n                $counter$ = 0 \\;\n                \\For{$src, dst \\in V \\times V$}{\n                    \\If{shortest(src, $candidate$) + shortest($\\bar{v}$, dst) $\\le$ shortest(src, dst)} {\n                        $counter$ ++ \\;\n                    }\n                 }\n                 \\If{counter $>$ value} {\n                    $best$, $value$ = $candidate$, $counter$ \\;\n                 }\n             }\n             \\Return $best$ \\;\n         }\\;\n         \n         \\caption{calculate $\\arg\\max_e f(E \\cup \\{e\\})$ efficiently}\n         \\label{alg::implementation_naive}\n    \\end{algorithm}\n    \n        \\begin{algorithm}\n        \\DontPrintSemicolon\n        \\SetKwProg{Fn}{Function}{:}{}\n        \n        \\SetKwFunction{FFindNext}{FindNext}\n         \\Fn{\\FFindNext{$E$, $V$, $\\bar{v}$}}{\n            $best$, $value$ = null, 0; \\;\n            \\For{$candidate \\in V$}{\n                $counter$ = 0 \\;\n                \\For{$src$ reachable to $candidate$}{\n                    \\For{$dst$ reachable from $src$}{\n                        \\If{($src,dst$) is already attacked}{continue}\n                        \\If{shortest(src, $candidate$) + shortest($\\bar{v}$, dst) $\\le$ shortest(src, dst)} {\n                            $counter$ ++ \\;\n                        }\n                    }\n                 }\n                 \\If{counter $>$ value} {\n                    $best$, $value$ = $candidate$, $counter$ \\;\n                 }\n             }\n             \\Return $best$ \\;\n         }\\;\n         \n         \\caption{Our implementation of findNext, while optimizing the runtime and reduce calls to the db}\n         \\label{alg::implementation}\n    \\end{algorithm}\n\n    It is important to notice that the above algorithms are indeed not optimal and are just an approximation. This only strengthens our results: these algorithms yield, in practice, very good results (for the attacker), and more sophisticated attackers may do even more damage.\n    \n\\section{Exploring Solutions} \\label{sec::suggested_solution}\n\nLet us now explore methods that can increase the robustness of the network,\nand at least partially address the tradeoffs observed above.\nIn the following, we will suggest two different solutions:\nthe first is based on a game-theoretic perspective where \nwe analyze the strategies of the attacker and defender as two rational players.\nThe second is based on a set of conclusions that we learned from the above experiments. \n\n\\subsection{Game Theoretic Approach}\n\nWe can reason about the interaction of the attacker and the defender \nas a continuous game, where the attacker tries to sabotage \nas many edges as possible in a long time range. On the other hand, \nthe attacker may try to perform ``fast attacks\", where the adversary gains access to \nmuch resources for a short period, and then\ntries to block the transactions in the network. As for the defender's perspective,\nthe matching examples are if \nit performs cycles of trust-building or maximizes the security of each transaction.\n\nAnother interesting approach to see the interaction is to consider \nnon-selfish nodes, where we utilize the interaction between a single attacker \nand the network as a whole. The nodes cooperate in order to increase the overall security of the network. This approach is interesting because it must include other incentives to the nodes\n(otherwise they will employ selfish routing).\n\nIn the following, as a first step, \nwe will examine only a very simple approach, \nin which the defender is selfish, and the attacker ties to attack a single transaction.\n\n\\boldheader{Simple example}\nWe will present here a short game theoretic analysis of a specific case, \nwherein a selfish node (defender) tries to perform a single transaction. \nOn the other hand, the attacker is trying to attack this node specifically, \nknowing the exact target node of the transaction and the transaction size. \nWe assume that they both are fully rational.\n\nThe model that we suggest here is simple: assume that the\nweight function is simply the sum of fees on channels on the route, \nand that the attacker can always create a channel that has less weight \ncompared to an existing channel. For the attacker, the price to create nodes \nis negligible, and the price to establish a channel with capacity of $c$ is $c \\cdot I$, \nwhere $I$ is a global constant that represents liquidity costs (i.e., \nthe attacker pays the interest rate on locked funds that are otherwise unused \nfor the duration of the attack)\\footnote{Note that we omit the time span for which \nthe money is locked. This obviously may change $I$. We will get back to this point in the next subsections.}. Moreover, assume that in the case of successful attack, the attacker wins the same value that the defender looses. Denote this value by $H$. The defender, tries to minimize the weight to execute the transaction.\n\nThe pure strategies available to the defender are described by all the paths to the target, \nand the attacker's pure strategies are always to add new nodes and new channels.\nThe utility function is thus defined as follows: if the attacker created the channels $C_{att} = a_1, \\cdots, a_k$ and the defender chooses the path $C_{def} = d_1, \\cdots, d_l$, then the utility of the attacker is $U_{attacker} = H \\cdot \\delta_{C_{att}, C_{def}} - I \\cdot \\sum_{c \\in C_{att}} c_{capacity}$, and the defender's utility is $U_{defender} = -H \\cdot \\delta_{C_{att}, C_{def}} - \\sum_{c \\in C_{def}} c_{fee}$, where $c_{capacity}, c_{fee}$ are the capacity and fee of the channel $c$, and $\\delta_{A,B}$ is 0 if $A \\cap B = \\emptyset$ or 1 otherwise.\n\nIntuitively, in every Nash equilibrium in this game, \nthe attacker will hijack the paths that the defender will use with the highest probability. On the other hand, the defender will try to minimize the probability to use every set of specific channels (not being predictable).\n\nExploring examples in different graphs is interesting,\nbut beyond the scope of this paper and left for future research. \n\n    \n    \n    \n    \n    \n    \n\n    \n    \n\n  \n\n\\subsection{Lesson Learned - Suggested Weight Function}\nWe next suggest first ideas \nbased on the empirical experiments that we did in Section~\\ref{sec::hijack_analysis}. \nWe will focus on insights that aim to increase the cost of a successful hijack attack, \nand we hope that these insights will be considered when implementing a new weight function. \nWe later give an example of the impact of slight changes to Eclair's weight function.\n\nThe first lesson is related to the vulnerability of Eclair to the delay attack. \nHere, the weight is determined by multiplying the channel's parameters with the fee. \nThis creates a tradeoff between the fee and the delay: when multiplying\nthe delay and dividing the fee by the same factor, this will result in the same weight, \nalthough the more intensive attack. Therefore we suggest to either multiply the delay by the total amount of the transaction or to summarize it to the other evaluations.\n\nThe second lesson is how to create a non-deterministic algorithm. \nC-lightning adds noise to the channel's fee (fuzzing). As we saw, it has a\nlow effect in case the attack because of the exceptionally low fees of the attack channels. On the other hand, Eclair chooses uniformly a path among the top ones (and not necessarily the best), and that has also a low effect in a case of an attack because of the amount of different paths that the attacker \ncan create with a small amount of resources. Therefore we suggest to add fuzz to the total weight of the channel, and avoid choosing one of the top-$k$. The difference between these two options is rather \nthat the attacker needs to be better than the others by a small constant difference or linearly.\n\nFew more lessons worth pointing: (i) older nodes are better because the interest rate (as a parameter in the utility of the attacker) is higher; (ii) high capacity is safer than low capacity; (iii) the delay is important.\n\nWe were considering to add the betweeness rank to the weight calculation, \nbut we think that it makes the routing algorithm computationally expensive, and therefore diverges \nfrom the goal to create simple improvements to existing weight functions.\n\n\\boldheader{Improve Eclair}\nWe think that creating a weight function that will be resilient to hijack attacks and preserve important network properties (such as connectivity, low fees, etc.) should be researched properly. In the next discussion we will not suggest an optimal weight function, but only try to improve the existing weight functions using the same structure of implementation. We based our suggestion on Eclair's weight function that was presented in Section~\\ref{subsubsec::imp_eclair}.\n\nWe suggesting the improvement of taking into account the following channels properties. \nThe weight parameters should be determined according to the network and the user's configuration. The general structure is:\n$$ scale = \\mathcal{N}(1, \\sigma^2) $$\n$$ fee = ams[i+1] \\cdot p[i].propFee + p[i].baseFee $$\n\\begin{align*}\n we&ight[i] = scale \\cdot (\\\\\n &normalizedDelay \\cdot delayRatio \\\\\n &+ normalizedHeight \\cdot ageRatio \\\\\n &- normalizedCapacity \\cdot capacityRatio \\\\\n &- capacity \\cdot height \\cdot IntrestRatio \\\\\n &+ \\frac{fee}{ams[i+1]} \\cdot feeRatio \\\\\n )\n\\end{align*}\nFor $\\mathcal{N}(1, \\sigma)$ which is the standard Gaussian distribution around $1$ \nwith variance $\\sigma^2$ and some normalization factors and ratios. Note that the fee is not normalized, the scale multiplies everything and the negative sign in the capacity parameters.\n\nIn order to evaluate \nthe above function, we took the following parameters: $\\sigma = 0.2, delayRatio=0.5, ageRatio=0.5, capacityRatio=0.3, feeRatio=100$, and the normalization parameters of Eclair.\nWe implemented this weight function and evaluated it using the same experiments as before. The results are presented in Figures~\\ref{figure::suggested_bribe_attack},\\ref{figure::suggested_add_links_attack},\\ref{figure::suggested_delay_attack}. \n\nWe note that these results require further exploration, specifically, it is important to evaluate other features of the new weight function, including the average fees for paths that it finds, and the failure rates of paths it selects due to liquidity imbalances. We leave such deeper evaluations for future work. \n\n\\begin{figure} \n\t\\centering\n\t\\includegraphics[scale=0.55]{percentage_graphs/suggested_aviv_bribe_attack.pdf}\n\t\\caption{Percentage of paths that go through the most common nodes (assuming transaction sizes of 1000 millisatoshis).}\n\t\\label{figure::suggested_bribe_attack}\n\\end{figure}\n\\begin{figure} \n\t\\centering\n\t\\includegraphics[scale=0.6]{percentage_graphs/suggested_aviv_add_links_attack.pdf}\n\t\\caption{The hijack percentage in the trained sampling (with no fuzz) comparing to the percentage in other samples with fuzz = 5\\% (default).}\n\t\\label{figure::suggested_add_links_attack}\n\\end{figure}\n\\begin{figure} \n\t\\centering\n\t\\includegraphics[scale=0.6]{percentage_graphs/suggested_delay_attack.pdf}\n\t\\caption{The hijack percentage when we create edges with higher and higher delay, using the top 30 new links}\n\t\\label{figure::suggested_delay_attack}\n\\end{figure}\n\n\\section{Related Work}\\label{sec:relwork}\n\nSince Bitcoin was first deployed in 2009 \\cite{nakamoto2008bitcoin}, \nit received significant interest in academia, including security aspects.\nWhile the main initial security research focus was on \nthe analysis of the double-spending attack \\cite{rosenfeld2014analysis},\nmany additional vulnerabilities were identified later~\\cite{li2017survey}.\n\nAlso the P2P network has been analyzed intensively, \nfor Bitcoin \\cite{koshy2014analysis} and Ethereum \\cite{kim2018measuring} (including the\ncentralization analysis in \\cite{gencer2018decentralization}), \nbut similar analysis existed already, e.g., \nfor Skype \\cite{guha2005experimental}. Our routing attacks can generally\nbe understood from the perspective of centrality; as discussed,\nespecially betweenness centrality has been studied much in the literature, as well as its interesting generalizations~\\cite{dolev2010routing}. However, our model is different because the weight of each edge is determined by all the path (and not only by the edge). More implicitly, the weight of the edge is calculated using the amount of millisatoshis that it is transfer, and this amount could be changed if we will choose a different path (because of the difference in fees).\n\nAttacks on the network level are also known, e.g.,\nthe eclipse attacks on Bitcoin \\cite{heilman2015eclipse} and Ethereum \\cite{marcus2018low}, \nor the attacks possibly performed by ASes \\cite{apostolaki2016hijacking}. \nRoute hijacking attacks were researched in a variety of fields, such as wireless ad-hoc networks \\cite{deng2002routing}, general P2P networks \\cite{naoumov2006exploiting}, and Bitcoin~\\cite{apostolaki2017hijacking}.\n\nAn interesting recent work also discusses \npath hijacking in the Lightning network~\\cite{rohrer2019discharged}.\nThere, the focus is on isolation attacks: \nthe authors consider only the graph of the channels, without referring to the different implementations of the routing algorithms. Our work continues this idea and generalizes it to a general DoS\nattack, where the attacker tries to damage the transactions of the network and not the nodes themselves. Therefore the delay amplifier and the analysis of the differences between the weight functions and \nrandomized path selection has not been researched yet.\n\n\\section{Conclusion}\\label{sec:conclusion}\n\nThis paper identified a novel attack on off-chain networks \nwhich introduces an interesting tradeoff both for the attacker \nas well as the rational defender. We have demonstrated the feasibility of this\nattack on different networks and provided a first analysis.\n\nWe showed an empirical difference between the existing methods used\nto randomize the chosen path. Random fuzzing on the fee of every channel was found to yield, in practice, weak protection against this type of attack compared to fuzzing the overall weight of the channel. Furthermore, we showed that if the defender considers the fee as a multiplier to the weight, then it will be especially vulnerable to the increasing delay attack.\nWe also proposed a first game theoretic model\nfor designing a new weight function.\n\nWe see our work as a first step and believe that it opens several interesting\navenues for future work. Generally, it will be interesting to analyze properties that weight functions should have, and build optimal functions accordingly.\nIt would also be interesting to consider the use of mechanism design\nto incentivize nodes to choose routes that will increase the overall security of the network. \nFinally, it will be interesting to examine this attack on future features,\nsuch as node ``switchboards\" for message passing: the attacker may connect only to them to  control all the nodes that use it.\n\n\\balance\n\n\\end{document}\n</paper 2>\n\n<paper 3>\n\\title{Optimally Reliable \\& Cheap Payment Flows on the Lightning Network}\n\n\\begin{document}\n\n\\maketitle\n\n \n\\begin{abstract}\n  Today, payment paths in Bitcoin's Lightning Network are found by searching for shortest paths on the fee graph.\n  We enhance this approach in two\n  dimensions. Firstly, we take into account the probability of a payment\n  actually being possible due to the unknown balance distributions in the\n  channels. Secondly, we use minimum cost flows as a proper generalization of\n  shortest paths to multi-part payments (MPP).\n\n  In particular we show that under plausible assumptions about the balance\n  distributions we can find the most likely MPP for any given set of senders, recipients and amounts by solving for a (generalized) integer\n  minimum cost flow with a separable and convex cost function. Polynomial time\n  exact algorithms as well as approximations are known for this optimization\n  problem.\n\n  We present a round-based algorithm of min-cost flow computations for\n  delivering large payment amounts over the Lightning Network. This algorithm\n  works by updating the probability distributions with the information gained\n  from both successful and unsuccessful paths on prior rounds. In all our\n  experiments a single digit number of rounds sufficed to deliver payments \n  of sizes that were close to the total local balance of the sender.\n  Early experiments indicate that our approach increases the size of payments that can be reliably delivered by several orders of magnitude compared to the current state of the art.\n\n  We observe that finding the cheapest multi-part payments is an NP-hard problem\n  considering the current fee structure and propose dropping the base fee to make\n  it a linear min-cost flow problem. Finally, we discuss possibilities for\n  maximizing the probability while at the same time minimizing the fees of a\n  flow. While this turns out to be a hard problem in general as well --- even in\n  the single path case --- it appears to be surprisingly tractable in practice.\n  \n\\end{abstract}\n\n\\section{Introduction}\nThe Lightning Network is a payment channel network using source-based onion routing to deliver payments from senders to recipients.\nA necessary condition for a single onion package to be delivered successfully is that the onion follows a path with sufficient liquidity.\nIn this context sufficient liquidity does not just mean that the publicly known channel capacities of the channels on the path between sender and recipient are larger than the payment amount. Rather, every node along the path has to own enough of the channel capacity as their local balance to be able to forward the amount to the next hop.\nAs broadcasting the balance values would hinder the scalability of the Lightning Network they are generally kept private and thus unknown to other nodes.\nCurrently the sender node mitigates this uncertainty by entering a trial-and-error loop for delivering payments.\nHowever, past experiments have demonstrated that payments are often failing, in particular when the amounts to be delivered are increasing\\cite{DBLP:journals/corr/abs-1911-09432,DBLP:journals/corr/abs-2006-14358,lange2021impact, pickhardt2021security}.\n\nCurrent implementations largely find candidate paths for the trial-and-error-loop by solving\nshortest path problems or generalizations like $k$-shortest paths on the\nweighted channel graph, where the weights correspond to the routing fees charged by nodes forwarding a payment along a channel.\\footnote{We also observe a combination of the fee function with features like a penalty for longer CLTV values, prior experiences of using the channel and a bias against smaller channels.}\nThat approach tries to find the cheapest payment path for the sender but does not systematically factor in success probabilities. As a consequence, the payment loop might try a large number of cheapest but unreliable paths before timing out instead of using slightly more expensive but vastly more reliable paths. It also does not produce an optimal split of the payment into multiple paths.\n\nSoftware implementations of the Lightning Network protocol have mainly focused on three strategies for handling the uncertainty of sending a payment.\n\\begin{enumerate}\n\\item Incentivizing the path finding algorithm to favor larger channels.\\footnote{\\url{https://lists.ozlabs.org/pipermail/c-lightning/2021-May/000203.html}}%clightning dev\n\\item Ad-hoc splitting of large payment amounts into smaller ones after failed attempts using a technique called multi-part payments (MPP).%\\footnote{\\url{https://www.coindesk.com/multi-part-payments-could-bring-bigger-bitcoin-sums-to-lightning-network}}\n\\item Using provenance scores of nodes and channels and other data collected during operation of a node to estimate which nodes and channels might be reliable.\n\\end{enumerate}\n\nIn this work we are developing a general technique that is achieving the effects of these rather ad-hoc techniques in a systematic fashion.\nThis text largely builds upon and extends prior research which pointed out that\nthe uncertainty of channel balance values can be mathematically modeled to\narrive at a probabilistic path finding scheme\\cite{pickhardt2021security}. While\nthis earlier work demonstrated a significant reduction in failed attempts while\ndelivering payments it still mostly kept the perspective of a single path finding\nproblem.\n\nIt has long been a folklore view that delivering payments on the Lightning Network can be modeled as a network flow problem.\nIn what follows we show that the discovery of the most likely multi-path payment is equivalent to solving a (generalized) min-cost flow problem in which the negative logarithms of channel success probabilities are considered as the cost of using a channel.\nThe channel success probabilities are priors that have to be estimated, through sampling for example.\nUnder the assumption of an independent uniform balance distribution on each channel as the prior, finding the most probable multi-part payment for a given amount from a sender to a recipient can be usefully modeled as solving an integer min-cost flow problem with a separable convex cost function.\nWhile in general min-cost flow problems are complex\noptimization problems, the above mentioned subclass is known to have polynomial\ntime solutions with a runtime complexity of $O(m \\cdot \\log(U) \\cdot S(n,m))$\nwhere $n$ is the number of nodes, $m$ is the number of edges on the network, $U$\nis the amount to be delivered, and $S(m,n)$ is the time it takes to obtain a\nsolution to the single source shortest path problem\\cite{Minoux1986,ahuja1993network}. This\nis typically done using Dijkstra's Algorithm in time $O(m+n) \\cdot \\log(n)$, so\nthat we arrive at a total runtime of $O(\\log(U)\\cdot(m^2+mn)\\cdot\\log(n))$.\n\nIf the balance values were known, the decision if a payment between two nodes can be conducted could be arrived at by finding a max-flow / min-cut and comparing it to the amount that is to be delivered.\nGiven the uncertainty of channel balances, the decision problem is much harder to solve and still involves a trial-and-error loop.\nWe introduce a practical round-based algorithm that can either quickly deliver the payment or decide with a high probability that the min-cut is lower than the payment amount that is supposed to be delivered between sender and receiver.\nIt starts by creating the most likely MPP split as the solution of the min-cost flow problem and sending out the partial payments.\nThe algorithm reduces its uncertainty of the balance values by learning from the failures and successes.\nThis is done by updating the prior probabilities after the failing onions have returned.\nFinally it creates another candidate MPP for the residual amount by solving a min-cost flow on the updated graph.\n\n\\section{Payments as Integer Flows}\n\\label{flows}\nLet $G = (V,E)$ be a directed graph and $u: E \\longrightarrow \\mathbb{N}$ a function assigning capacity values to all edges in the graph.\nFor every node $v\\in V$ let $b_v \\in \\mathbb{Z}$ denote its \\emph{excess, supply or demand}.  Typically $b_v$ will be $0$ except for the source node $s$ (with supply $b_v>0$) and the destination $d$ (with demand $b_v<0$). We call a function $f: E \\longrightarrow \\mathbb{N}_{0}$ a \\emph{flow} if the following conditions hold:\n\\begin{enumerate}\n\\item \\textbf{capacity constraint}: For every edge $e \\in E$ we have: $$0 \\leq f(e) =: f_{e} \\leq u_{e} := u(e).$$\n\\item \\textbf{flow conservation}: For every node $i\\in V$ we have: $$\\sum_{(i,j)\\in E} f_{ij} - \\sum_{(j,i)\\in E} f_{ji} = b_i.$$\n\\end{enumerate}\n\n\\subsection{Flows on a Known Balance Graph}\nAssuming the balance values of every payment channel of the Lightning Network were publicly known, one could create a flow network called \\emph{balance graph} as follows:\nFor any given payment channel between two nodes $i$ and $j$ with capacity $u$ we know that the balance $u_j$ of node $j$ plus the balance $u_i$ of node $i$ must be equal to the capacity $u$.\nOn the balance graph we add two directed edges for the payment channel between the nodes $i,j$.\nFirst we add the edge $(i,j)$ with a capacity of $u(i,j) = u_i$ and then we add another edge in the opposing direction $j,i$ with a capacity of $u(j,i)=u_j$.\\footnote{In reality, channel reserves would need to be accounted for by lowering the capacities to the spendable balances.}\n\nObserve that in this balance graph, a set of payment paths from $s$ to $t$ determines a flow simply by summing up the amount sent through any edge.\\footnote{We abstract from the fact that the amount sent through a payment path diminishes along the path by the fees collected; we assume the total fees are included until the end. See Section~\\ref{generalized} for a discussion of the impact of this relaxation.}\nIn fact, the converse is also true: It is easy to see that any flow can be decomposed into paths from $s$ to $t$ and cycles in linear time~\\cite[p.~79ff]{ahuja1993network}.\nSince cycles do not change supply or demand at any node, we can safely ignore them.\nIn this way, we can represent any MPP split as a flow and vice versa.\nWe emphasize that the paths of the decomposed flow that lead to the MPP split do not need to be disjoint.\n\nGiven the balance values, we could decide the maximum possible amount that can be sent for any given node pair $s,t \\in V$ by computing the minimal $s$--$t$-cut.\nUsing, say, the Ford-Fulkerson algorithm\\cite{ford_fulkerson_1956} one could compute a max-flow and disect it into a series of paths.\nThese paths could then be used to construct several onions for a multi-part payment.\n\nIn a preliminary test we use two different prior distributions to generate two static balance graphs and check on each how often the min-cut between arbitrarily chosen pairs of sender and receiver is actually determined by the minimum of the local outbound capacity of the sender and the local inbound capacity of the recipient.\nIn Figure~\\ref{fig:mincut} we can see that for both of these distributions --- which have been observed on the entire Lightning Network and an active core subset, respectively --- in only about $5\\%$ of the payment pairs is the max-flow smaller than the maximum amount locally sendable by the payer and the maximum amount locally receivable by the target node.\n\\begin{figure}[htpb]\n  \\center\n  \\includegraphics[width=0.45\\textwidth]{img/maxFlowFraction.png}\n  \\caption{Showing the percentage of payment pairs where the maximal payable amount is actually lower than the upper bound given by the local balance known to both sender and recipient.}\n  \\label{fig:mincut}\n\\end{figure}\n\nThe fact that with publicly known balance values in $19$ out of $20$ payment pairs the amount that can be delivered is as high as the local limits of the payment pair is in stark contradiction to the currently observed and reported \\cite{DBLP:journals/corr/abs-1911-09432,DBLP:journals/corr/abs-2006-14358,lange2021impact, pickhardt2021security} success rates. In fact, these are declining heavily with amounts larger than $100,000$ satoshi (1 BTC = 100,000,000 sat) for which the delivery should be almost always possible.\nWe conjecture that this is due to the fact that in reality, the balance values are not publicly known.\nThis forces us to take the total channel capacities $u$ as capacities on our flow network in both directions.\nNote that finding a max-flow on this network is not sufficient for deciding if a payment can be made. % removed footnote as it is actually a bit more subtle in reality https://twitter.com/renepickhardt/status/1412383409578590209\nHowever, we can generalize the flow model to the case of uncertain balance values and will return to this question in Section~\\ref{rounds}.\n\n\\subsection{Uncertainty Networks}\nEarlier research~\\cite{pickhardt2021security} has introduced a mathematical framework for handling uncertain balance values in payment channels with the goal of making path finding decisions that maximize the success probability of payment paths.\nWe recall that --- given a prior belief about the balance uncertainty via a probability distribution $P_e$ and a random variable $X_e$ ---  the channel success probability for a payment of size $f_e$ for a channel $e$ is expressed as $P_e(X_e\\geq f_e)$.\nWhereas in~\\cite{pickhardt2021security} the goal was maximizing the path success probabilities, here we aim to maximize the success probability for the entire flow. Assuming the channel balances to be independently distributed, this combined success probability is simply the product of all channel success probabilities:\n\n\\[\nP(f)=\\prod_{e\\in E}P(X_{e} \\geq f_e)\n\\]\n\nAny flow $f$ that maximizes the success probability $P(f)$ is also minimizing $-\\log\\left(P(f)\\right)$ and vice versa.\nUsing the fact that the logarithm is a group homomorphism from the multiplicative group of positive real numbers to the additive group of real numbers we can write:\n\\[\n-\\log\\left(\\prod_{e\\in E}P_e(X_{e} \\geq f_e)\\right) = \\sum_{e\\in E}-\\log\\left(P_e(X_e \\geq f_e)\\right)\n\\]\nThe right hand side of the equation has the form of a separable cost function $C$ for the flow $f$ from the theory of min-cost flows:\n\\[\nC(f) := \\sum_{e\\in E}-\\log\\left(P_e(X_e \\geq f_e)\\right)\n\\]\nGiven fixed probability distributions for the channel balances, finding the most likely flow is therefore equivalent to finding a flow of minimum cost on this \\emph{uncertainty network}. Any such flow can then be disected into the most likely multi-path payment as in the previous section.\n\nIn general, finding optimal solutions to the min-cost flow problem with non-linear costs is NP-hard~\\cite{guisewite1990minimum}. Fortunately, in the special case of integer flows and capacities together with a separable convex cost function a polynomial algorithm has been introduced by~\\cite{Minoux1986}.\nSince our flows are integer-valued and the cost function is separable we need to understand when a cost function arising from channel success probabilities is convex in order to be able to apply such an algorithm.\nBecause the cost function $C$ is separable we can test convexity independently for any given channel $e$ and the resulting cost function $c_e(f_e):=-\\log\\left(P_e(X_e\\geq f_e)\\right)$\nAfter simplifying by assuming a flow value $x:=f(e)$ and defining $p(x):=P_e(X_x\\geq x)$ we get:\n\\[\nc_e(x)=-\\log(p(x))\n\\]\nAssuming this function is twice differentiable, it is convex iff its second derivative is be nonnegative on the entire domain.\nThe first derivative is:\n\\[\nc_e'(x) = -\\frac{p(x)'}{p(x)}\n\\]\nand the second derivative is:\n\\[\nc_e''(x) = \\frac{(p'(x))^2-p(x)p''(x)}{{p^2(x)}} \\geq 0\n\\]\nIn particular we see that the negative log probabilities result in a convex cost function iff the following inequality holds:\n\\[\n(p'(x))^2 \\geq p(x)p''(x)\n\\]\nIn the uniform case $p(x)=\\frac{u+1-x}{u+1}$ (cf.~\\cite{pickhardt2021security}) we have $p'(x)=\\frac{-1}{u+1}$ and $p''(x)=0$ demonstrating that the resulting cost function $c_e(x)$ is convex on its entire domain.\nThis indicates that the polynomial algorithm can be used to find the flow that minimizes:\n\\[\nC(f)=\\sum_{e\\in E}-\\log\\left(\\frac{u_{e}+1-f_e}{u_{e}+1}\\right)\n\\]\nThus the most probable multi-part split for delivering the amount $U$ can be found by solving a min-cost flow problem and disecting the flow into paths.\n\nWe do not explicitly handle fees in this model, but observe that if we can find a flow that includes an upper bound to the total fees, the real payment success probability will be at least as high as the one predicted by this model, since the transported amount is only falling along the paths and our probability function is monotonic.\n\n\\subsection{Maximizing Success Probabilities vs Minimizing Fees}\n\\label{fees}\nThe current routing fee function on the Lightning network is a separable cost function depending only on the flow across each channel.\nHowever, it is easy to see that the function is not convex at the transition between flow $0$ (cost $0$) and flow $1$ (cost base fee plus unit flow cost), whenever the base fee is larger than the proportional unit flow cost. In fact, a cost function of this form is often called a \\emph{concave fixed-charge cost} in the literature. Unfortunately, finding the flow that minimizes a cost function of this form is a strongly NP-hard problem as shown in~\\cite{guisewite1990minimum} by reduction from 3-SAT to a min-cost flow problem with only fixed-charge costs.\n\nOn the other hand, if the Lightning Network community were to drop the base fee, the separable cost function would become linear in the flow value of each arc.\nFinding an MPP split that minimizes routing fees could easily be done by solving the linear min-cost flow problem using any of a number of algorithms~\\cite{ahuja1993network}.\nHowever, we note that minimizing the routing fees alone tends to\nsaturate the full capacity of cheap channels. Such paths are highly improbable to succeed since they can only do so when the entire balance is on the right side of the channel (even ignoring channel reserves). In our opinion that makes optimizing purely for fees a poor choice in general. On the other hand, only maximizing the success probability might allow routing node operators and liquidity providers to game the algorithm and extract unlimited fees.\n\nSo in practice, it should be our goal to both minimize fees and maximize success probabilities.\nNaturally, these goals can be contradictory, since node operators\ncan and will choose fees freely. Two ways of expressing this goal might be\n\\begin{enumerate}\n\\item to minimize fees with a side constraint of achieving a certain minimal probability bound, or\n\\item to maximize success probability with a side constraint of staying below a certain maximal fee bound.\n\\end{enumerate}\n\nUnfortunately, both of these problems are weakly NP-hard via the following argument:\nFirst, observe that adding unit capacities to the problems and looking for a flow of size 1 makes them instances of the so-called constrained shortest-path problem.\nThen,~\\cite[p.~798]{ahuja1993network} shows that this subclass of constrained min-cost flow problems is already NP-hard by reduction from the Knapsack problem.\n\nFortunately, the picture is not quite as bleak as it looks on first sight.\nFirst, the reduction only implies weak NP-hardness, meaning that we could find a polynomial algorithm whenever $U=O(n^k)$ for some $k$.\nStrictly speaking, the flow size $U$ is always bounded by a constant in our applications, since the total number of bitcoin is limited. Looking into the theory of Lagrangian relaxation~\\cite[p.~598ff]{ahuja1993network} methods, however, gives us immediate practical results instead of just hope.\n\nIn fact, the two cases enumerated above collapse into one when we try to find bounds for them by applying a simple one-dimensional Lagrange multiplier, that is we try to minimize:\n\\[\n\\sum_{e\\in E}-\\log(\\frac{c_{e}+1-f_e}{c_{e}+1})+\\mu\\cdot f_e\\cdot fee(e)\n\\]\nthe linear combination of both costs, with a suitable multiplicative constant\n$\\mu$.\nBy calculating this combined min-cost flow (note that the linear combination of\nthe two cost functions remains convex), not only do we get a feasible flow of size $U$, but because of the \\emph{Lagrangian bounding principle}~\\cite[p. 605f]{ahuja1993network}, whatever total fee $x$ and success probability $p$ we achieve, we are guaranteed that this combination is optimal on both sides.\nThat is, there is no solution with cheaper total fees than $x$ and at least probability $p$, and there is no solution with higher success probability than $p$ that still only costs at most $x$.\nSo in case we are not satisfied with the parameters of the solution we got, finding an adequate solution is reduced to either increasing $\\mu$ and getting a potentially cheaper, but less probable solution, or decreasing $\\mu$ and receiving a more reliable but also more expensive solution.\n\n\\subsection{Generalized Flows with Losses}\n\\label{generalized}\nSo far we have ignored the fact that every node on every path takes some part of the payment as a fee, which means that the total amount of flow gets smaller towards the target.\nThis observation is best described by a slightly more general model called \\emph{generalized (minimum cost) flows with gains and losses}. In this formulation, the flow conservation condition for any node $i\\in V$ is changed to $$\\sum_{(i,j)\\in E} f_{ij} - \\sum_{(j,i)\\in E} \\gamma_{ji}f_{ji} = b_i.$$\nThus, when we send 1 unit of flow along an edge $(i,j)$, $\\gamma_{ij}$ units of flow arrive at node $j$. The edge multipliers $\\gamma_e$ are positive rational numbers\\footnote{In the Lightning Network, these correspond to the proportional part of the fee. Again, including the base fee makes solving the problem infeasible, which is why we propose abolishing it.} and the edges are called \\emph{gainy} ($\\gamma_e > 1$) or \\emph{lossy} ($\\gamma_e < 1$) accordingly.\nNotice that until now, this formulation still depends on us knowing the exact supply/demand amounts at the source and destination nodes. This is especially troubling here, because we cannot just use an upper bound to the supply as before: there might not be a solution that uses the corresponding exact amount of fees. Therefore we introduce a cost-free high-capacity gainy (say, $\\gamma_s=2$) self-loop at the source node and set the source excess to zero. This allows for introduction of an arbitrary amount of flow at the source. Then, we aim to minimize the convex cost function as before under the remaining flow and capacity constraints.\n\nThe generalized flow problem is clearly a proper generalization of the min-cost flow problem outlined above. Unfortunately, it also appears to be harder to solve. The algorithm that we implemented for the min-cost flow problem does not seem to carry over to this more general problem. We did find pointers to some approaches~\\cite{tsengbertsekas} that might be worth exploring. So far, we have been reluctant to invest too much effort in this direction, because in our application, the fees are generally expected to be a small fraction of the total flow.  Thus it is doubtful if the greater computational effort will be worth the slightly more favorable probability/fee result.\n\n\\section{Payment Algorithm}\n\\label{rounds}\nOnce we are able to efficiently compute minimum cost flows optimizing either for success probabilities, fees or both using the Lagrange relaxation we naturally arrive at a round-based payment algorithm that can be used by a node $s$ that wishes to send an amount $U$ to a destination $d$.\nFor now, we assume a Lagrange-style combination between channel success probabilities and the linear fee rate function, as we believe this achieves the most useful results.\n\nThe round-based algorithm is initialized by the sending node $s$ in the following way:\nIt starts by creating a new uncertainty network model $N$ of the Lightning Network which encodes the initial uncertainty and information $s$ is gaining about the balance distribution on the network during the rounds.\nIn order to deliver the full amount, the node $s$ will have to solve a minimum cost flow problem, send out onions and update the uncertainty network based on the successes and failures of the onions in each of the rounds.\nThe uncertainty network $N$ consists of all the nodes that are on the same connected component as $s$ on the channel graph.\nThe edges of $N$ correspond to payment channels on the Lightning Network.\nIf $s$ has no further knowledge about the channels, a directed arc for both directions of each payment channel is added to the uncertainty network.\nThe capacities of the edges are set to the capacities of the payment channel (possibly deducting channel reserves).\n\nNotice for example that in the local channels of $s$ the balance values are known and there is no uncertainty.\nThus the capacity for those channels is set to the local balance value $u$ as this is the most that can currently be sent on those channels.\nThe probability is set to $1 = P(X\\geq a | X=u)$ for any amount $a$ between $0$ and $u$.\nThis results in a negative log probability of $0$ and thus makes it very cheap for the minimum cost flow computation to utilize the liquidity in this channel. In particular since the node $s$ also does not have to pay any fees to itself.\n\nSimilarly, the receiving destination node $d$ could tell the sending node about the state of its local channels and this knowledge could also be incorporated into the graph by creating edges with 0 log probabilities and decreased capacities.\\footnote{Communicating this information in invoices is currently not part of the protocol but routing hints in the invoices might be extended to encode such information.} In Figure~\\ref{fig:mincut} we have demonstrated that for about $95\\%$ of all payment pairs the amount that can be delivered through the network is actually limited by the local outbound capacity of the sender and the local inbound capacity of the receiving node which yields another motivation for this information to be shared.\n\nAfter the setup phase the round-based phase starts. Here the algorithm iterates over the following steps until either the entire amount is delivered or the minimum cost flows become too unlikely or cannot be computed for the residual amount, which means the minimum $s$--$d$-cut has been discovered.\\footnote{In such cases it seems reasonable that $s$ open a new payment channel with $d$ for at least the remainder amount.}\nThe round starts with $s$ computing a minimum cost flow for the amount $U$ to $d$ following the optimization goal.\nThe flow is then decomposed into paths and cycles. Note that cycles cannot appear in our application as long as we do not allow negative cost edges. If they appeared, they would indicate profitable rebalancing options that may or may not be reachable for $s$. Since negative fees are not allowed in the BOLT standards, we can safely ignore cycles for now.\n\nThe node then conducts a multi-part payment by concurrently sending out onions along the resulting paths.\nIn practice one has to chose a decomposition of the flow into paths that does not create more HTLCs on a remote channel than the HTLC limit encoded into the protocol permits.\nThis engineering challenge as well as others like the question of channel reserves are ignored here for simplicity of the presentation.\nDespite the fact that the most likely flow was used, some of the onions will not reach the target in most cases. So the sending node gathers information from the error codes of failed attempts as previously described in~\\cite{tikhomirov2020probing} as well as information from the paths that have not returned an error to update the probabilities as described in~\\cite{pickhardt2021security}.\nThis step decreases the uncertainty of the channel balances and is crucial for the improvement and different results in the next round which is why we explicitly explain how the knowledge is updated in several cases.\n\\begin{enumerate}\n\\item If an onion with the amount $h$ has not been returned, we assume it has arrived at the destination. Thus all channels across the path have now locked some liquidity into an HTLC.\\@ In our uncertainty network we thus reduce the capacity $u$ of each involved channel by the amount $h$ that was sent along that channel on that path. This changes our future success probabilities for the amount $a$ to be $P(X\\geq a+h|X\\geq h)$ which corresponds to a change from $\\frac{u+1-a}{u+1}$ to $\\frac{(u-h)+1-a}{(u-h)+1}$ in the uniform case. For any value of $a$ and positive $h$ the second fraction is smaller that the first one. This leads to lower probabilities which in turn yields higher costs to use those channels again in follow up rounds.\n\\item If an onion of size $h$ fails we learn the following new information:\n  \\begin{enumerate}\n  \\item On every channel up to the failed channel there has been sufficient liquidity to forward the amount $h$. In future rounds we can use the conditional probability $P(X\\geq a|X\\geq h)$. For $a<=h$ this term will be $1$, resulting in log costs of $0$. For $a>h$ the conditional probability is uniform again. It is important to notice that the conditional probability will again lead to a convex cost function.\n  \\item Assuming the failure code is related to liquidity issues for the failed channel we know that the amount $h$ was not available. Thus we are able to reduce the capacity to $h-1$ and change the probability for the future rounds from $\\frac{u+1-a}{u+1}$ to $\\frac{h-a}{h}$ in the uniform case, or $P(X\\geq a|X < h)$ in general. This probability decrease will result in higher costs for utilizing this channel.\n  \\item If on the other hand the failure code is related to an issue with the next hop, for example a downtime, the node can update its local view by temporarily removing the failed node with all its channels.\n  \\end{enumerate}\n\\end{enumerate}\n\nNote that both successful and failing onions would also allow us to update the knowledge about the balances in the reverse direction.\nOnce all the knowledge from the partial attempts of the round has been learned --- which is reflected by the update of the probabilities and cost functions --- the algorithm enters the next round.\nFirst, the sum of all failed onions is computed as the residual amount that still needs to be delivered.\nWe enter the next round with that amount on the updated uncertainty network by computing a new minimum cost flow to generate the next optimal MPP split.\n\n\\section{Example}\nLet us go through an example that illustrates why finding a min-cost flow is necessary instead of just adding optimal paths.\nIt also serves to better understand the round-based algorithm.\nIn order to simplify the example, we ignore fees and channel reserves and optimize purely for probability here.\nWe also hide the nonintuitive negative log probabilities by writing down the corresponding max-probable flow with probabilities as edge weights.\nFor the channel graph depicted in Figure~\\ref{fig:counterexample},\n\\begin{figure}[htpb]\n  \\center\n  \\includegraphics[width=0.45\\textwidth]{img/counterexample.png}\n  \\caption{Example Channel Graph on which the $2$-flow with maximal probability is not an extension of the $1$-flow from  $s$ to $d$ with maximal probability. The success probabilities for sending $i$ sat are depicted as $p_i$. The channels capacities are the bold numbers along the edges.}\n  \\label{fig:counterexample}\n\\end{figure}\nassuming uniform probability distributions we compute the following probabilities for the $1$-flows (paths delivering 1 sat):\n\\[\n\\begin{aligned}\np([s,A,B,d]) = & \\frac{2}{3}\\cdot\\frac{2}{3}\\cdot\\frac{4}{5}=\\frac{16}{45} &= 0.35\\overline{5} \\\\\np([s,X,Y,d]) = & \\frac{1}{2}\\cdot\\frac{7}{8}\\cdot\\frac{4}{5}=\\frac{28}{80} &= 0.35 \\\\\np([s,X,B,d]) = & \\frac{1}{2}\\cdot\\frac{9}{10}\\cdot\\frac{4}{5}=\\frac{36}{100} &= 0.36 \\\\\n\\end{aligned}\n\\]\n\nThis indicates that $s,X,B,d$ is the minimum cost $1$-flow.\nThe $(s,X)$ arc is obviously saturated so that a $2$-flow extending the $1$-flow would have to go via the $(s,A)$ arc.\nOne can easily compute the probability of the resulting $2$-flow $f^2$ if the next sat is also using the $(B,d)$ channel and being merged with the min-cost $1$-flow as\n\\[\np(f^2) = \\frac{1}{2}\\cdot \\frac{9}{10}\\cdot \\frac{2}{3}\\cdot \\frac{2}{3}\\cdot \\frac{3}{5} = \\frac{3}{25}=0.12\n\\]\n\nHowever if we look at the $2$-flow $g^2$ that sends $1$ sat along $s,A,B,d$ and $1$ along $s,X,Y,d$ we get $p(g^2)=\\frac{16}{45}\\cdot\\frac{28}{80} = 0.124\\overline{4}$\nwhich is also the min-cost $2$-flow in this graph.\nThis example shows that finding a min-cost flow cannot in general be done  by computing the most likely path for a single sat and extending it with the next most likely $1$-sat-paths.\\footnote{This simple $+1$-algorithm could actually be rescued so that it would be able to compute the min-cost flow. However both versions would also be quite slow as they would be linear in the amount that was to be sent --- which is exponential in the input size}\n\nExtending our example and assuming we want to send a total of 3 sat we start again by computing the min-cost flow $f^3$ which can be disected into two paths $l_1= s,X,Y,d$ with an amount of $1$ and another path $l_2=s,A,B,d$ with an amount of $2$.\nAfter sending out the onions we might have learned that the onion along $l_1$ has been successful, but the one with $2$ sat along $l_2$ has failed because $B$ did not have enough liquidity to forward the onion to $d$ on the $(B,d)$ channel.\nFor the second phase of the algorithm we now compute the min-cost flow on a graph where we know that we can deliver 2 sat with perfect certainty to $B$.\nThis updated uncertainty network is depicted in Figure~\\ref{fig:round2}\n\\begin{figure}[htpb]\n  \\center\n  \\includegraphics[width=0.45\\textwidth]{img/round2.png}\n\\caption{The uncertainty network of $s$ after HTLCs of value $1$ are locked in along the path $s,X,Y,d$ and a 2-sat onion along $s,A,B,d$ failed because of missing liquidity on the $B,d$ channel. Saturated edges are removed. The black labels on the edges depict the uncertainty range of the balance or a single number if the balance is known to $s$. The $p_i$ express the success probability for sending a further $i$ sat along an edge given the updated knowledge. }\n  \\label{fig:round2}\n\\end{figure}\n\nThe flow that sends the full residual amount of $2$ sat along $s,A,B,X,Y,d$ has a probability of $\\frac{8}{10}\\cdot\\frac{5}{7}\\cdot\\frac{1}{2}=0.286...$ while the flow that sends $1$ sat along the $B,d$ channel has a probability of $\\frac{1}{2}\\cdot\\frac{9}{10}\\cdot\\frac{6}{7}\\cdot\\frac{3}{4}=0.289...$ telling us that for the residual amount we should make another split payment sending one sat along each of the paths $q_1=s,A,B,d$ and $q_2=s,A,B,X,Y,d$.\n\nFinally, if the path $q_1$ locks in and $q_2$ returns an error at any of the channels $(B,X),(X,Y)$ or $(Y,d)$ we would know that we cannot deliver the full payment as the min-cut in the network on the balance graph had the value $2$.\nIf however $q_2$ and $q_1$ both lock in we have successfully delivered the payment.\nIf both $q_1$ and $q_2$ return an error we know the min-cut between $s$ and $d$ on the balance graph was $1$ (as that had been locked-in in the first round and no further HTLCs have locked in).\nFinally if $q_1$ returns an error and $q_2$ locks in we will have to enter the third round.\nIn the third round there is only 1 sat to be delivered on a single possible path $q_2$ which, given our knowledge, has a success probability of $\\frac{8}{9}\\cdot\\frac{5}{6}\\cdot\\frac{2}{3}=0.494\\ldots$\\footnote{the numerical similarity to the twitter account mentioned in the acknowledgements is completely coincidental as we used that graph even before we had the discussion with the individual.}.\n\n\\section{Anecdotal Lab Report}\n\\textbf{Disclaimer:} We stress that this document is a preprint. In particular this section cannot be considered a proper evaluation. For that we would also have to test the algorithms on the Lightning Network mainnet.\nIn addition to the fundamental complications arising through the base fee\\footnote{which should be easily avoidable at the moment by incorporating some buffer in the fee size, as long as it remains lightly used}, such a real-world test requires overcoming several engineering challenges that we did not have the time to address yet:\n\nA practical implementation needs to automatically answer questions that might arise in case of hanging HTLCs, if channels become inactive, or amounts reach HTLC limits of channels, for example.\nAlso the implementation of the min-cost flow solver would have to be engineered to have a much faster runtime than our experimental version so that it would actually be feasible to use it on the real Lightning Network.\nHowever we felt the need to share some preliminary research progress after some test results from our simulated setting indicated an improvement of reliability of several orders of magnitude over the currently reported statistics for payment delivery.\nIn particular, an anecdotal lab report --- while highly unusual --- seemed appropriate for this particular situation in order to inform the developer community as early as possible about the potential need for a protocol upgrade removing the base fee.\n\n\\subsection{Simulation}\nSince the computation with base fees is not feasible\\footnote{and the fees are also currently low enough to not impact the results too much}, we have ignored the base fees in all our computations.\nIn fact, we started experimenting by not even optimizing for low fees at all but just for high probabilities.\n\nWe took a recent snapshot from the channel graph of the Lightning Network that was observed via the gossip protocol on one of our long running mainnet nodes.\nWe then created a static balance graph instantiation of the simulated network by splitting the channel capacity into two balance values uniformly at random independently for each channel.\n\nWe created a Python-based min-cost solver following the algorithm described in~\\cite[p.~556ff]{ahuja1993network} and a Scala version later on that turned out to be faster by a factor of about $3$--$4$.\nWhile implementing this algorithm we made some mistakes early on that accidentally led to the discovery of a heuristic that, on our snapshot Lightning Network graph, reliably produced results with less than 1\\% deviation from the optimal cost in less than 1\\% of the runtime.\nBecause the exact algorithm takes more than 30 minutes even in the faster Scala implementation, the following results have been mostly obtained with this heuristic, which typically takes about 6 seconds to run in Scala. So it is notable that the optimal results would be even better, although negligibly so.\n\nWe picked a medium-sized Lightning node that got randomly assigned a local balance of $0.42$ BTC and tried to send $0.4$ BTC to another node $3$ hops distant using the round-based algorithm described in Section~\\ref{rounds}.\nThe remote node had a total capacity of roughly $1.5$ BTC and more than $0.4$ BTC inbound liquidity. \nAssuming no routing hints from the recipient we started the first round computing a flow that was disected into several hundred small paths.\nSending them out we where able to deliver almost $75\\%$ of the amount that we wanted to deliver at once.\nWe updated the graph with the insights from the successes and failures and started the second round for the residual amount of roughly $0.1$ BTC.\nIn this round the min-cost solver on the graph with less uncertainty suggested a split of about $100$ paths.\nAfter sending out the payments we observed that the residual amount was only about $0.009$ Bitcoin.\nIn the third round, again on the updated graph, the min-cost solver suggested to send about 15 concurrent payments, of which all but one where successful.\nWe entered the fourth and final round with an amount of $30,000$ sat ($0.0003$ BTC) remaining.\nOwing to the learned data, the heuristic of our min-cost solver sent the full amount on a single path with $8$ hops, because it had already gained enough certainty for all but one channel (of size 1 BTC) along that path that it could forward $30,000$ sat.\nThus with a $99.97\\%$ probability the $30,000$ sat path settled on the selected $8$ hops path and the payment was delivered in full.\nWhile sending out all the onions we tracked the total routing fees to be $814$ sat.\n\nWe also repeated the experiment with reduced initial uncertainty by assuming the recipient node had initially communicated to the sender on which channels it could receive what amounts in the invoice.\nIn this case and on the same graph the algorithm delivered the final payment in the third round already.\n\nWe repeated the experiment a couple of times with different amounts and different instantiations of the simulated balance graph, resulting in similar results with every run. We therefore believe it reasonable to expect that we would see very similar results on the actual Lightning Network even though the unknown balance graph of the mainnet is constantly changing (potentially making some of our learned knowledge invalid).\n\nWe also used the above combination of balance graph, source and destination node for some experiments with the Lagrangian relaxation. This time, we allowed multiple parallel channels between nodes, as they are actually observed in the Lightning Network. Also, instead of going through the rounds of the payment algorithm, we just looked at the results of a single min-cost flow calculation, with a payment amount of 9.2 million sat (0.092 BTC). In this setting\\footnote{without using any knowledge about the source's or the destinations' channels}, optimizing for reliability only ($\\mu=0$) yields a probability of $P=0.16$, with total fees of 697 sat (excluding base fees). On the other hand, choosing $\\mu=100$ means optimizing almost exclusively for fees. This brings the total fees down to $16$ sat, but, as expected from the arguments in Section~\\ref{fees}, the success probability drops to $P=1.1\\cdot10^{-11}$. Table~1 shows that when we lower $\\mu$ through multiple orders of magnitude, the success probability increases drastically, while the fees are only rising moderately. Unfortunately, we increasingly observed numerical instabilities while decreasing $\\mu$. This lead to our algorithm not terminating beyond $\\mu=0.01$.\n\n\\begin{table}\n\\begin{center}\n\\begin{tabular}[h]{l|l|r}\n  $\\mu$ & P & fee(sat) \\\\\n  \\hline\n  100  & $1.1\\cdot10^{-11}$ & 16 \\\\\n  10 & $2.3\\cdot 10^{-5}$ & 16 \\\\\n  1 & $0.0097$ & 18 \\\\\n  0.1 &  0.044 & 24 \\\\\n  0.01 & 0.056 & 28 \\\\\n  0  & 0.16 & 697\n\\end{tabular}\n\\caption{Results of varying $\\mu$ on a fixed payment pair}\n\\end{center}\n\\label{table:mu}\n\\end{table}\n\nAgain, all numbers are from the heuristic, but the exact algorithm performed nearly identically in all our samples, including the numerical instabilities.\n\n\\subsection{Source code}\nWe could not find any preexisting open source software implementing the solution of the integer minimum cost flow problem for arbitrary separable convex cost functions.\nWe therefore share the source code of the described algorithms and methods as well as the latex sources of this document with an open MIT license at: \\url{https://github.com/renepickhardt/mpp-splitter}.\nThis repository consists of Scala- and Python-based example implementations of the exact min-cost flow algorithm described in~\\cite[p.~556ff]{ahuja1993network} for a separable convex cost function.\nIt also includes a minimalistic simulation framework in Python to test the practicality of the round-based payment loop.\nThe Scala version includes example code to demonstrate the usage of the Lagrangian relaxation.\n\n\\section{Advanced Applications}\n\n\\subsection{Multiple Senders and/or Receivers}\n\nNotice that our definition of a flow in Section~\\ref{flows} allows for an arbitrary number of both sources and sinks, that is, nodes with non-zero excess. This means that while a min-cost flow calculation might be computationally expensive, it can result in an optimized flow for multiple payments and/or channel balancing efforts at the same time. With respect to the runtime of the algorithm we have implemented\\footnote{which relies on single source shortest path calculations}, a more complex flow will take longer to optimize in practice, even though it will still respect the same worst-case runtime bounds.\nWe expect that entities like Lightning Service Providers (LSP) or trampoline routers, who need to find paths for many payments, will find this aspect helpful.\nOne could imagine a permanently running min-cost flow calculation loop that keeps learning about the network and sending out remainder amounts as in Section~\\ref{rounds}, but can always add additional payments in the next round.\nIt bears mentioning that in such multi-purpose rounds, the minimum cost is always optimized globally, which could lead to some payments being cheaper at the expense of others.\nThis needs to be accounted for when, e.g., routing payments for multiple clients.\n\n\\subsection{Optimal Channel Rebalancing}\n\\label{rebalancing}\nIt is well-known in the community that routing nodes can contribute to the overall payment reliability in the Lightning Network by using various channel rebalancing techniques. A recent survey paper~\\cite{papadis2020blockchain} in particular describes channel rebalancing via off-chain circular onions. This can happen proactively or lazily at routing time via a technique called just in time routing (JIT-routing)\\cite{Pickhardt2019}. To our knowledge, rebalancing has so far only been considered one channel pair at a time.\nWe observe that a node $i$ might want to rebalance several channels at once by shifting excess balance from source channels to target channels where more liquidity would be demanded.\nIn the uncertainty network, we can then assign the supply for rebalancing to the channel partner nodes of the corresponding outbound supply channels and remove these edges from the graph.\nBecause we have to account for the fees on inbound channels, the construction is a little more involved for the channels that demand extra balance: For every incoming edge $(j,i)$ that demands a balance increase, we create a copy $(j,k)$\n(with the same capacity and cost function) leading to a new node $k$ that is assigned the demand.\nFinally, we can compute a multi-source-multi-sink min-cost flow in order to shift the liquidity and conduct a multi-channel rebalancing.\nAs rebalancing is rarely time critical, one might prefer a high value of $\\mu$ in the min-cost flow computation that favors low fees over a high success rate.\nA node might even decide to stop the rebalancing operation before all of the onions have been successfully delivered: it has just engaged into a cheap opportunity for rebalancing; if delivering the remaining amounts turns out to be too expensive in the next min-cost flow calculation, it might prefer to stay with this improved but not perfect balance according to its own rebalancing strategy.\n\nAt first sight, rebalancing seems most interesting for nodes that engage more in routing than sending or receiving payments.\nHowever, we want to stress that for LSPs who conduct several payments per second, it might be very reasonable to combine the rebalancing and payment aspect, and suggest two ideas.\nFirst, we recall the global uncertainty of a node is always decreasing while delivering payments, so learning this knowledge could help find opportunities for engaging in rebalancing operations.\nSecond, an LSP might aim to keep its channels balanced according to a certain strategy.\nInstead of allowing itself to use all channels for making a payment, an LSP could restrict itself only to the channels where it has too much liquidity and exclude other channels from the computation.\nThis min-cost flow might be more expensive and less likely, but it might increase the chances for the node to forward payments; potentially earning a fee and increasing its overall reliability for other nodes might make such a trade-off worthwhile.\n\n\\section{Limitations}\n\n\\begin{enumerate}\n\\item As discussed in Section~\\ref{fees}, the currently adopted base fees in the Lightning Network make computing a min-cost flow NP-hard whenever the cost function includes these fees. Thus we have inquired about the motivation for the inclusion of a base fee online and received a response from the developer who appears to be responsible for this decision.\\footnote{Rusty Russell's answer to the question: Why was the base\\_fee for the routing fee calculation of the Lightning Network included? \\url{https://bitcoin.stackexchange.com/a/107341/81940}}\nWe are under the impression that the base fee was a rather ad-hoc and arbitrary choice and is not of significant importance to the Lightning Network protocol.\nEven if it were too difficult to change the protocol we see clear incentives for node operators setting the base fee to zero:\nNodes who want to conduct path finding might ignore base fees in their path computation in the future and thus ignore channels with a non-zero base fee.\nFurthermore, we note that our approach favors channels with large capacity, whose operators might therefore be able to demand higher fees.\nWe conjecture that this will give rise to a more balanced fee market, which should be in the interest particularly of node operators who have invested significant liquidity.\n\\item We made the crucial assumption that channel balances are uniformly distributed. While this was confirmed by prior research~\\cite{pickhardt2021security}, the situation could evolve over time, making our priors less suitable.\nIf, say, we assumed a normal distribution, the negative log probabilities would not be convex on the entire domain and the min-cost flow problem might not be solvable in polynomial time.\nHowever, we note for future research that there are practical solutions\nfor this, like limiting the domain by limiting the allowed channel capacity. Moreover, in~\\cite{pickhardt2021security} it has also been shown in the single path case that adopting a rebalancing protocol which changed the prior to a normal distribution but computing paths with a uniform prior still performed well.\nIn fact, we conjecture that we cannot do better than assume uniformity unless we have knowledge of the parameters of the actual distribution.\n\\item While the min-cost flow problem admits a polynomial time solution in the case of a convex cost function (without base fees), it is still computationally intensive, with a runtime that is quadratic in the number of channels. Remember also that we might have to solve several of these problems per payment round in order to find a suitable Lagrange multiplier in the trade-off between reliability and fees.\nOur prototype implementation is currently not optimized for speed; on the full Lightning Network graph, running times can easily reach 30 minutes and more, depending on the degree of precision. However, we have achieved preliminary experimental results on a promising heuristic that seems to very favorably trade reductions in runtime for only a slight deterioration from the optimal solution of the minimum cost flows.\nUsing heuristics like this, algorithmic methods including approximation and parallelization, as well as optimized code, we estimate that on the currently public Lightning Network it should be feasible to achieve sub-second runtimes on commodity hardware.\nHowever, we feel that this research is still too early for publication.\n\\end{enumerate}\n\n\\section{Future work}\nBeyond the optimization steps required for practical usability and extensive tests on the actual Lightning Network that we have\nhinted at above, we see some additional directions for further research:\n\n\\begin{enumerate}\n\\item Recall from Section~\\ref{fees} that when optimizing for both fees and reliability one has to find a suitable value for $\\mu$. We hope that improving on the current Lightning Network user experience will be possible with some experimentation, user interface design, and drawing from the extensive literature on Lagrangian relaxation.\n\n\\item In the round-based payment algorithm described in \\ref{rounds}, the optimal delay spent waiting for further responses after the first failed onion has returned and before entering the next round with updated knowledge remains an open question. In our experiments and simulation we have assumed waiting for the status of all onions to be resolved. We defer investigation of this question to practical experimentation but point out that it does not appear too critical since we can always incorporate information that arrives too late for one round in any later ones. In the extreme case, for every returned onion a new round could be entered.\n\n\\item It is conceptionally straight forward to extend the probabilities with provenance scores from operating nodes on the Lightning Network.\nInstead of just looking at the channel balance distribution one could create a joint distribution from, e.g., estimating the nodes' uptime.\n\n\\item Large channels could become the equivalent to the autobahn and attract a lot of traffic. Given the limitations of concurrent payments on the Lightning Network, the need for congestion control mechanisms might arise.\n\n\\item The payment planning and execution algorithm accumulates knowledge about the actual channel success probability distributions. However, we know that in practice those distributions do not stay constant. In fact, they change with every payment that is conducted through a particular channel or via the rebalancing behavior of node operators.\nFurther research into the dynamics of the money flow through the Lightning Network will help estimate how long to rely on the knowledge gained from previous payment attempts. This knowledge can then be adequately discounted or forgotten in future rounds.\n\n\\item The promising idea of adding redundant liquidity during the path finding phase of MPP splits was introduced by~\\cite{DBLP:journals/corr/abs-1910-01834}. It would be very interesting to study if we could find optimal redundant overpayments so that we can expect to finish within one round of sending out multi-part payments with high probability.\n\n\\item  In spite of the arguments given in Section~\\ref{generalized} that led to prioritizing other aspects first, we still believe generalized flows to be an interesting future research direction, especially in light of multiple-source-multiple-sink applications (cf. Section~\\ref{rebalancing}). In this setting, constructions like the self-loop we described might allow for more flexibility: One can specify some sources and destinations with exact excess requirements as well as leave others open in order to give the optimization more leeway.\n\n\\end{enumerate}\n\n\\section{Acknowledgements}\nThis research was partially sponsored by the Norwegian University of Science and Technology (NTNU).\nWe want to thank David Karger and MIT open courseware for sharing a lecture series about min-cost flows\\footnote{\\url{https://www.youtube.com/playlist?list=PLaRKlIqjjguDXlnJWG2T7U52iHZl8Edrc}} that has been very useful for us in creating our reference implementation and understanding the theory of min-cost flows.\nWe are grateful to Ravindra Ahuja, Thomas Magnanti and James Orlin for their exceptional textbook~\\cite{ahuja1993network} which contains so much of the knowledge we have been adapting to our use case here.\nWe also thank Twitter user \\texttt{@four9four} for discussing our preliminary results after the Lightning hacksprint in April 2021.\nThanks to GB for polishing the graphics.\nWe thank Rene's co-authors Andreas M. Antonopoulos and Olaoluwa Osuntokun for accepting Rene's decision to temporarily prioritize this research over their Lightning Network book project.\nFinally our gratitude goes to Christian Decker with whom we had several discussions and who provided valuable feedback along the course of this research.\nIf you like the idea of decentralized and independent research and development of the Lightning Network feel free to support future work by contributing via \\url{https://donate.ln.rene-pickhardt.de}.\n\n\\begin{appendix}\n  \\section{Twitter-based TL;DR}\n  While putting all together we actually shared the method and results in 6 Tweets:\n  \\\\\\\\\n\n    \\textbf{March 17th 2021}\\footnote{\\url{https://twitter.com/renepickhardt/status/1372169686251626499}} \\\\\n    Over the last year I have been making quite some discoveries about  \\#bitcoin Payment Pathfinding on the \\#LightningNetwork .\\\\A paper which introduces a probabilistic approach of modeling the uncertainty of remote channel balances is out and discussed on \\url{https://lists.linuxfoundation.org/pipermail/lightning-dev/2021-March/002984.html}\\\\\\\\\n  \n  \\textbf{April 22nd 2021}\\footnote{\\url{https://twitter.com/renepickhardt/status/1385144337907044352}} \\\\\n  Multipathfinding \n\\begin{enumerate}\n\\item capacities are integers (Satoshis)\n\\item channel success probabilities -log(1-x/c) are convex functions\n\\item Solving integer minimum cost flows with separable convex cost objective polynomially: \\url{https://link.springer.com/chapter/10.1007\\%2FBFb0121104}\n\\end{enumerate}\n  Kudos @stefanwouldgo 4 digging this out\n\\\\\\\\\n  \n  \\textbf{May 26th 2021}\\footnote{\\url{https://twitter.com/renepickhardt/status/1397559345139888137}}\\\\\n  most likely MPP-split to deliver 92 mBTC from my lightning node (03efc...) to (022c6...).\n  We split into 11 onions!\n\\begin{figure}[htpb]\n  \\center\n  \\includegraphics[width=0.45\\textwidth]{img/optflow.jpeg}\n  \\label{fig:optflow}\n\\end{figure}\\\\\nWith knowledge of my own balance \\& routing hints in the invoice the total likelihood to deliver all 11 onions is $64.84\\%$\nNote the 6 hop path with 4 WUMBO channels!\n\\\\\\\\\n\n\\textbf{June 6th 2021}\\footnote{\\url{https://twitter.com/renepickhardt/status/1401514950984712198}}\\\\\nCouldn't go to Miami so I coded up my algorithm!\\\\\\\\\nIn a simulated network with realistic balance values a node having 0.42 BTC could send 0.4 BTC to a remote node (that could receive up to 1.59 BTC) with no direct channel\\\\\\\\\nIt took just 4 attempts to deliver and 814 sat in fees\\\\\\\\\n\n\\textbf{June 8th 2021}\\footnote{\\url{https://twitter.com/renepickhardt/status/1402264479677693958}}\\\\\non other good news:\n\\begin{enumerate}\n\\item this yields another test vector for unit tests\n\\item the previous / non optimal algorithm might for other reasons (that go beyond a tweet) actually be better suitable for the lightning network after all\n\\item either way the issue seems fixable (:\n\\end{enumerate}\n\n  \\textbf{July 5th 2021}\\footnote{\\url{https://twitter.com/stefanwouldgo/status/1412158904008646660}}\\\\\n  Lightning Routing IS NP hard, though.\n\n  It's funny 'cause it's true.\n\n\\end{appendix}\n\n\\end{document}\n</paper 3>\n\nYour summary should follow these steps:\n- Title: Clearly state the main subject or topic of the summary.\n- Introduction: Describe the field and briefly introduce its history. Then introduce current progress and challenges.\n- Introduce the main content of each paper separately. Then summarize their commonalities and innovations.\n- Compare the results of the papers and discuss difference of the results.\n- Conclusion: Summarize the main findings and suggest future research directions.\n\n<keys>\nThe following are the key points to note:\n- If there are important data or mian equation in the given papers, remember to mention them in your summary using Markdown.\n- Use of tables to clearly compare different approaches is encouraged.\n- The first appearance of a professional term must be marked with the full English name and abbreviation.\n- Don't directly copy the papers, write the summary in your own words.\n- Do not include the titles of reference papers directly in your paper.\n</keys>\n\nTotal word count should be about 4000 words.",
    "paper": [
        "arXiv-1709.05748v2.tex",
        "arXiv-1909.06890v1.tex",
        "arXiv-2107.05322v1.tex"
    ],
    "group_id": "group_12",
    "response": "### Title: Efficient Decentralized Routing for Path-Based Transactions and DoS Attacks on Off-Chain Networks\n\n### Introduction\nDecentralized path-based transaction (PBT) networks, such as Bitcoin's Lightning Network and Ethereum's Raiden Network, have emerged as a promising solution to overcome the scalability and privacy challenges of traditional blockchain-based payment systems. These networks enable real-time gross settlements and smart contract execution by leveraging local payment channels between participants, allowing for off-chain transactions that are faster and more cost-effective than on-chain blockchain operations. However, the design and implementation of routing algorithms within these networks are critical for ensuring their effectiveness, efficiency, and privacy. This summary explores three research papers that delve into the intricacies of routing algorithms in PBT networks, each addressing different aspects of the problem, including efficiency, privacy, and security against Denial-of-Service (DoS) attacks.\n\nThe history of PBT networks is rooted in the early days of blockchain technology, where the need for scalable and private payment systems was recognized. Traditional blockchain networks, such as Bitcoin and Ethereum, face significant scalability issues due to the high transaction fees and long confirmation times required for on-chain operations. In response, PBT networks were developed to facilitate off-chain transactions, thereby reducing the load on the blockchain and enhancing transaction speed and privacy. However, the design of routing algorithms for these networks remains a challenging task, as existing solutions often lack either efficiency or privacy, or both.\n\nCurrent progress in PBT networks has seen the deployment of several routing algorithms, including landmark routing and embedding-based routing. However, these algorithms face challenges in terms of efficiency, privacy, and the ability to handle network dynamics. The first paper introduces SpeedyMurmurs, a novel routing algorithm that combines the concepts of VOUTE and credit networks to achieve efficiency, privacy, and robustness against network dynamics. The second paper identifies and analyzes a novel DoS attack based on route hijacking, highlighting the importance of secure routing mechanisms. The third paper presents a round-based algorithm for delivering payments that optimizes for both success probabilities and fees, using a probabilistic approach to handle uncertain balance values in payment channels.\n\n### Main Content of Each Paper\n\n#### Paper 1: Settling Payments Fast and Private: Efficient Decentralized Routing for Path-Based Transactions\nThis paper introduces SpeedyMurmurs, a routing algorithm designed for decentralized PBT networks. The algorithm aims to address the shortcomings of existing routing methods, such as landmark routing and Flare, by providing a balance between efficiency, effectiveness, and privacy. SpeedyMurmurs leverages embedding-based routing and on-demand stabilization to handle network dynamics efficiently. The authors also propose a two-phase construction algorithm to accommodate unidirectional links, which are common in PBT networks but not in traditional embedding-based routing algorithms.\n\nThe routing process in SpeedyMurmurs involves three main steps: generating anonymous return addresses for the receiver, splitting the transaction value randomly among multiple paths, and using VOUTE's routing algorithm to find paths that can transmit the required funds. The algorithm ensures that nodes can proactively allocate funds for transactions, reducing the likelihood of failures due to insufficient liquidity. Additionally, SpeedyMurmurs maintains privacy by concealing the transaction value and the identities of the sender and receiver from adversaries.\n\nThe authors evaluate SpeedyMurmurs using real-world data from the Ripple credit network, demonstrating its superior performance in terms of success ratio, delay, and overhead compared to landmark routing. SpeedyMurmurs reduces the overhead of stabilization by up to two orders of magnitude and the overhead of routing a transaction by more than a factor of two. The simulation results indicate that SpeedyMurmurs performs transactions at about twice the speed of landmark routing, while maintaining a similar or higher success ratio.\n\n#### Paper 2: A DoS Attack on Off-Chain Networks and a Design Tradeoff\nThis paper focuses on the security vulnerabilities of off-chain networks, specifically identifying a novel DoS attack based on route hijacking. The attack exploits the routing mechanisms in PBT networks by creating new channels with low fees and delays, thereby attracting a large portion of the network's traffic. The authors analyze the feasibility of this attack using empirical data from the Lightning Network and explore the tradeoffs between minimizing fees and maximizing success probabilities.\n\nThe paper highlights that the current routing algorithms in the Lightning Network implementations (lnd, C-lightning, and Eclair) differ in their objectives and strategies. For instance, lnd prioritizes the shortest path with the lowest fees, while Eclair randomizes between the top three routes. The authors argue that these differences can be exploited by attackers to launch DoS attacks, as they can create new channels that are more attractive to the routing algorithms. The paper also discusses the impact of the base fee and proportional fee on the routing decisions and suggests a modified weight function that balances the tradeoff between reliability and cost.\n\nThe empirical analysis reveals that a small number of highly central nodes can disrupt a significant portion of the network's transactions. For example, five highly central nodes can hijack roughly 60% of all transactions, and an external attacker can hijack about 65% to 75% of the traffic by creating just five new channels. The authors propose a game-theoretic model to understand the interaction between attackers and defenders and suggest strategies for both sides to optimally invest their resources.\n\n#### Paper 3: Optimally Reliable & Cheap Payment Flows on the Lightning Network\nThis paper presents a round-based algorithm for delivering payments on the Lightning Network that optimizes for both success probabilities and fees. The authors introduce a probabilistic approach to handle the uncertainty of channel balance values, which is a critical issue in PBT networks. The algorithm uses minimum cost flows to find the most likely multi-part payment (MPP) splits, considering the negative logarithms of channel success probabilities as the cost function.\n\nThe paper discusses the NP-hardness of finding optimal MPP splits when the cost function includes base fees. To address this, the authors propose dropping the base fee to make the problem solvable in polynomial time. They also introduce a Lagrangian relaxation method to balance the tradeoff between minimizing fees and maximizing success probabilities. The algorithm iterates over rounds, updating the uncertainty network based on the outcomes of previous attempts, and recomputing the minimum cost flow for the residual amount.\n\nThe authors present preliminary results from simulations, indicating that their algorithm can deliver payments with a high probability of success, even for large amounts. For example, a node with 0.42 BTC could send 0.4 BTC to a remote node with no direct channel, using just four attempts and incurring only 814 satoshis in fees. The paper also explores advanced applications, such as multi-source multi-sink min-cost flows for channel rebalancing and the potential need for congestion control mechanisms in large channels.\n\n### Commonalities and Innovations\nAll three papers focus on the design and optimization of routing algorithms for PBT networks, addressing the critical issues of efficiency, privacy, and security. They all utilize graph theory and network flow algorithms to model the network and find optimal paths for transactions. However, each paper introduces unique innovations and perspectives:\n\n- **Paper 1** emphasizes the importance of privacy and efficiency in routing algorithms, proposing a two-phase construction algorithm and on-demand stabilization to handle network dynamics. It also introduces a novel approach to splitting transaction values before routing, which allows for more flexible path selection.\n- **Paper 2** identifies a novel DoS attack based on route hijacking and analyzes its feasibility using empirical data from the Lightning Network. It highlights the tradeoffs between minimizing fees and maximizing success probabilities and suggests strategies for both attackers and defenders.\n- **Paper 3** presents a round-based algorithm for delivering payments that optimizes for both success probabilities and fees, using a probabilistic approach to handle uncertain balance values. It also explores the NP-hardness of the problem and suggests dropping the base fee to make it solvable in polynomial time.\n\n### Comparison of Results and Discussion\nThe results of the three papers are complementary, each addressing different aspects of the routing problem in PBT networks. SpeedyMurmurs, as proposed in Paper 1, achieves higher success ratios and lower delays compared to landmark routing, while maintaining privacy. Paper 2 demonstrates the vulnerability of the Lightning Network to DoS attacks based on route hijacking, highlighting the need for robust routing algorithms that can handle such attacks. Paper 3 presents a round-based algorithm that optimizes for both success probabilities and fees, achieving high reliability with minimal fees.\n\nThe main difference in the results is the focus of each paper. Paper 1 focuses on the efficiency and privacy of routing, while Paper 2 emphasizes the security and robustness of routing algorithms against DoS attacks. Paper 3 combines both aspects, proposing an algorithm that optimizes for both reliability and cost. The empirical results from Paper 2 suggest that the current routing algorithms in the Lightning Network are vulnerable to route hijacking attacks, which could be mitigated by the probabilistic approach and Lagrangian relaxation method proposed in Paper 3.\n\n### Conclusion\nThe three papers collectively provide a comprehensive view of the challenges and potential solutions for routing algorithms in PBT networks. SpeedyMurmurs offers an efficient and privacy-preserving routing algorithm, while Paper 2 highlights the security vulnerabilities of existing routing algorithms. Paper 3 presents a round-based algorithm that optimizes for both reliability and cost, using a probabilistic approach to handle uncertain balance values.\n\nThe main findings from these papers include:\n- **Efficiency and Privacy**: SpeedyMurmurs achieves higher success ratios and lower delays compared to landmark routing, while maintaining privacy.\n- **Security Vulnerabilities**: The Lightning Network is vulnerable to DoS attacks based on route hijacking, which can be mitigated by robust routing algorithms.\n- **Optimal Routing**: A round-based algorithm that optimizes for both success probabilities and fees can deliver payments with high reliability and minimal fees.\n\nFuture research directions could include:\n- **Enhancing Robustness**: Developing more robust routing algorithms that can handle both efficiency and security concerns.\n- **Dynamic Network Analysis**: Continuously analyzing and adapting to the evolving network topology to improve routing performance.\n- **Mechanism Design**: Designing mechanisms to incentivize nodes to choose secure and reliable paths, balancing the tradeoff between fees and success probabilities.\n- **Congestion Control**: Implementing congestion control mechanisms to manage the flow of payments and prevent network saturation.\n\nBy addressing these challenges, PBT networks can become more reliable, efficient, and secure, paving the way for broader adoption and integration into existing financial systems."
}