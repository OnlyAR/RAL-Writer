{
    "instruction": "You are an experienced researcher, I will give you some scientific research papers in the same field. Please read them carefully and write a summary about them.\n\nHere are the papers:\n\n<paper 1>\n\\title{Implications of Topological Imbalance for Representation Learning on Biomedical Knowledge Graphs}\n\n\\begin{document}\n\n\\maketitle\n\n\\begin{abstract}\n\n    Adoption of recently developed methods from machine learning has given rise to creation of drug-discovery knowledge graphs (KG) that utilize the interconnected nature of the domain. Graph-based modelling of the data, combined with KG embedding (KGE) methods, are promising as they provide a more intuitive representation and are suitable for inference tasks such as predicting missing links. One common application is to produce ranked lists of genes for a given disease, where the rank is based on the perceived likelihood of association between the gene and the disease. It is thus critical that these predictions are not only pertinent but also biologically meaningful. However, KGs can be biased either directly due to the underlying data sources that are integrated or due to modeling choices in the construction of the graph, one consequence of which is that certain entities can get topologically overrepresented. We demonstrate the effect of these inherent structural imbalances, resulting in densely-connected entities being highly ranked no matter the context. We provide support for this observation across different datasets, models as well as predictive tasks. Further, we present various graph perturbation experiments which yield more support to the observation that KGE models can be more influenced by the frequency of entities rather than any biological information encoded within the relations. Our results highlight the importance of data modeling choices, and emphasizes the need for practitioners to be mindful of these issues when interpreting model outputs and during KG composition.\n\n\\end{abstract}\n\n\\section{Introduction}\\label{sec:intro}\n\nDrug discovery and development is a highly complex, lengthy and multi-disciplinary endeavour~\\cite{cook2014lessons}, associated with high costs and attrition, particularly due to efficacy failure~\\cite{morgan2018impact} which is in turn underpinned by the hypothesis of which drug target(s) is thought to play a key role in a given disease. It is a process entailing many different critical decision points, for example which protein target(s) to focus on, what type of pharmacological agent to use to modulate a target, and which molecule to take into clinical trials. The biomedical domain is characterised by a high rate of technological evolution~\\cite{goodwin2016coming, ran2013genome}, multitudes of low and high dimensional data types~\\cite{ebrahim2016multi, hasin2017multi}, and a high volume and rate of semi-/unstructured information emerging constantly via scientific literature, conferences and patents.\n\nThese characteristics of the domain have led to exploration of Knowledge Graphs (KG) to improve representation of information, as well as delivery of predictions and hypotheses to improve the quality of the decisions made~\\cite{bonner2021review, gaudelet2020utilising}. In a drug discovery KG, nodes often represent entities such as genes, diseases or drugs, whilst the relations between them capture their interactions with each other. Graph representation of these relationships not only allows for a more intuitive navigation of the complex domain for exploratory tasks, but is also particularly suitable for inferential analysis as Knowledge Graph Embedding (KGE) models can be used to derive meaningful, lower-dimensional representations of these biological entities and relationships. These representations in the embedding space can then be used for predicting missing links between these entities. In the case of target prediction, such approaches would produce a ranked list of genes, ordered by the score from the embedding model, predicted to be associated with a given disease. The top k elements from this list would then be inspected via subject matter experts (SME) to be triaged and further refined into a smaller list for a more manageable target validation process~\\cite{paliwal2020preclinical}. For example, performing drug target identification has been addressed as link prediction between gene and disease entities using the ComplEx model~\\cite{trouillon2016complex} on a drug discovery graph~\\cite{paliwal2020preclinical}.\n\nIn the drug discovery domain, working with KGs has the promise of countering cognitive biases by leveraging massive amounts of information, well-beyond what is humanly feasible to comprehend, to inform a given hypothesis or decision through a computationally sound process that is agnostic to \\emph{a priori} experience. Challenges remain however, e.g.\\ dealing effectively with the structural biases in the information sources~\\cite{nguyen2017pharos} and the relative lack of negative data for validation in particular. To the best of our knowledge, the precise effect of the structural imbalance inherent in biomedical KGs, on predictive tasks using KGE models has not been explored thoroughly in the literature.\n\nIn this study, we aim to fill in this gap by providing a comprehensive analysis of how structural imbalance in the underlying data in a KG affects the scores for predicted relationships. We demonstrate that the KGE methods tend to overrate the highly-connected entities, and that this result is reproducible in different datasets (i.e. graphs), for different embedding models, across different diseases and different predictive tasks. We go on to study the extent of this imbalance by further investigating the type of relationships the entities have, by introducing various types of perturbations to the graph to assess the stability of the rankings, as well as presenting a thorough case study in target discovery task set on the unperturbed graph. Seen altogether, our results would indicate that the total volume of connections an entity has within the graph seemingly matters more than any biological information encoded within. We thus highlight the need for careful consideration of graph composition in relation to the analytical methods employed for a given task.\n\nExample code for the experiments presented in thus study is available online.\\footnote{\\url{https://github.com/AstraZeneca/biomedical-kg-topological-imbalance}} Results are presented on only publicly available datasets.\\section{Background \\& Related Work}\\label{sec:litreview}\n\n\\subsection{Background}\\label{ssec:background}\n\n\\textbf{Knowledge Graphs.} A knowledge graph is a way to capture and represent, often widely scoped, knowledge within a domain, based on graph theory principles. Semantically, a KG is a heterogeneous, multi-relation and directed graph, connecting a set of entities \\(\\mathcal{E}\\) to each other by a set of relationships \\(\\mathcal{R}\\), defined as \\(\\mathcal{K} \\subseteq \\mathcal{E} \\times \\mathcal{R} \\times \\mathcal{E}\\) \\cite{zhang2019heterogeneous}. KGs are often considered as a series of triples \\((h,r,t) \\in \\mathcal{K}\\), where \\( h,t \\in \\mathcal{E}\\) are the head and tail entities connected via the relationship \\( r \\in \\mathcal{R}\\). A hypothetical triple from a drug discovery KG could be \\(( \\mathit{Gene}_i, \\mathit{associates}, \\mathit{Disease}_j) \\), where the entities \\(\\mathit{Gene}_i\\) and \\(\\mathit{Disease}_j\\) are connected via the relationship \\(\\mathit{associates}\\). Given that a KG is still a graph, its topological structure can be measured using a well studied range of techniques~\\cite{newman2018networks}. A common measure to consider at the level of individual entities is that of \\emph{degree}, which is the number of relationships of any type a given entity has to all others (possibly including itself) within the graph.\n\nIn many real-world KGs, the set of triples can be noisy and incomplete~\\cite{ali2020bringing}. Thus numerous techniques attempt to impute missing information based on the existing data in \\(\\mathcal{K}\\) through multi-relation link prediction~\\cite{ruffinelli2019you}. Such techniques consider the partial triple \\(( \\mathit{Gene}_i, \\mathit{associates}, ?) \\) and attempt to predict the correct tail entity, i.e. try to answer the question \\emph{`with which disease(s) is \\(\\mathit{Gene_i}\\) associated?'} or be given \\(( ?, \\mathit{associates}, \\mathit{Disease}_j) \\) and attempt to predict the correct head entity, i.e. \\emph{`which gene(s) are associated with \\(\\mathit{Disease_j}\\)?'}\n\n\\textbf{Knowledge Graph Embeddings.} In this work we consider KG embedding models~\\cite{ji2020survey, wang2017knowledge}, which aim to learn low-dimensional representations of all entities and relations. These embeddings are combined in various ways to produce a score of how likely a given triple is to be true, with a larger score typically implying a more plausible triple~\\cite{ali2020bringing}. More concretely, a model \\(f : \\mathcal{E} \\times \\mathcal{R} \\times \\mathcal{E} \\rightarrow \\mathbb{R} \\), calculates a scalar value \\(s_{(h,r,t)}\\) representing the plausibility for each potential triple \\((h,r,t) \\in \\mathcal{K}\\). For KGE approaches, \\(f\\) is a learned model which operates only with the embeddings of the elements in the triples, \\(f( \\mathbf{h}, \\mathbf{r} , \\mathbf{t} )\\), where \\(\\mathbf{h}, \\mathbf{t} \\in \\mathbb{R}^m \\) and \\(\\mathbf{r} \\in \\mathbb{R}^n \\). The values of \\(m\\) and \\(n\\) represent the dimension of the entity and relation embedding respectively. It should be noted that the values of the scaler scores \\(s_{(h,r,t)}\\) are not directly meaningful by themselves and are generally used to rank true triples above a sampled set of negative ones. Furthermore, the scale of score values varies according to the function used by the particular KGE model~\\cite{ali2020bringing}, meaning comparing scores from different models side by side is meaningless.\n\nGiven a trained KGE model, it is possible to pass it an incomplete triple \\((h,r,?)\\) as described earlier and it will predict which entity is most likely to complete it. In practice, this is achieved by enumerating over all entities in the graph and the model scoring the triple with each entity taking the place of the missing element: \\( \\mathcal{S} = \\{f(h,r,t^\\prime) \\mid t^\\prime \\in \\mathcal{E} \\} \\). This list of scores \\(\\mathcal{S}\\) is then sorted and a user can interpret it as a ranked list from most to least likely. Many of the common metrics, such as Hits@k or Mean Reciprocal Rank (MRR) for assessing the predictive performance of KGE models are based on this ranked output, with the hope that the model ranks true, but previously unknown triples, above meaningless ones~\\cite{ali2020bringing}.\n\nOne of the most attractive properties of KGE methods is that it is possible to query the same trained model for link prediction tasks no matter the exact context as the model is trained to reconstruct the entire graph, agnostic of a particular type of inference. In other words, it is possible to reuse the same model across different tasks, whether predicting the most likely genes to associate with a given disease, or the most likely drugs to interact with a given gene.\n\n\\textbf{Drug Discovery and Knowledge Graphs.} Drug discovery is driven by the need to improve the standard of care for a particular disease, either by providing a more efficacious treatment or one that has fewer, less severe side effects. A crucial step early in the process is target discovery, that is to correctly identify molecular entities that are associated with the disease or symptom in question, for which a drug can be designed and developed. These entities can be genes, proteins or metabolites, which play an important role in disease causation or progression and alternatively play an important role in managing the symptoms of the disease (e.g. while steroid nose sprays like mometasone do not affect the direct cause of allergy, they help alleviate symptoms like running nose). With the cost of drug discovery estimated at hundreds of millions of dollars~\\cite{wouters2020drugdisco}, it is crucial to find the right target~\\cite{morgan2018impact}.\n\nOne use case for KG predictions is for them to be integrated into a complex drug discovery pipeline leading to resource intensive experiments being performed to validate the predictions~\\cite{paliwal2020preclinical}. In the case of target prediction, such approaches would produce a ranked list of genes, ordered by the score from the model, predicted to be associated with a given disease. The top k elements from this list would then be inspected via subject matter experts (SME) to be triaged and further refined into a smaller list for a more manageable target validation process. In one study, the top 600 genes predicted to be associated with rheumatoid arthritis were reduced down to 55 by SMEs to be taken forward for experimental validation~\\cite{paliwal2020preclinical}. It is therefore imperative that predictions are made using pertinent biological information so that viable targets can be discovered.\n\n\\subsection{Previous Works}\n\nIt has long been observed that graphs representing real-world data possess a long or heavy-tailed distribution of degree values~\\cite{barabasi1999emergence}. This means that the majority of vertices have a limited number of connections to others, with a small number of highly connected hub-vertices being present. This inherent connectivity imbalance present in KG data can pose challenges when using it for input to machine learning models, however to what extent it has an impact has not yet been fully explored.\n\nThe issue of biased training data has become an area of great interest within the KG field. Typically, the bias of concern is that of attributes associated with the entities in the graph, for example gender, age or race~\\cite{wang2021unbiased, arduini2020adversarial, bourli2020bias}. However, recent work~\\cite{mohamed2020popularity} has shown how popularity bias is present in three frequently used non-biomedical KGs: FB15K~\\cite{bordes2013translating}, WN18~\\cite{bordes2013translating} and YAGO3-10~\\cite{mahdisoltani2014yago3}. The work argues that traditional methods for addressing data imbalance, such as up-weighting or over-sampling minority classes, do not map well onto KG data where we operate in the unit of triples. By definition triples contain two linked entities, each of which might have a very different level of connectivity within the graph, so how to re-weight the training process of KG-specific models is unclear~\\cite{mohamed2020popularity}. Instead, the authors propose alterations to the Hits@k and MRR ranking metrics to account for entity and relation popularity when scoring model performance.\n\nThe issue of non-uniform graph connectivity (typically in homogenous graphs) has begun to be studied in parallel by the field of Graph Neural Networks (GNN), where researchers have shown that models learn low-quality representations, and thus making more incorrect predictions for low-degree vertices~\\cite{liu2020towards, liu2021tail, tang2020investigating}. This has also been explored in the context of homogenous graph representation learning~\\cite{arduini2020adversarial} and for random walks~\\cite{kojaku2021residual2vec, rahman2019fairwalk}.\n\nOther work has argued that degree can be a strong feature for predicting an edge between two entities in biomedical graphs, but this can cause issues when the graph representation does not truly reflect the real underlying connections between the entities~\\cite{zietz2020probability}. The work derives a prior via a process of graph perturbations to measure the likelihood of an edge being present based solely on degree. However the impact of connectivity in relation to KGE models is not considered.\\section{Experimental Setup}\\label{sec:expsetup}\n\n\\subsection{Dataset}\\label{ssec:dataset}\n\nThroughout this work we primarily make use of the publicly available Hetionet biomedical knowledge graph \\cite{himmelstein2017systematic}. Hetionet was originally created as part of a project focusing on drug repurposing and integrates 29 public data sources, however its use has been explored in other areas such as target prediction~\\cite{bonner2021understanding}. Hetionet contains information on diseases, human protein-coding genes and compounds, among others, which are represented as entities within the graph and total over 47K. These are linked via 24 different relationship types capturing 2.2M interactions between them. An overview of Hetionet is presented in Figure \\ref{fig:hetionet}, which shows the overall degree distribution (Figure \\ref{fig:hetionet:full}), as well as for just the gene entities (Figure \\ref{fig:hetionet:gene}), both of which demonstrate a heavy-tailed distribution. The frequency of the entities (Figure \\ref{fig:hetionet:ef}) and relations (Figure \\ref{fig:hetionet:rf}) shows an imbalance, with certain ones being more prevalent than others\\footnote{A detailed explanation of entity and relation types can be found in the original publication~\\cite{himmelstein2017systematic}}.\n\nAs we focus on target discovery, that being the prediction of links between gene and disease entities, we make use of the \\(\\mathit{Disease} \\xrightarrow[]{\\textit{associates}} \\mathit{Gene}\\) (DaG) edges from Hetionet. These edges are extracted from data sources such as DISEASES~\\cite{pletscher2015diseases}, GWAS Catalog~\\cite{buniello2019nhgri} and DisGeNET~\\cite{pinero2016disgenet}, all of which capture known gene-disease associations and come from a variety of sources, ranging from expert curation to text mining. Additionally, Hetionet also contains two other edge types between gene and disease entities: \\(\\mathit{Disease} \\xrightarrow[]{\\textit{upregulates}} \\mathit{Gene}\\) and \\(\\mathit{Disease} \\xrightarrow[]{\\textit{downregulates}} \\mathit{Gene}\\). This is important to consider as it could be trivial for a model to learn that if a gene-disease pair are linked via an up- or down-regulates edge, then they should also be linked via an associates edge, as it would be a common case logically.\n\n\\begin{figure*}[!ht]\n\t\\centering\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/het_dist.pdf}\n\t\t\\caption{Degree Distribution}\\label{fig:hetionet:full}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/het_dist_gene.pdf}\n\t\t\\caption{Degree Distribution (Gene)}\\label{fig:hetionet:gene}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.365\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/hetnet_entity.pdf}\n\t\t\\caption{Entity Frequency}\\label{fig:hetionet:ef}\n\t\\end{subfigure}\n\n\t\\begin{subfigure}[b]{0.5\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/hetnet_relations.pdf}\n\t\t\\caption{Relation Frequency}\\label{fig:hetionet:rf}\n\t\\end{subfigure}\n\t\\caption{An overview of the Hetionet dataset.}\n\t\\label{fig:hetionet}\n\\end{figure*}\n\n\\subsection{Model}\\label{sec:model}\n\nMany knowledge graph embedding models have been introduced, with the primary differentiator between them being how they score the plausibility of a given triple. Throughout this present study we make use of the TransE model which was one of the earliest approaches, and often still one of the most capable. TransE uses the notion of translational distance to learn embeddings such that relations are used to translate between entities in latent space~\\cite{bordes2013translating}. In the TransE score function, the relation embedding is added to the head entity such that the result lies close to the tail embedding:\n\\[ f(h,r,t) =  -|| \\mathbf{h} + \\mathbf{r} - \\mathbf{t}||_F, \\]\nwhere \\(F\\) can be the l1 or l2 norm. One can interpret this score as simply the distance between the head and tail entity in the high-dimensional embedding space. Since its introduction, numerous other approaches have been proposed in the literature which build on or alter the TransE approach including TransH~\\cite{wang2014knowledge}, ComplEx~\\cite{trouillon2016complex}, RotatE~\\cite{sun2019rotate} \\& DistMult~\\cite{yang2015embedding}, all with different strengths and weaknesses regarding relation types that can be captured~\\cite{rossi2021knowledge}. However TransE has proven to still be highly competitive, when tuned appropriately, and can outperform more recent approaches~\\cite{bonner2021understanding}.\n\nConsidering its comparable predictive performance and relatively modest computational requirements, the majority of our results refer to TransE, as the experiments we demonstrate in this study required a large number of training regimens. Nevertheless, we train and evaluate the performance of the above-mentioned newer models in the gene-disease prediction setting, and indeed observe the same trends regardless of the model in use (See Figure \\ref{fig:degree-regression-models}). Furthermore, all these models were trained using optimal hyperparameters previously established~\\cite{bonner2021understanding} on the same dataset.\n\n\\subsection{Case Study Diseases}\\label{ssec:dis}\n\nNot all entities are created equally and in our context this refers to the connectivity of diseases which naturally varies due to how well-studied a particular disease is. In order to assess how the ranking of \\(DaG\\) predictions vary due to the degree of the disease, we choose diseases on both ends of the connectivity scale. An overview of these five diseases and how they are connected within the graph is presented in Table \\ref{tab:disease}.\n\nOn the upper end, we have Breast Cancer which is the most highly-connected disease in Hetionet, with a degree of 1159, out of which 540 are of type \\(DaG\\). However, considering the heterogeneous nature of breast cancers and the diversity of both clinical and molecular subtypes~\\cite{szymiczek2021bc} we also wanted to include other highly-connected diseases, with relatively more homogeneous aetiologies in the analysis. For this purpose, we chose melanoma and Parkinson's disease (PD) as representatives of  highly-studied diseases. Melanoma is a common type of cancer with relatively few subtypes and many known driver mutations \\cite{rabbie2019melanoma}. Furthermore, it is the 4th best connected disease in the Hetionet graph, with a degree of 944 and 930 distinct neighbours. Parkinson's, on the other hand, is a complex neurodegenerative disease that has several monogenic variants, that is mutations in single genes causing the disease, as well as various identified genetic risk factors~\\cite{hernandez2016Parkinson}. In Hetionet, Parkinson's disease has a degree of 795, and is the 8th most connected disease.\n\nFor low connectivity diseases, we chose Fuchs Endothelial Dystrophy (FED) and Fallopian Tube Cancer (FTC). Fuchs endothelial dystrophy, is a relatively rare disease with only 22 connections in the graph, all distinct neighbors. Besides being the 4th least connected disease in the graph, we found this disease to be of interest in terms of high level of characterisation and several known genetic factors as well as affected bioprocesses~\\cite{Eghrari2015Fuchs}. Fallopian tube cancer is a fairly rare type of cancer, with an incidence rate of about 0.36-0.41 per 100000 women~\\cite{stasenko2019ftc}. Given its rarity, there is little in literature about this disease, especially in comparison to closely related ovarian and peritoneal carcinomas. In Hetionet, FTC has a degree of 29; connecting to 10 diseases, 8 symptom and anatomy nodes each, and most importantly to 3 genes.\n\nSeen together these diseases provide a wide range of pathologies, both common and rare. Additionally, these diseases have high tissue-specificity and, in most cases, relatively low diversity in cell types and subtypes. Even in the case of FED and FTC, there are known genes with causative and/or risk-affecting mutations. These properties can be used in order to sanity check the predicted gene-disease associations to some extent.\n\n\\begin{table*}[ht!]\n\n\t\\centering\n\t\\begin{tabular}{p{0.295\\textwidth}  C{0.1\\textwidth}  C{0.15\\textwidth} C{0.15\\textwidth} C{0.15\\textwidth}}\n\t\t\\toprule\n\t\t\\textbf{Disease}            & \\textbf{Degree} & \\textbf{\\# Distinct} & \\textbf{\\# DaG} & \\textbf{Connectivity} \\\\\n\t\t\\midrule \\midrule\n\t\tBreast Cancer               & 1159            & 1123                 & 540             & High                  \\\\\n\t\tMelanoma                    & 944             & 930                  & 342             & High                  \\\\\n\t\tParkinson's Disease         & 795             & 789                  & 143             & High                  \\\\\n\t\t\\midrule\n\t\tFallopian Tube Cancer       & 29              & 29                   & 3               & Low                   \\\\\n\t\tFuchs Endothelial Dystrophy & 22              & 22                   & 6               & Low                   \\\\\n\t\t\\bottomrule\n\t\\end{tabular}\n\t\\vspace{5pt}\n\t\\caption{The diseases we focus on in this study and associated metrics for them from Hetionet. Where \\# Distinct is the number of unique entities connected to the disease.}\n\t\\label{tab:disease}\n\\end{table*}\n\n\\subsection{Implementation Details}\n\nAll work has been performed using the open-source PyKEEN framework~\\cite{ali2020pykeen}, a python library for knowledge graph embeddings built on top of PyTorch~\\cite{paszke2019pytorch}. All experiments were performed on machines with Intel(R) Xeon(R) Gold 5218 CPUs and NVIDIA(R) V100 32GB GPUs. Additionally, we kept the software environment consistent throughout all experimentation using python 3.8, CUDA 10.1, PyTorch 1.9, and PyKEEN 1.5.0. Models were trained using optimal hyper-parameters, presented in Table~\\ref{tab:params}, as discovered through a detailed optimisation process of over 100 unique parameter configurations per model~\\cite{bonner2021understanding}. Additionally, all models were trained on the same fixed random split of the Hetionet dataset.\n\n\\begin{table}[h!]\n\t\\centering\n\t\\small\n\t\\begin{tabular}{l c c c c c }\n\t\t\\toprule\n\t\t\\textbf{Parameter} & \\multicolumn{5}{c}{\\textbf{Value By Approach}} \\T\\B                                                                      \\\\\n\t\t\\midrule \\midrule\n\t\t                   & ComplEx                                                                          & DistMult & RotatE & TransE & TransH\\B \\\\\n\t\t\\cline{2-6}\n\n\t\tEmbedding Dim      & 272                                                                              & 80       & 512    & 304    & 480\\T    \\\\\n\t\tNum Epochs         & 700                                                                              & 400      & 500    & 500    & 800      \\\\\n\t\tLearning Rate      & 0.03                                                                             & 0.02     & 0.03   & 0.02   & 0.005    \\\\\n\t\tNum Negatives      & 91                                                                               & 41       & 41     & 61     & 1        \\\\\n\t\t\\midrule\n\t\tOptimiser          & \\multicolumn{5}{c}{Adagrad}                                                                                              \\\\\n\t\tInverse Relations  & \\multicolumn{5}{c}{False}                                                                                                \\\\\n\t\tLoss Function      & \\multicolumn{5}{c}{Negative Sampling Self-Adversarial Loss~\\cite{sun2019rotate}}                                         \\\\\n\t\t\\bottomrule\n\t\\end{tabular}\n\t\\caption{Model hyperparameters and training setups.}\\label{tab:params}\n\\end{table}\n\n\\emph{A note on runtime:} The training of knowledge graph embedding models can be costly in regards to runtime on KGs the size of Hetionet~\\cite{bonner2021understanding}. For example, training a TransE model with the hyperparameters detailed in Table~\\ref{tab:params}, took six hours on the previously detailed hardware. All other models demonstrated runtimes equal to, or often, greater than this. This has particular implications for the experiments where the KG is being perturbed in some way (i.e.\\ the edge removal, addition or rewiring experiments) as each individual data point and each experiment repeat requires a full model retraining, meaning that these results took several hundred GPU hours to compute. This is ultimately why we limited this analysis to specific diseases, rather than repeating it over all available in Hetionet.\\section{Results}\\label{sec:results}\n\nIn this section we present the results of our experimental evaluation. Unless otherwise stated, all experiments employ the \\(\\mathit{Disease} \\xrightarrow[]{\\mathit{associates}} \\mathit{Gene}\\) relation type from Hetionet and make use of the TransE model as described in Section~\\ref{sec:expsetup}.\n\n\\subsection{Correlation with Topological Structure}\\label{ssec:cor-top}\n\nWe begin by studying correlation between an entity's degree and the score assigned to it by the model measuring how likely it is to be the correct one to complete the triple.\n\nAs highlighted in Section \\ref{ssec:background}, KGE models are essentially agnostic of the data schema when completing missing edges during inference time. As such they provide a score for each and every entry regardless of their type. Figure \\ref{fig:all-entity} displays the score assigned by TransE\\footnote{This score is the direct value taken from the TransE scoring function as detailed in Section \\ref{sec:model}, hence the negative value.} to each entity in the Hetionet graph when completing the triple (Disease, DaG, ?) plotted against the degree for that entity, from which two main patterns can be seen. First and foremost, in both Melanoma (Figure \\ref{fig:ae:mel}) and FED (Figure \\ref{fig:ae:fuchs}) we can see a clear separation for Gene entities from everything else in the score space. This implies that the model is assigning a higher confidence to Genes being the correct entities to complete the triple. This is encouraging since we can conclude that the model at least is able to learn that the DaG relation only ever connects a Disease and a Gene in the training dataset.\n\n\\begin{figure*}[!th]\n\t\\centering\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/mel-all.png}\n\t\t\\caption{Melanoma}\\label{fig:ae:mel}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/fuchs-all.png}\n\t\t\\caption{Fuchs Endothelial Dystrophy}\\label{fig:ae:fuchs}\n\t\\end{subfigure}\n\t\\caption{Predicted score for each entity using TransE when completing the partial triple (Disease, DaG, ?) versus the degree of the entity. Points are styled by entity type. The higher the score, the more likely the model considers the entity and being the correct one to complete the triple.}\n\t\\label{fig:all-entity}\n\\end{figure*}\n\nHaving passed this first sanity check for the predictions, we thus move to focus on the relationship between the score assigned to just the Gene entities. The second pattern observed in Figure \\ref{fig:all-entity} was that there appears to be a correlation between degree and score. We now explore this in further detail for the various diseases explained in Section~\\ref{ssec:dis}.\n\nIn Figure \\ref{fig:degree-regression} the relationship between the score assigned to the gene entities by the TransE model and their degree is presented across both low and highly connected diseases. The points are coloured according to whether the particular entity was seen completing the triple in the train or test datasets, or whether it is novel (i.e. a DaG relationship not present in Hetionet between the given disease and that particular gene). The figures show there is a very clear relationship between the degree of the entity and the score assigned to it by the model -- the higher the degree, the more likely the model considers the entity to complete the triple. This observation holds for both well-connected (Figures \\ref{fig:dr:mel} and \\ref{fig:dr:park}) and sparsely connected diseases (Figures \\ref{fig:dr:fuchs} and \\ref{fig:dr:fal}). Indeed the pattern is remarkably similar, not only across all the diseases shown here in detail, but also for all 137 unique diseases that exist in Hetionet (Figure \\ref{fig:r2_over_disease}), suggesting that the connectivity of the gene has a large impact on whether it is likely to be predicted as associated with a disease, no matter which disease we investigate.\n\nAnother observation that can be made from Figure \\ref{fig:degree-regression} is that many entities not seen during training have a higher score given by the model than those in the training data. This is especially true for the low connectivity diseases (Figures \\ref{fig:dr:fuchs} and \\ref{fig:dr:fal}) where the model ranks many genes with high degree over those with an actual connection in the training data. In other words, the model is more confident in a highly-connected gene than a true positive it has seen during training. While it is prudent not to draw big conclusions with so few data points in these diseases, it is nevertheless an important finding that a high-degree node can be ranked higher than a known positive. Indeed, the perceived wisdom would be that the model would over-fit to the training data and one would expect the training points to all be given high scores regardless of their degree, which does not appear to be the case.\n\n\\begin{figure*}[!ht]\n\t\\centering\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/mel-degR.png}\n\t\t\\caption{Melanoma}\\label{fig:dr:mel}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/park-degR.png}\n\t\t\\caption{Parkinsons}\\label{fig:dr:park}\n\t\\end{subfigure}\n\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/fuchs-degR.png}\n\t\t\\caption{Fuchs Endothelial Dystrophy}\\label{fig:dr:fuchs}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/fal-degR.png}\n\t\t\\caption{Fallopian Tube Cancer}\\label{fig:dr:fal}\n\t\\end{subfigure}\n\t\\caption{Relationship between gene entity degree and the score assigned to it by TransE assessing the likelihood of it associating with the given disease.}\\label{fig:degree-regression}\n\\end{figure*}\n\n\\begin{figure}[!ht]\n\t\\centering\n\t\\begin{subfigure}[b]{0.45\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/r2_dist.pdf}\n\t\t\\caption{Distribution of \\(R^2\\)}\\label{fig:r2:violin}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.45\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/r2_deg.pdf}\n\t\t\\caption{\\(R^2\\) values vs disease degree}\\label{fig:r2:dist}\n\t\\end{subfigure}\n\t\\caption{Correlation between the gene degree and score is consistent across all diseases in Hetionet as shown here. All diseases in Hetionet show high correlation coefficients between gene degree vs score, while the disease degree seems not to influence the results.}\n\t\\label{fig:r2_over_disease}\n\\end{figure}\n\nAdditionally, we wanted to explore how this apparent degree bias impacts the commonly used metrics for ranking entities. We demonstrate this by measuring the Mean Rank (MR) and Mean Reciprocal Rank (MRR), as well as Hits@\\textit{k}, with \\textit{k}=1 and \\textit{k}=10, of the tail entities for all DaG triples present in a holdout testset over 10 different dataset splits, as shown in Table \\ref{tab:metrics}. Results are separated into high-degree (genes with degree \\(>1000\\)) and low-degree (genes with degree \\(<200\\)). The table shows that the model indeed demonstrates significantly lower performance, often by an order of magnitude, when evaluating on low-degree ground truth data.\n\n\\begin{table}[h!]\n\t\\centering\n\n\t\\begin{tabular}{l  c c c  c c c  }\n\t\t\\toprule\n\t\t\\textbf{Degree} & \\multicolumn{4}{c}{\\textbf{Metric}} \\T\\B                                                                    \\\\\n\t\t\\midrule \\midrule\n\t\t                & MR \\(\\downarrow\\)                        & MRR \\(\\uparrow\\)  & Hits@1 \\(\\uparrow\\) & Hits@10 \\(\\uparrow\\)\\B \\\\\n\t\t\\cline{2-5}\n\t\tLow             & 4353.7\\(\\pm\\)198.8                       & 0.006\\(\\pm\\)0.001 & 0.001\\(\\pm\\)0.001   & 0.012\\(\\pm\\)0.003\\T    \\\\\n\t\tHigh            & 300.85 \\(\\pm\\)96.6                       & 0.053\\(\\pm\\)0.018 & 0.010\\(\\pm\\)0.017   & 0.118\\(\\pm\\)0.053\\B    \\\\\n\t\t\\bottomrule\n\t\\end{tabular}\n\t\\vspace{5pt}\n\t\\caption{Ranking metrics over high and low degree DaG edges from the holdout testsets. Arrows indicate if a higher or lower value is best for a given metric.}\n\t\\label{tab:metrics}\n\\end{table}\n\n\\textbf{Correlation Across Diseases} Figure \\ref{fig:r2-across-disease} shows how the R-Squared value for the correlation between gene degree and predicted score across all 137 diseases in Hetionet, where the diseases have been categorised into families. The figure highlights how the strong correlation is present across the whole range of diseases in the dataset.\n\n\\begin{figure}[!th]\n\t\\centering\n\t\\includegraphics[width=0.9\\textwidth]{figs/r2_across_disease.pdf}\n\t\\caption[R-Squared value across disease family]{R-Squared value of the relationship between gene degree and score across all 137 diseases in Hetionet categorised into disease families. Disease families are Cancer, Immune/Inflammatory (Imm/Inf), Metabolic, Neurological (Neuro), Cardio-Vascular (CV), Infection and Other.}\n\t\\label{fig:r2-across-disease}\n\\end{figure}\n\n\\textbf{Different Models.} Figure \\ref{fig:degree-regression-models} highlights that this relationship between degree and score is not just a TransE specific issue but is prevalent across many knowledge graph embedding models used in the literature (including TransH~\\cite{wang2014knowledge}, ComplEx~\\cite{trouillon2016complex}, RotatE~\\cite{sun2019rotate} \\& DistMult~\\cite{yang2015embedding} which were trained using optimised hyper-parameters for Hetionet as detailed previously~\\cite{bonner2021understanding}). The figure also displays the Hits@10 score on a hold-out testset comprising 10\\% of the triples for all models. There appears to be little direct relationship between the Hits@10 score and the R-squared value, although the worse performing model ComplEx does have the weakest correlation between degree and the score assigned to the gene entities.\n\n\\begin{figure*}[!h]\n\t\\centering\n\t\\begin{subfigure}[b]{0.24\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/transh-breast.png}\n\t\t\\caption{TransH (0.11)}\\label{fig:dr:transh}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.24\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/complex-breast.png}\n\t\t\\caption{ComplEx (0.07)}\\label{fig:dr:complex}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.24\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/rotate-breast.png}\n\t\t\\caption{RotatE (0.27)}\\label{fig:dr:rotate}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.24\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/distmult-breast.png}\n\t\t\\caption{DistMult (0.14)}\\label{fig:dr:distmult}\n\t\\end{subfigure}\n\t\\caption{Relationship between gene degree versus predicted score for association with Breast Cancer. Numbers detail the Hits@10 score for that model on a holdout testset. Note that the change scale for the score is due to the different objective function used by the models.}\n\t\\label{fig:degree-regression-models}\n\\end{figure*}\n\n\\textbf{Different Datasets.} Further, Figure \\ref{fig:other-datasets} shows this issue not to be a dataset specific one as the same pattern can be found on two other biomedical knowledge graphs: the Drug Repurposing Knowledge Graph (DRKG)~\\cite{drkg2020} and OpenBioLink~\\cite{breit2020openbiolink}. Here the TransE model is used to predict the genes most likely to be associated with breast cancer. Figure \\ref{fig:other-datasets} shows that a correlation between predicted score and degree is indeed present in both datasets, although OpenBioLink has a weaker correlation. Although we only present results for breast cancer for these datasets, we observed similar patterns across all of our chosen diseases.\n\n\\begin{figure*}[!h]\n\t\\centering\n\t\\begin{subfigure}[b]{0.32\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/drkg_b.png}\n\t\t\\caption{DRKG}\\label{fig:other-datasets:drkg}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.32\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/obl_b.png}\n\t\t\\caption{OpenBioLink}\\label{fig:other-datasets:obl}\n\t\\end{subfigure}\n\t\\caption{Relationship between the predicted score for gene association with breast cancer and degree across other biomedical knowledge graphs.}\n\t\\label{fig:other-datasets}\n\\end{figure*}\n\n\\textbf{Different Tasks.} We show that the issue is not specific to the task of gene-disease association prediction, but is replicated across many drug discovery tasks. Figure \\ref{fig:other-tasks} highlights the relationship between score and entity degree for three other tasks, namely: Drug Target Interaction (DTI), Protein-Protein Interaction (PPI) and Drug Repurposing (DR). For the DTI task (Figures \\ref{fig:other-tasks:dti1}-\\ref{fig:other-tasks:dti3}), we use the \\(\\mathit{Compound} \\xrightarrow[]{\\mathit{binds}} \\mathit{Gene}\\) (CbG) edge types to rank genes by how likely they are to bind to the drugs Sunitinib, Auranofin and Doxorubicin. These compounds are selected in order to showcase different aspects of the dataset. Sunitinib and Doxorubicin are both chemotheraphy agents against cancer; the former is a receptor tyrosine kinase while the latter is an anthracycline topoisomerase inhibitor. Both drugs are well studied and thus well connected in the graph, Sunitinib has the most CbG connections, while Doxorubicin is extremely well connected both in terms of overall degree, and specifically connections to genes. On the opposing end of the connectivity scale Auranofin has fewer overall connections in the graph, and very few CbG connections thus provides a good example when there is little information to train on.\n\nIn the PPI task (Figures \\ref{fig:other-tasks:ppi1}-\\ref{fig:other-tasks:ppi3}), the \\(\\mathit{Gene} \\xrightarrow[]{\\mathit{interacts}} \\mathit{Gene}\\) (GiG) edge types are used and genes are ranked based on likelihood to interact with the query genes MAPK1, PCNA and UBC. These are all fairly well studied genes, despite their apparent differences in terms of degree in Hetionet. An overwhelming majority of the connectivity of UBC is to other genes, specifically of the type GiG we consider here. PCNA on the other hand has again majority of its connections to other genes, however these are of a different relationship type. Lastly, MAPK1 has a much more balanced connectivity profile, in terms of diversity to other entities in the graph. Thus it provides a good test case to see if connectivity to other node types make any tangible contribution to the predictive performance in GiG relationships.\n\nFinally, in the DR task (Figures \\ref{fig:other-tasks:ctd1}-\\ref{fig:other-tasks:ctd3}), the \\(\\mathit{Compound} \\xrightarrow[]{\\mathit{treats}} \\mathit{Disease}\\) edges are utilised to rank compounds by how likely the model considerers them to treat the diseases Rheumatoid arthritis, Fuchs endothelial dystrophy and Hypertension. This choice of diseases is motivated by two well-connected diseases of different aetiologies, both with various compounds for treatment options currently used in the clinic. The third disease here is a weakly connected one, without any compound connectivity and surgery as a primary means of treatment. Thus it provides a negative control for the predictive performance for the model. Last but not least, all three diseases are chosen to be distinct from various forms of cancer, as these disease dominate the overall connectivity, as well as to compounds in particular. Many cancer drugs are used for various indications and indeed a model could simply do well by extrapolating a well-connected compound to a well-connected form of cancer.\n\nAcross all tasks and example cases, we observe a strong correlation between score and degree highlighting that this is not a task-specific issue and is prevalent across many drug discovery problems.\n\n\\begin{figure*}[!ht]\n\t\\centering\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/Compound_DB01268_dti.png}\n\t\t\\caption{DTI - Sunitinib}\\label{fig:other-tasks:dti1}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/Compound_DB00995_dti.png}\n\t\t\\caption{DTI - Auranofin}\\label{fig:other-tasks:dti2}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/Compound_DB00997_dti.png}\n\t\t\\caption{DTI - Doxorubicin}\\label{fig:other-tasks:dti3}\n\t\\end{subfigure}\n\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/Gene_5594_ppi.png}\n\t\t\\caption{PPI - MAPK1}\\label{fig:other-tasks:ppi1}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/Gene_5111_ppi.png}\n\t\t\\caption{PPI - PCNA}\\label{fig:other-tasks:ppi2}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/Gene_7316_ppi.png}\n\t\t\\caption{PPI - UBC}\\label{fig:other-tasks:ppi3}\n\t\\end{subfigure}\n\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/Disease_DOID_7148_ctd.png}\n\t\t\\caption{DR - Rheumatoid arthritis}\\label{fig:other-tasks:ctd1}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/Disease_DOID_10763_ctd.png}\n\t\t\\caption{DR - Hypertension}\\label{fig:other-tasks:ctd2}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.3\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/Disease_DOID_11555_ctd.png}\n\t\t\\caption{DR - FED}\\label{fig:other-tasks:ctd3}\n\t\\end{subfigure}\n\t\\caption{Relationship between the prediced score and degree for other drug discovery tasks;  in a-c we query drug-target interactions for three compounds, d-f protein-protein interaction partners for three genes  are queried, and in g-i we query for compounds for treatment of three diseases.}\n\t\\label{fig:other-tasks}\n\\end{figure*}\n\n\\subsection{Relations with Disease}\n\\label{ssec:rel-disease}\n\nWe now consider whether the number of connections a gene has to disease entities within the training graph can affect ranking.\n\nFigure \\ref{fig:disease-connections} shows this analysis where melanoma is the query disease in question. Intuitively, one would expect a gene that has multiple connections to diseases to have a higher likelihood of being associated with another disease. This follows from the fact that in order to be associated with any disease in the first place, the gene would need to be characterized and often these associations are experimentally validated. Therefore, it is more likely that a well-characterized gene is associated with another disease, than a completely unknown gene is to be linked to a disease for the first time.\n\nAs expected, we found that the genes that have links to disease entities tend to have a higher predicted score (and thus higher rank) than those that have no disease links, as shown in Figure \\ref{fig:disease:deg}. As mentioned above, gene-disease annotations are not uniformly distributed over genes. In other words, some genes have many disease annotations while others have few or none. Considering this, we wanted to check whether or not we can see a difference between high-ranking and low-ranking genes in terms of total number of connections to other diseases (Figure \\ref{fig:disease:num}).\n\nOverall, we observed there is a connection between the number of edges to other diseases and the ranking, such that genes with a higher number of connections to other diseases, tend to have higher scores. However, not all high ranking genes had a large number of edges, which brings us to the question of whether it is the proportion of the edges of a gene to disease nodes that play a significant role. This did not turn out to be the case, as shown in Figure \\ref{fig:disease:ratio} there is little relationship between the proportion of edges a gene has to disease entities and the score assigned to it. However, ultimately it is hard to disentangle the impact of disease connections versus the total number, as highly connected genes are also more likely to be connected to diseases.\n\n\\begin{figure*}[!ht]\n\t\\centering\n\t\\begin{subfigure}[b]{0.4\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/mel_deg_disease.png}\n\t\t\\caption{Disease Linked}\\label{fig:disease:deg}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.4\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.74\\textwidth]{figs/mel_deg_disease_box.pdf}\n\t\t\\caption{Disease Linked (Box)}\\label{fig:disease:deg-box}\n\t\\end{subfigure}\n\n\t\\begin{subfigure}[b]{0.4\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/mel_num_disease.png}\n\t\t\\caption{Number of disease connections}\\label{fig:disease:num}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.4\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/mel_ratio_disease.png}\n\t\t\\caption{Ratio of disease edges}\\label{fig:disease:ratio}\n\t\\end{subfigure}\n\t\\caption{The relationship between the prediced score for Melanoma and various measures of connectivity between genes and the disease entities.}\n\t\\label{fig:disease-connections}\n\\end{figure*}\n\n\\subsection{Trivial Relations}\\label{ssec:trivial-relations}\n\nWe now consider whether the presence of other relation types between a given gene and disease pair in the training graph affects score.\n\nThis is a subtle but important aspect, as multiple relationship types between entities in biological KGs like Hetionet typically allow for information leakage in the form of trivialized predictions. The presence of trivial relations, such as inverse ones, is known to result in over-optimistic models, which although appear as though they are demonstrating good predictive performance, in reality have exploited trivial patterns in the data~\\cite{toutanova2015observed, dettmers2018convolutional}. In Hetionet besides the DaG relation type we have used so far, there are also two other relationship types that are allowed between disease and gene entities, specifically \\(\\mathit{Disease} \\xrightarrow[]{\\textit{upregulates}} \\mathit{Gene}\\) and \\(\\mathit{Disease} \\xrightarrow[]{\\textit{downregulates}} \\mathit{Gene}\\). Figure \\ref{fig:disease-other-edge} shows the relationship between score and degree, as before, however here we stratified the genes by whether they have another type of relationship to the queried disease, for melanoma and Parkinson's Disease.\n\nCuriously, while the pattern of high correlation between degree and score is maintained for both groups, there is little difference between them in terms of ranking. In other words, the existence of another relation type between the same disease and gene does not appear to affect the associates relation. Especially interesting are the genes at the lower end of the degree distribution, where there are genes whose only edge is to the disease of interest which are still ranked lowly. We could not replicate this with the other two, sparsely-connected, diseases since they did not have multiple relation types between them and genes.\n\n\\begin{figure*}[!ht]\n\t\\centering\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/mel_other_disease_edges.png}\n\t\t\\caption{Melanoma}\\label{fig:disease:mel}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/park_other_disease_edges.png}\n\t\t\\caption{Parkinsons}\\label{fig:disease:park}\n\t\\end{subfigure}\n\t\\caption{Relationship between predicted gene-disease association score and entity degree. Points are coloured to indicate whether the gene has an edge of a different type to the disease of interest.}\n\t\\label{fig:disease-other-edge}\n\\end{figure*}\n\n\\subsection{Graph Perturbations}\n\\label{ssec:graph-perturbations}\n\nIn this section we aim to understand whether we can artificially influence the rank assigned to a gene by a model via a perturbing process whereby edges are removed or added, thus altering the graph topology. Any change in score relative to a disease could then be measured by retraining the model on this new graph. For all experiments presented in this section, 10 repeats are performed over different sets of random edges, with results being presented as the mean with 95\\% confidence intervals.\n\n\\textbf{Edge Removal.} In this experiment, a random selection edges are incrementally removed from the highest ranked novel gene for a given disease and any change in rank is measured. Two strategies are used for this removal process:\n\\begin{itemize}\n\t\\item \\emph{Disease:} edges are removed randomly from the gene to only other disease entities.\n\t\\item \\emph{Random:} edges are removed randomly from the gene to any other entity.\n\\end{itemize}\n\nFigure \\ref{fig:reduce} shows how the rank of the top gene for a disease is affected as different proportions of its edges are removed. As can be seen in both panels, there is a clear relationship between the removal of edges and a decrease in rank. It should noted that this result should not be considered surprising, indeed the assumption would be that as knowledge is removed from the graph, the model is able to learn less about the gene and thus is able to make less confident predictions about it. What is more interesting however is that by removing disease connections, the rank is relatively unaffected, which is somewhat counter-intuitive.\n\n\\begin{figure*}[!ht]\n\t\\centering\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/leptin_reduce.pdf}\n\t\t\\caption{Leptin - Fallopian Tube Cancer}\\label{fig:reduce:lep}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/interleukin_reduce.pdf}\n\t\t\\caption{Interleukin 1 beta - Melanoma}\\label{fig:reduce:inter}\n\t\\end{subfigure}\n\t\\caption{Removel of edges from the top ranked novel gene for two diseases: Fallopian Tube Cancer and Melanoma}\n\t\\label{fig:reduce}\n\\end{figure*}\n\n\\textbf{Edge Addition.} In this experimental setup we add random, biologically meaningless edges to a gene to investigate how this impacts the score assigned to it by the model in relation to a set of diseases. To achieve this, we took the gene predicted to be the least likely to associate with a given disease and artificially increased its connectivity within the graph using two strategies:\n\n\\begin{itemize}\n\t\\item \\emph{Disease:} edges are added randomly from the gene to only other disease entities, excluding the disease we are scoring against. These edges conform to the graph schema and use the correct relation types of DaG, DuG and DdG.\n\t\\item \\emph{Ant-Comp-Gene:} edges are added randomly from the gene to other gene, compound and anatomy entities. Again these edges conform to graph schema and use the correct relation types.\n\\end{itemize}\n\nFigure \\ref{fig:add:fed} shows the results for Fuchs endothelial dystrophy, whilst Figure \\ref{fig:add:breast} the results for Breast Cancer. For both of these the gene to which the edges were added was T cell receptor gamma locus (TRG) as it was the least likely genes for both diseases. TRG has just a single edge in the original graph, connecting it to another gene. Overall the figures highlight the key observation that for both diseases, TRG was able to be moved from the least likely to one of the most likely gene to associate with the disease by the addition of biologically meaningless random edges. This finding provides further evidence that the predictions from KGE models can be biased by the frequency with which the entity is observed during the training process, and that this bias might outweigh any domain-specific knowledge captured in the data that may be useful to make more accurate real-world predictions.\n\n\\begin{figure*}[!ht]\n\t\\centering\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/fed_add.pdf}\n\t\t\\caption{Fuchs endothelial dystrophy}\\label{fig:add:fed}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/breast_add.pdf}\n\t\t\\caption{Breast Cancer}\\label{fig:add:breast}\n\t\\end{subfigure}\n\t\\caption{Addition of edges the lowest ranked gene for two diseases: Breast Cancer and Fuchs endothelial dystrophy. In both cases, the gene TRG is used as the target for the edge addition.}\n\t\\label{fig:add}\n\\end{figure*}\n\n\\subsection{Case Study: UBC}\n\\label{ssec:ubc}\n\nA consistent feature of the ranking vs degree plots is a gene to the top-right of the plot area, ranked curiously high no matter the disease in question, likely due to its particularly high degree. This gene is \\emph{Polyubiquitin-C} (UBC), with a degree just below \\(10^4\\), nearly an order of magnitude higher than any other gene within Hetionet.\n\nThe UBC gene codes for multiple copies of the Ubiquitin protein, which in turn is a crucial component in many signalling and transport processes within the cell~\\cite{kimura2010ubi}. Specifically, ubiquitin signalling is associated with protein degradation and recycling of amino acids, which is a critical metabolic process that has important implications for normal function of a cell. With such an critical role, it is not surprising that ubiquitin, and thus indirectly ubiquitin-coding genes like UBC, are involved in many pathways.\n\nAdditionally, the overwhelming majority of the connections UBC has in Hetionet is to other genes (Table \\ref{tab:ubc-conn}), likely due to UBC being directly responsible for degradation of many proteins these genes code for. Despite its predicted association with all our diseases of interest, UBC has a only single connection to a Disease and Compound entity type in the graph.\n\n\\begin{table}[ht!]\n\t\\centering\n\t\\begin{tabular}{l c c}\n\t\t\\toprule\n\t\t\\textbf{Neighbour Type} & \\textbf{\\# of Conns} & \\textbf{\\# of Distinct} \\\\ \\midrule \\midrule\n\t\tGene                    & 8789                 & 8653                    \\\\\n\t\tBiologicalProcess       & 345                  & 345                     \\\\\n\t\tPathway                 & 173                  & 173                     \\\\\n\t\tAnatomy                 & 55                   & 44                      \\\\\n\t\tCellularComponent       & 7                    & 7                       \\\\\n\t\tMolecularFunction       & 1                    & 1                       \\\\\n\t\tCompound                & 1                    & 1                       \\\\\n\t\tDisease                 & 1                    & 1                       \\\\ \\bottomrule\n\t\\end{tabular}\n\t\\vspace{5pt}\n\t\\caption{Overview of UBC's connectivity within Hetionet. The disparity between number of connections and the number of distinct neighbours is due to the fact that any two entities can have multiple relationships between them.}\n\t\\label{tab:ubc-conn}\n\\end{table}\n\nSeen altogether, UBC provides a good example of where a highly connected entity is being over ranked as a prediction using KGE methods. UBC is ranked in the top 100 for every disease in the Hetionet dataset (See Table \\ref{tab:ubc-rank}), despite having only a single relationship of the desired type (i.e. DaG), or barely any type of relationship to the entity type of interest (i.e. Disease). Furthermore, a gene that is heavily interconnected with other genes, like UBC, is likely to be considered a poor candidate disease target since any interference with its function will likely have many unintentional and undesired downstream effects, as vital metabolic and signalling processes would be altered out of the context of the disease.\n\nAs an interesting point of comparison, in the OpenBioLink dataset~\\cite{breit2020openbiolink}, UBC has a degree of 5937 and is only the sixth most well-connected gene, with many genes possessing a similar degree value. Table \\ref{tab:ubc-rank} shows how in OpenBioLink, now that UBC is no longer an outlier with nearly an order of magnitude greater connections than the next gene, its predicted rank in relation to the diseases is greatly reduced.\n\n\\begin{table}[ht!]\n\t\\centering\n\t\\begin{tabular}{l c c}\n\t\t\\toprule\n\t\t\\textbf{Disease}            & \\textbf{Rank (Hetionet)} & \\textbf{Rank (OpenBioLink)} \\\\ \\midrule \\midrule\n\t\tBreast Cancer               & 60                       & 232                         \\\\\n\t\tMelanoma                    & 82                       & 1061                        \\\\\n\t\tParkinsons disease          & 59                       & 1599                        \\\\\n\t\tFuchs Endothelial Dystrophy & 23                       & 3329                        \\\\\n\t\tFallopian Tube Cancer       & 52                       & 2117                        \\\\\n\t\t\\bottomrule\n\t\\end{tabular}\n\t\\vspace{5pt}\n\t\\caption{The predicted rank of the gene UBC to be associated with the range of diseases. Results presented using the Hetionet and OpenBioLink graphs with the TransE model.}\n\t\\label{tab:ubc-rank}\n\\end{table}\n\n\\textbf{Graph Rewiring.} Using UBC as our gene of interest, we investigated one final way of altering the graph topology: random rewiring. Here, edges from UBC to other entities in the graph are permuted by swapping the target entity via a random strategy. In this strategy, edges are rewired to the correct entity type. Further, the existing set of entities were removed from the pool of possible replacements to avoid the new edge replicating an already observed edge in the training data.\n\nFigure \\ref{fig:rewire} demonstrates the results of this rewiring process across four diseases in relation to UBC. The most apparent observation is that rewiring edges in accordance to the schema has almost no negative impact on the rank of UBC in relation to the four diseases. Indeed the rank actually increases for UBC across all diseases as we rewire edges. We hypothesise this to be caused by new edges being formed with other hub entities, thus further increasing UBC's importance within the graph. Simply put, this experiment shows we are able to go as far as completely randomising the biological information contained within UBC's edges without drastically altering how likely the model considers the gene to be associated with a disease. This is further evidence that KGE models are seemingly biased by the number of connections an entity has, rather than any domain knowledge encoded within its edges.\n\n\\begin{figure*}[!ht]\n\t\\centering\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/rewire_mel.pdf}\n\t\t\\caption{Melanoma}\\label{fig:rewire:mel}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/rewire_park.pdf}\n\t\t\\caption{Parkinsons}\\label{fig:rewire:park}\n\t\\end{subfigure}\n\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/rewire_fed.pdf}\n\t\t\\caption{Fuchs Endothelial Dystrophy}\\label{fig:rewire:fuchs}\n\t\\end{subfigure}\n\t\\begin{subfigure}[b]{0.48\\textwidth}\n\t\t\\centering\n\t\t\\includegraphics[width=0.99\\textwidth]{figs/rewire_ftc.pdf}\n\t\t\\caption{Fallopian Tube Cancer}\\label{fig:rewire:fal}\n\t\\end{subfigure}\n\t\\caption{The change in rank assigned to the gene UBC after a varying fraction of its edges are rewired.}\n\t\\label{fig:rewire}\n\\end{figure*}\n\n\\subsection{Discussion}\n\nThe purpose of this study was not to critique a particular dataset or methodology, the trends we observed were present across multiples of both anyway, rather we wanted to take a deeper look at how topological imbalance may be affecting predictions within the drug discovery domain. We believe the evidence from this experimental evaluation suggests that degree has a strong influence on KGE models, with highly connected entities seemingly being highly ranked regardless of context. Whilst this result may not initially seem surprising, as the high-degree entities are simply observed more during the model training process, the level of correlation should nevertheless be of concern to practitioners.\n\nIndeed the collective evidence from this study raises the prospect that domain knowledge encoded in the relationships matters less than one would expect and a highly connected, but biologically implausible, gene can be associated with a disease over one that would ultimately make a better drug target. This result also suggests that the predictions made by a KGE model, in the context of target discovery, may suffer from non-specificity -- the same set of highly connected genes are highly ranked regardless of the query disease, leading to little variability in candidates.\n\n\\textbf{Modeling.} Many existing KGE models were designed to solve tasks in other domains, and may not have been developed against biomedical graphs which can often have a distinct topological structure, such as higher average connectivity~\\cite{liu2021neural}. We hope that new models will more regularly include datasets such as Hetionet during their development phase. More generally, and taking cues from the field of GNNs~\\cite{liu2021tail, liu2020towards, tang2020investigating}, new methods could be be developed which consider how best to learn meaningful representations for low-degree entities.\n\n\\textbf{Evaluation.} Common metrics used for evaluating KGE models such as Hits@k and MRR do not consider entity or relation frequency and thus can be biased by it~\\cite{mohamed2020popularity}. As a simple mitigating step, care should be taken to ensure that low degree entities are included in test and validation sets to ascertain their impact is reflected in these metrics. Overall,  global performance metrics should not be the sole way of assessing model performance, rather practitioners should directly inspect the output predictions to look for any patterns contained within. For example, a highly ranked, but low degree, entity may be particularly interesting to consider.\n\n\\textbf{Graph Composition.} The examples demonstrated here provide a cautionary tale as relationship types seem to matter less than the overall volume of connectivity. This implies that KG practitioners should be aware of the implications of their data modelling decisions, being cognisant of any potential outliers in terms of topological structure. Thought should also be given to whether auxiliary information, which may un-proportionally increase the degree of certain entities, is really beneficial to the task at hand. This is especially important if edges are being automatically extracted, from publications for example, via NLP-based pipelines. Depending on the biological question at hand, a more focused and task-specific graph projection may lead to better overall predictions~\\cite{ratajczak2021task}.\n\nThroughout this process we have determined the following initial set of recommendations to help address topological imbalance:\n\n\\begin{itemize}\n\t\\item \\emph{Awareness -} We encourage practitioners to actively investigate the topologies of the graphs they are using for predictions, checking specifically for any inherent imbalance in entity or relation frequency. This also extends to awareness of which data sources and modalities have been used in graph construction, and any redundancies that may lie within.\n\t\\item \\emph{Predictions -} Further, KGE users should not rely solely on performance metrics, instead the ranked list of predictions should be inspected and compared with topological features for those entities. Where metrics are required, results should be presented across different levels of connectivity.\n\t\\item \\emph{Projections -} Practitioners should consider creating task-specific graph projections from larger holistic resources like Hetionet which may reduce the overall volume of connections and thus imbalance. However this should be performed in a principled manner so pertinent information is not lost as the graph is reduced.\n\t\\item \\emph{Edge Confidence -} One way to explore more principled projections could be to filter the graph based on confidence scores assigned to the edges. These values could be taken directly from the underlying data sources or computed where absent.\n\\end{itemize}\\section{Conclusion}\\label{sec:conclusion}\n\nBiological knowledge graphs, especially in a drug discovery context, are heavily unbalanced in terms of degree distribution. On the one hand we observe prior knowledge bias, i.e.\\ well-studied genes and diseases are typically have more, and often more confident, annotations. On the other hand, regardless of any \\emph{a priori} bias, biological entities are known to display a power law of connectivity, some genes have a wide range of biological functions, involved in various different diseases, and typically work in concert with a wide range of other genes. These two factors combine to create super-hub entities in the graph.\n\nAdditionally, modelling choices during the conception of the KG may lead to a very connection-dense resultant graph. For example, in the case of Hetionet, almost any two gene entities can be connected with a 1-hop path via an anatomy or cellular-component entity. This complexity is increased when one considers the multitude of ways entities can be connected to each other, depending on the data sources integrated into the graph. Automated data mining and natural text processing pipelines may further impact this by adding a significant number of relationships between the entities, often with questionable certainty, or little contextual information.\n\nIn this study, we demonstrate a reproducible tendency of KGE methods to overestimate highly-connected entities in predictive tasks. Furthermore, we show that this particular issue is independent of the choice of entities, or indeed even type of predictive task. We discuss the potential reasons for these results, as well as propose some tangible solutions that can be applied to avoid or at least ameliorate these type of problems. In the light of these findings, we believe it is prudent to pay close attention to the data modeling when creating a biological KG, application of embedding methods as well as to validate the resultant rankings for predictive tasks on these KGs. Despite the shortcomings discussed in this paper, we believe KGs and KGE methods provide valuable tools for generating meaningful representations of biological processes, reducing machine learning complexity and thus have potential for real impact in drug discovery efforts, especially when used appropriately for the underlying domain specific data. For future work, we aim to reduce the impact of connectivity imbalance through the use of a popularity bias term introduced in the model interaction function.\n\\section*{Acknowledgement}\n\nWe would like to thank all of the PyKEEN team for their help and support. We would also like to acknowledge the use of the Science Compute Platform (SCP) within AstraZeneca. Stephen Bonner is a fellow of the AstraZeneca postdoctoral program.\n\n\\end{document}\n</paper 1>\n\n<paper 2>\n\\title{Centrality Measures in multi-layer Knowledge Graphs}\n\n\\begin{document}\n\n\\maketitle              %\n\n\\begin{abstract}\nKnowledge graphs play a central role for linking different data which leads to multiple layers. Thus, they are widely used in big data integration, especially for connecting data from different domains. Few studies have investigated the questions how multiple layers within graphs impact methods and algorithms developed for single-purpose networks, for example social networks. This manuscript investigates the impact of multiple layers on centrality measures compared to single-purpose graph. In particular, (a) we develop an experimental environment to (b) evaluate two different centrality measures – degree and betweenness centrality -- on random graphs inspired by social network analysis: small-world and scale-free networks. The presented approach (c) shows that the graph structures and topology has a great impact on its robustness for additional data stored. Although the experimental analysis of random graphs allows us to make some basic observations we will (d) make suggestions for additional research on particular graph structures that have a great impact on the stability of networks.\n\\end{abstract}\n\n\\section{Introduction}\n\nKnowledge graphs have been shown to play an important role in recent knowledge mining and discovery, for example in the fields of digital humanities, life sciences or bioinformatics. They also include single purpose networks (like social networks), but mostly they contain also additional information and data, see for example \\cite{suarez2021risks,berhan2019board,rollinger2014amicitia}. Thus, a knowledge graph can be seen as a multi-layer graph comprising different data layers, for example social data, spatial data, etc. In addition, scientists study network patterns and structures, for example paths, communities or other patterns within the data structure, see for example \\cite{dorpinghaus2019knowledge}. Very few studies have investigated the questions how multiple layers within graphs impact methods and algorithms developed for single-purpose networks, see \\cite{rossetti2021conformity}. This manuscript investigates the impact of a growing part of other layers on centrality measures in a single-purpose graph. In particular, we develop an experimental environment to evaluate two different centrality measures -- degree and betweenness centrality -- on random graphs inspired by social network analysis: small-world and scale-free networks. \n\nThis paper is divided into five sections. The first section gives a brief overview of the state of the art and related work. The second section describes the preliminaries and background. We will in particular introduce knowledge graphs and centrality measures. In the third section, we present the experimental setting and the methods used for this evaluation. The fourth section is dedicated to experimental results and the evaluation. Our conclusions are drawn in the final section.\n\n\\section{Preliminaries}\n\nThe term \\emph{knowledge graph} (sometimes also called a \\emph{semantic network}) is not clearly defined, see \\cite{Fensel2020}. In~\\cite{ehrlinger2016towards},  several definitions are compared, but the only formal definition was related to RDF graphs which does not cover labeled property graphs. As another example, \\cite{paulheim2017knowledge} gives a definition of knowledge graphs limited to the definition of important features. Knowledge graphs were introduced by Google in 2012, when the Google Knowledge Graph was published on the use of semantic knowledge in web search, see \\url{https://blog.google/products/search/introducing-knowledge-graph-things-not/}. This is a representation of general knowledge in graph format. Knowledge graphs also play an important role in the Semantic Web and are also called semantic networks in this context.\n\nThus, a \\emph{knowledge graph} is a systematic way to connect information and data to knowledge. It is thus a crucial concept on the way to generate knowledge and wisdom, to search within data, information and knowledge. Context is the most important topic to generate knowledge or even wisdom. Thus, connecting knowledge graphs with context is a crucial feature. \n\n\\begin{definition}[Knowledge Graph]\\label{def:kg}\nWe define a knowledge graph as graph $G=(E,R)$ with entities $e\\in E=\\{E_1,...,E_n\\}$ coming from formal structures $E_i$ like ontologies. \n\\end{definition}\n\nThe relations $r\\in R$ can be ontology relations, thus in general we can say every ontology $E_i$ which is part of the data model is a subgraph of $G$ indicating $O\\subseteq G$. In addition, we allow inter-ontology relations between two nodes $e_1, e_2$ with $e_1 \\in E_1$, $e_2 \\in E_2$ and $E_1 \\neq E_2$. In more general terms, we define $R=\\{R_1,...,R_n\\}$ as a list of either inter-ontology or inner-ontology relations. Both $E$ as well as $R$ are finite discrete spaces.\n\nEvery entity $e\\in E$ may have some additional metainformation which needs to be defined with respect to the application of the knowledge graph. For instance, there may be several node sets (some ontologies, some actors (like employees or stakeholders, for example), locations, ...) $E_{1},...,E_{n}$ so that $E_{i}\\subset {E}$ and ${E} = \\cup_{i=1,...,n} E_{i}$. The same holds for ${R}$ when several context relations come together such as \"is relative of\", \"has business affiliation\", \"has visited\", etc. \n\nBy using formal structures within the graph, we are implicitly using the model of a labeled property graph, see \\cite{rodriguez2012graph} and \\cite{rodriguez2010constructions}. Here, nodes and edges form a heterogeneous set. Nodes and edges can be identified by using a single or multiple labels, for example using $\\lambda:E\\rightarrow \\Sigma$, where $\\Sigma$ denotes a set of labels. We need to mention that both concepts are equivalent, since graph databases use the concept of labeled property graphs.\n\nHere, our experimental setting is -- without loss of generality -- settled in social network analysis (SNA). It is quite obvious that a social network containing actors may easily be extended with other data, for example spacial data (e.g. locations, rooms, towns, countries), or social groups (e.g. companies, clubs), or any other information (e.g. information data about actors). \nOnce a social network is built, we may start to ask questions like ``How many friends does actor $X$ have?'' or ``To how many groups does actor $Y$ belong?''. The mathematical formulation of these questions would be ``What is the degree of node $X$?'' and ``How many communities $C_i$ can be found such that $Y\\in C_i$?''.  The mathematical foundations in this and the following sections are based on  the works of \\cite{diestel2012graphentheorie} and  \\cite{matouvsek2007diskrete} unless otherwise noted.\n\nIn general, we define a \\emph{Graph} $G=(V,E)$ with a set of edges or vertices $V$ -- these are actors, locations or any other nodes in the network -- and edges $E$, which describe the relations between nodes. The number of nodes $|V|$ is usually denoted with $n$. Given two nodes $s=$Simon and $j=$Jerusalem we may add an edge or relation $(s,j)$ between both describing for example, that Simon is or was in Jerusalem. Then we say $s$ and $j$ are \\emph{connected} or they are \\emph{neighbors}. The \\emph{neighborhood} of a vertice $v$ is denoted with $N(v)$ and describes all nodes connected to $v$. If we are interested in the size of this neighborhood we calculate the node \\emph{degree} given by $deg(v)=|N(v)|$. \n\nThe neighborhood thus gives information about the connectedness of an actor in the network. This can be useful to illustrate the direct influence of an actor within the complete network, especially for actors with a high node degree. But it is obvious that the amount of relations does not necessarily give a good idea on their quality or how we could use these relations. While the node degree is often used as a measure to create random graphs, it is in general not a good measure in order to analyze particular actors in networks, see \\cite{Jackson2010}. \n\nNevertheless, the \\emph{degree centrality} for a node $v\\in V$ is given by\n\\[dc(v)=\\frac{deg(v)}{n-1}\\]\nThe output value ranges between 0 and 1 and gives a reference to the direct connections. As discussed, it omits all indirect relations and in particular the node's position in the network.\n\n\\begin{definition}[Scale-Free Network]\nA network is scale-free if the fraction of nodes with degree $ k $ follows a power law $k^{-\\alpha}$, where $\\alpha > 1$. \n\\end{definition}\n\\begin{definition}[Small World Network \\cite{watts1999networks}]\nLet $G=(V,E)$ be a connected graph with $n$ nodes and average node degree $k$. \nThen $G$ is a small-world network if $k\\ll n$ and $k\\gg 1$.\n\\end{definition}\n\nIn any case, the \\emph{degree distribution} provides us with information about the network structure since we can distinguish between sparsely and densely connected networks. While \\cite{Jackson2010} suggests statistical analysis to compute the correlation between attributes of the network and the density of nodes, this will not work for the small networks and the missing statistical values. In any case, although scale-free networks are not an universal characteristic for real-world networks, we might use this approach to get a first overview about the network itself. Random graphs, like the Erdős–Rényi networks, follow a Poisson distribution. Scale-free networks, inspired by real-world social networks, follow a power law. \nSee Figure \\ref{abb:exl:dist12} for two examples of a random graph and a more common distribution in real word networks.\n\n\\begin{figure}[t]\n\\centering\n\\includegraphics[width=0.45\\textwidth ]{dist1.pdf} \\quad\n\\includegraphics[width=0.45\\textwidth ]{dist2.pdf}\n\\caption{Top: In random networks the degree distribution follows a given random distribution. Here, most nodes are average linked and an equal number of nodes is lowly and highly linked. Bottom: Real networks often follow other or even no standard random distribution. Here, a scale-free distribution is shown: Most nodes are lowly linked whereas only very few notes are highly linked.}\\label{abb:exl:dist12}\n\\end{figure}\n\nWe will now discuss one more property to evaluate nodes and their position in the networks. \nThese properties can be used to calculate statistical parameters, so-called \\emph{centrality measures}, cf. \\cite{freeman1978centrality} and \\cite{carrington2005models}. They answer the question ``Which nodes in this network are particularly significant or important?''.\n\n\\emph{Betweenness} analyzes critical connections between nodes and thus gives an indication of individuals that can change the flow of information in a network. This measure is based on paths in a network:\n\n\\begin{quote}\nMuch of the interest in networked relationships comes from the fact that individual\nnodes benefit (or suffer) from indirect relationships. Friends might provide access\nto favors from their friends, and information might spread through the links of\na network.\\cite{Jackson2010}\n\\end{quote}\nA \\emph{path} $p$  in a graph $G=(V,E)$ is a set of vertices $v_1,...,v_t$, $t \\in \\mathbb{N}$, for example written as\n\\[p=[v_1,...,v_t],\\] \nwhere $(v_i,v_{i+1})\\in E$ for $i\\in\\{1,\\ldots,t-1\\}$. \nThe length $|p|$ of the path $p$ is the total number of edges -- not nodes. Thus $|p|=t-1$. \nThe path $p$ links the starting node $v_1$ and an ending node $v_t$. \nIn a path, no crossings are allowed, thus $v_i\\neq v_j$ for all $i,j\\in \\{1,...,t\\}$. \nIf all properties of a path are met except that the beginning and the end vertex are the same -- that is, $v_1 = v_t$ -- \nwe denote this set as a \\textit{circle}.\n\n\\emph{Betweenness centrality} was first introduced by \\cite{freeman1977set}\\footnote{Initially introduced for symmetric relations -- undirected graphs -- it was extended to asymetric relations -- directed graphs -- by \\cite{white1994betweenness}.} and considers other indirect connections, see \\cite{schweizer1996muster}. Given a node $v$, it calculates all shortest paths in a network $P_v(k,j)$ for all beginning and ending nodes $k,j\\in V$ that pass through $v$. If $P(k,j)$ denotes the total number of paths between $k$ and $j$, the importance of $v$ is given by the ratio of both values. Thus the betweenness centrality according to \\cite{Jackson2010} is given by\n\n\\[bc(v)= \\sum_{k\\neq j, v\\neq k, v \\neq j} \\frac{P_v(k,j)}{P(k,j)} \\cdot \\frac{2}{(n-1)(n-2)},\\] \n\nwhere $ n $ denotes the number of the vertices in the graph. \nThis parameter allows an analysis of the critical links and how often a node lies on such a path. This centrality measure thus answers the questions whether a node can change the flow of information in a network or whether it is a bridge between other nodes, see \\cite{schweizer1996muster}.\n\nWhile betweenness assumes network flows to be like packages flowing from a starting point to a destination, other measures consider multiple paths: For example, the so-called \\emph{eigenvector centrality} -- introduced by \\cite{bonacich1972factoring} -- measures the location of directly neighboring nodes in the network. For the \neigenvector centrality, we ``count walks, which assume that trajectories can not only be circuitous, but also revisit nodes and lines multiple times along the way.''\\cite{borgatti2005centrality} This measure not only classifies the direct possibility to influence neighbors, but also ranks the indirect possibility to influence the whole network. For a detailed mathematical background we refer to~\\cite{Jackson2010}.\n\nLess popular measures are Katz prestige, and Bonacich’s measure, see \\cite{Jackson2010}. It has been shown that these measures are closely related, see \\cite{ditsworth2019community}.\n\n\\section{Method}\n\n\\begin{figure}[t] %\n\t\\centering\n\t\\includegraphics[width=0.49\\textwidth]{sf.png}\n\t\\caption{Frequency of nodes with a given degree for three random Scale-Free Networks with $n=150$ nodes. }\n\t\\label{img:fd1}\n\\end{figure}\n\nWe evaluate the degree centrality and betweenness centrality on random graphs. First, we consider Scale-Free Networks with $n$ nodes, \nsee~\\cite{Jackson2010}. Moreover, \\cite{bollobas2003directed} introduced a widely used graph model with \nthree random parameters $\\alpha+\\beta+\\gamma=1$. \nThese values define probabilities and thus define attachment rules to add new vertices between either existing or new nodes. This model allows loops and multiple edges, where a loop denotes one edge where the endvertices are identical, and multiple edges denote a finite number of edges \nthat share the same endvertices. Thus, we convert the random graphs to undirected graphs. For testing purpose, we scale the number of nodes $n$ and use \n$\\alpha=0.41$, $\\beta=0.54$, and $\\gamma=0.05$.\nWe chose this random graph model since it is generic and feasible for computer simulations for measuring and evaluation purposes, \nsee~\\cite{bollobas2003mathematical,kivela2014multilayer}. \n\nFigure \\ref{img:fd1} shows the frequency of nodes (y-axis) with a particular degree (x-axis) for three random networks with $n=150$ nodes. \nCompared to Figure~\\ref{img:fd1}, Figure~\\ref{abb:exl:dist12} clearly shows the scale-free distribution, in which many nodes have a small degree and only few \nnodes have a very large degree: most nodes are hence lowly linked. Thus these small-degree nodes lead to a few communities which are highly connected.\n\n\\begin{figure}[t] %\n\t\\centering\n\t\\includegraphics[width=0.49\\textwidth]{nsw.png}\n\t\\caption{Frequency of nodes with a given degree for three Newman-Watts-Strogatz small-world random graph with $n=500$ nodes. }\n\t\\label{img:fd2}\n\\end{figure}\n\nThe second random graph uses a fixed degree distribution and is widely known as Newman-Watts-Strogatz small-world random graph \\cite{NEWMAN1999341}. The algorithm to create such as graph takes a number of nodes $n$, the number of $k$ nearest neighbors that form a ring topology and the probability  $p$ for adding a new edge. A small-world graph contains only small average paths and thus has a small diameter, see \\cite{Jackson2010}. Some studies like \\cite{aarstad2013ways} study the relation between scale-free and small-world networks, in particular the relationship between the average path length and local clusterings. In general, it is possible to generate scale-free networks with small-world attributes, see \\cite{klemm2002growing}.\n\nFigure~\\ref{img:fd2} shows the frequency of nodes with a given degree for three random networks with $n=500$ nodes. Compared to Figure~\\ref{abb:exl:dist12}, \nFigure~\\ref{img:fd2} clearly shows the Poisson distribution with many nodes having an average degree. Together with Figure~\\ref{img:fd1} it also illustrates the ``long tail'' of the scale-free distribution, see \\cite{Jackson2010}. \n\nWe will now evaluate how graph structures and in particular measures change when additional information are stored in extra layers. \nWe partition a graph into an uncolored part that contains the `original' data and into a part with blue nodes in which novel `extra' data stored. \nThese blue nodes simulate one or more new layers in the knowledge graph.\nThus, given a random graph $G=(V,E)$, a next step comprises a probability $p_b$ for blue nodes which leads to a graph $G$ with blue nodes $B\\subset V$. \nFirst, we compute the centrality measures for all nodes in $G_B = (V\\setminus B, E)$ and then for all nodes in $G$ but limit the output to all nodes in $B$. \nThus, we have two vectors $c_1, c_2\\in \\mathbb{R}^n$ where $n$ is the number of nodes in $V\\setminus B$. \nWe denote $c_i$ by $c_i = \\left( c_i^1, c_i^2, c_i^3, ...\\right)$.\n \nWhile comparing two vectors, we are interested in two values. \nThe first one is the total number of misordered elements, that is, \nthe total number of positions on which the elements differ from each other. \nThe second value that we compute in order to compare two vectors \nis the number of moved elements. \nFor this we count those elements that have a different predecessor and / or successor in the first vector compared to the second one.   \n\n\\begin{exl}\\label{ex:errormeasures}\nLet $c_1 = [1,2,3,4,5]$, $c_2=[5,3,2,1,4]$ and $c_3=[1,5,2,3,4]$. If $c_1$ is the original ordering, we see that $c_2$ has a totally different order. In $c_3$ the entry $5$ is moved, but the rest of the list is unchanged, although still 4 elements are on the wrong location. Hence, the number of misordered elements in $c_1$ compared to $c_2$ is 5. The number of moved elements is 5 and 1. %\n\\end{exl}\nTo identify both errors, we first define function $e$:\n\n\\[e(i,c_1, c_2)=\\begin{cases}\n    0 & c_{1}^{i}=c_{2}^{i}\\\\\n    1 & c_{1}^{i}\\neq c_{2}^{i}\n\\end{cases}\\]\n\nThat is, $e(i,j,c_1,c_2)=1$ if the element on the $i$th position of $c_1$ \ndiffers from the element on the $j$th position in $c_2$. \nTo shorten notation, we write $e(i,c_1,c_2)$ whenever $i=j$. \n\nLet $x$ be an element contained in every $c_u$, $u \\in \\mathbb{N}$. %\nThen $ p(x,c_u) $ denotes the predecessor of element $ x $ in $c_u$ \nand $s(x,c_u)$ denotes the successor of $x$ in $c_u$.  \nIf $x$ is the first element in $c_u$, then $p(x,c_u)=\\emptyset$. \nIf $x$ is the last element of $c_u$, then $s(x,c_u)=\\emptyset$. \nWith these definitions, \nwe define $e_N$: \n\n\\[e_N(x,c_1, c_2)=\\begin{cases}\n    1 \t& \\text{if } p(x,c_1)=\\emptyset \\text{ and } s(x,c_1) \\not = s(x,c_2),\\\\\n        & \\text{or } s(x,c_1)=\\emptyset \\text{ and } p(x,c_1) \\not = p(x,c_2),\\\\\n        & \\text{or } s(x,c_1) \\not = s(x,c_2) \\text{ and } p(x,c_1) \\not = p(x,c_2),\\\\\n    1/2\t& \\text{if } s(x,c_1) \\not = s(x,c_2) \\text{ and } p(x,c_1) = p(x,c_2),\\\\\n        & \\text{or } s(x,c_1) = s(x,c_2) \\text{ and } p(x,c_1) \\not = p(x,c_2),\\\\\n    0\t& otherwise. \n\\end{cases}\\]\n\nIn other words, \nwe consider the predecessor of an element in $c_1$ and \ncheck if this element is still a predecessor of this element in $c_2$, \nand analyse analoguously the successor of an element. \n\nWith this, we define two error measures $\\epsilon$ and $\\epsilon_N$:\n\n\\[\\epsilon(c_1, c_2)= \\sum_{i=1}^n e(i,c_1, c_2)\\]\n\n\\[\\epsilon_N(c_1, c_2)= \\sum_{x \\in c_1} e_N(x,c_1, c_2)\\]\n\n\\begin{exl}\n\tLet's reconsider Example~\\ref{ex:errormeasures}: \n\tRecall that $c_1 = [1,2,3,4,5]$, $c_2=[5,3,2,1,4]$ and $c_3=[1,5,2,3,4]$. \n\tThen, $\\epsilon(c_1,c_2)=5 \\text{ and } \\epsilon_{N}(c_1,c_2)=5.$  \n\tMoreover, $\\epsilon(c_1,c_3)=4$ and \n\t$\\epsilon_{N}(c_1,c_3)=2.5$.\n\\end{exl}\n\nWe will now analyze different scenarios to evaluate the impact of additional blue nodes on a scale-free and a small-world network.\n\n\\section{Results}\n\n\\subsection{Degree Centrality}\n\nThe Degree Centrality was evaluated with errors $\\epsilon$ and $\\epsilon_N$ for scale-free random graphs ($n=150$, $n=300$ and $n=500$, see Figure \\ref{img:dc-error-1}) and Newman-Watts-Strogatz small-world random graphs ($n=150$, $k\\in\\{4,8,50\\}$, see Figure \\ref{img:dc-error-2}). The mean values are given in Table \\ref{tab:1}.\n\n\\begin{figure*}[t] %\n\t\\centering\n\t\\includegraphics[width=0.69\\textwidth]{plot2.pdf}\n\t\\caption{Degree Centrality errors for scale-free random graphs ($n=150$, $n=300$ and $n=500$) for different values of $p_B$ between 0 and~0.3. }\n\n\t\\label{img:dc-error-1}\n\n\t\\centering\n\t\\includegraphics[width=0.69\\textwidth]{plot3.pdf}\n\t\\caption{Degree Centrality errors for Newman-Watts-Strogatz small-world random graph ($n=150$, $k\\in\\{4,8,50\\}$) for different values of $p_B$ between 0 and~0.3. }\n\n\t\\label{img:dc-error-2}\n\\end{figure*}\n\n\\begin{table}\n\\centering\n\\begin{tabular}{|c|c|c|c|c|c|c|}\n\\hline \n & $\\epsilon$ & $\\epsilon_{N}$ & $\\epsilon$ & $\\epsilon_{N}$ & $\\epsilon$ & $\\epsilon_{N}$\\tabularnewline\n\\hline \nScale-Free & \\multicolumn{2}{c|}{$n=150$} & \\multicolumn{2}{c|}{$n=300$} & \\multicolumn{2}{c|}{$n=500$}\\tabularnewline\n\\hline \nMean & 0.95 & 0.46 & 0.97 & 0.47 & 0.98 & 0.48\\tabularnewline\n\\hline \nSmall-World & \\multicolumn{2}{c|}{$k=4$} & \\multicolumn{2}{c|}{$k=8$} & \\multicolumn{2}{c|}{$k=50$}\\tabularnewline\n\\hline \nMean & 0.97 & 0.97 & 0.97 & 0.96 & 0.95 & 0.96\\tabularnewline\n\\hline \n\\end{tabular}\n\\vspace*{.1cm}\n\\caption{Mean values for Degree Centrality errors.}\\label{tab:1}\n\\end{table}\nHere, we see that the Small-World graph has a very high error rate for both $\\epsilon$ and $\\epsilon_N$ even for small $p_B$. In particular, the values are rather constant, no matter what value was chosen. In addition, the graph topology for different values of $k$ has only very little impact on the error rate. Thus, even small changes in the graph structure (a very small value for $p_B$) have a great impact on the degree centrality. Since Small-World graphs have a high level of local clustering, the random exclusion of blue nodes will most likely effect not only one cluster, but also other clusters. This changes not only the position, but also the ordering of node degrees. \n\nA different scenario occurs when considering Scale-Free graphs. Again we see a very high error rate for $\\epsilon$, even for small $p_B$. The values for $\\epsilon_N$ are usually near to $.5$ (mean values 0.46, 0.47, 0.48). Neither the graph size $n$ nor the value for $p_B$ has an impact on these errors. Here, we see the scale-free distribution: the blue nodes do change the position of the degree centrality, but while they also change the ordering within clusters, they do not affect the complete ordering due to the longer distance between nodes.\n\n\\subsection{Betweenness Centrality}\n\nThe Betweenness Centrality was evaluated with errors $\\epsilon$ and $\\epsilon_N$ for scale-free random graphs ($n=150$, $n=300$ and $n=500$, see Figure \\ref{img:bc-error-1}) and Newman-Watts-Strogatz small-world random graphs ($n=150$, $k\\in\\{4,8,50\\}$, see Figure \\ref{img:bc-error-2}). The mean values are given in Table \\ref{tab:2}.\n\n\\begin{figure*}[t] %\n\t\\centering\n\t\\includegraphics[width=0.69\\textwidth]{plot1.pdf}\n\t\\caption{Betweenness Centrality errors for scale-free random graphs ($n=150$, $n=300$ and $n=500$) for different values of $p_B$ between 0 and 0.3. }\n\n\t\\label{img:bc-error-1}\n\n\t\\centering\n\t\\includegraphics[width=0.69\\textwidth]{plot4.pdf}\n\t\\caption{Betweenness Centrality errors for Newman-Watts-Strogatz small-world random graph ($n=150$, $k\\in\\{4,8,50\\}$) for different values of $p_B$ between 0 and 0.3. }\n\n\t\\label{img:bc-error-2}\n\\end{figure*}\n\n\\begin{table}\n\\centering\n\\begin{tabular}{|c|c|c|c|c|c|c|}\n\\hline \n & $\\epsilon$ & $\\epsilon_{N}$ & $\\epsilon$ & $\\epsilon_{N}$ & $\\epsilon$ & $\\epsilon_{N}$\\tabularnewline\n\\hline \nScale-Free & \\multicolumn{2}{c|}{$n=150$} & \\multicolumn{2}{c|}{$n=300$} & \\multicolumn{2}{c|}{$n=500$}\\tabularnewline\n\\hline \nMean & 0.77 & 0.23 & 0.87 & 0.27 & 0.91 & 0.29\\tabularnewline\n\\hline \nSmall-World & \\multicolumn{2}{c|}{$k=4$} & \\multicolumn{2}{c|}{$k=8$} & \\multicolumn{2}{c|}{$k=50$}\\tabularnewline\n\\hline \nMean & 0.94 & 0.92 & 0.94 & 0.92 & 0.94 & 0.93\\tabularnewline\n\\hline \n\\end{tabular}\n\\vspace*{.1cm}\n\\caption{Mean values for Betweenness Centrality errors.}\\label{tab:2}\n\\end{table}\n\nBetweenness centrality (see Figure \\ref{img:bc-error-1}) in scale-free graphs is very much influenced by the choice for $p_B$. Again, the total error $\\epsilon$ becomes very high although there are several outliers. More interesting is again the ordering error $\\epsilon_N$: although the error increases with a rising value of $p_B$, it remains very low. Again, the number of nodes $n$ has only very little impact on the error measures. \n\nHere, again, the Small-World graph has a very high error rate for both $\\epsilon$ and $\\epsilon_N$ although not for very small $p_B$, see Figure \\ref{img:bc-error-2}. \nIn particular, we may find a boundary $p'_B$ so that the values are rather constant for $p_B>p'_B$. Again, the graph topology for different values of $k$ has only very little impact on the error rate. Thus, even small changes in the graph structure (a very small value for $p_B$) have a great impact on the betweenness centrality. Thus, the random choice of blue nodes again destroys the structures of local clustering which will most likely effect not only one cluster, but also other clusters. \n\n\\section{Discussion and Outlook}\n\nThis paper investigates the impact of a multiple layers on centrality measures compared to single-purpose graph. We presented an experimental environment to evaluate two different centrality measures -- degree and betweenness centrality -- on random graphs inspired by social network analysis: small-world and scale-free networks. The result clearly shows  that the graph structures and topology have a great impact on its robustness for additional data stored. In particular, we could identify nodes with a high node degree and closely connected communities or clusters as problematic for reordering the centrality measures. Thus, we could show that small-world networks are rather less robust than scale-free networks. \n\nAlthough the experimental analysis of random graphs allows us to make some basic observations we could also present some very preliminary error approximations. %\nWe need to mention that a lot of research needs to be done in this field, because we only considered degree and betweenness centrality. \nIn particular, we can identify the following questions for further research: Is it possible to find good error approximations for larger sets of blue nodes $B$? How do $\\epsilon$ and $\\epsilon_N$ behave on any given node $v\\in B\\subset V$ with a node degree $d(v)=m$? What are (other) graph structures that have a great impact on the stability of networks for degree, betweenness and other centralities? \n\nTo sum up, it is valid %\nto extend single-purpose networks with data from other sources. In particular, we considered random social networks as a basis. Thus, extending social networks with other information layers is possible, although it will change the behavior of measurements like network centrality. The effect highly depends on the given graph structure. More interdisciplinary research is needed to investigate the impact on real-world data within the context of humanities.\n\n\\end{document}\n</paper 2>\n\n<paper 3>\n\\title{TWIG: Towards pre-hoc Hyperparameter Optimisation and Cross-Graph Generalisation via Simulated KGE Models}\n\n\\begin{document}\n\n\\title{TWIG: Towards pre-hoc Hyperparameter Optimisation and Cross-Graph Generalisation via Simulated KGE Models}\n\n\\author{\\IEEEauthorblockN{1\\textsuperscript{st} Jeffrey Sardina}\n\\IEEEauthorblockA{\\textit{School of Computer Science and Statistics} \\\\\n\\textit{Trinity College Dublin}\\\\\nDublin, Ireland \\\\\n0000-0003-0654-2938}\n\\and\n\\IEEEauthorblockN{2\\textsuperscript{nd} John D. Kelleher}\n\\IEEEauthorblockA{\\textit{School of Computer Science and Statistics} \\\\\n\\textit{Trinity College Dublin}\\\\\nDublin, Ireland \\\\\n0000-0001-6462-3248}\n\\and\n\\IEEEauthorblockN{3\\textsuperscript{rd} Declan O'Sullivan}\n\\IEEEauthorblockA{\\textit{School of Computer Science and Statistics} \\\\\n\\textit{Trinity College Dublin}\\\\\nDublin, Ireland \\\\\n0000-0003-1090-3548}\n}\n\n\\maketitle\n\n\\begin{abstract}\nKnowledge Graphs (KGs) have become ever-more important for modelling biomedical information, as their intrinsic graph structure matches the structure of many biological interaction networks. Together with KGs, Knowledge Graph Embeddings (KGEs) have shown immense potential to learn biological data and predict new, in-band facts about the data the KG describes. However, recent literature has suggested several major deficits to KGEs: that they have an extremely short `receptive field' of data they use to make predictions and that their learning is guided by memorising graph structure, not learning latent semantics. Moreover, while several studies have suggested that graph structure and KGE model choice affect optimal hyperparameters, the exact relationship of hyperparameters to learning remains unknown and is instead solved using a computationally intensive hyperparameter search.\n\nIn this paper we introduce TWIG (Topologically-Weighted Intelligence Generation), a novel, embedding-free paradigm for simulating the output of KGEs that uses a tiny fraction of the parameters. TWIG learns weights from inputs that consist of topological features of the graph data, with no coding for latent representations of entities or edges. Our experiments on the UMLS dataset show that a single TWIG neural network can predict the results of state-of-the-art ComplEx-N3 KGE model nearly exactly on across all hyperparameter configurations. To do this it uses a total of 2590 learnable parameters, but accurately predicts the results of 1215 different hyperparameter combinations with a combined cost of 29,322,000 parameters. Based on these results, we make two claims: 1) that KGEs do not learn latent semantics, but only latent representations of structural patterns; 2) that hyperparameter choice in KGEs is a deterministic function of the KGE model and graph structure. We further hypothesise that, as TWIG can simulate KGEs without embeddings, that node and edge embeddings are not needed to learn to accurately predict new facts in KGs. Finally, we formulate all of our findings under the umbrella of the ``Structural Generalisation Hypothesis\", which suggests that ``twiggy\" embedding-free / data-structure-based learning methods can allow a single neural network to simulate KGE performance, and perhaps solve the Link Prediction task, across many KGs from diverse domains and with different semantics.\n\\end{abstract}\n\n\\begin{IEEEkeywords}\nknowledge graph embeddings, knowledge graphs, parameter reduction, generalisation, simulation\n\\end{IEEEkeywords}\n\n\\section{Introduction}\nKnowledge Graphs (KGs) are graph-based data stores in which all data is expressed as a series of labelled nodes connected by a set of labelled edges; every set of a ``subject\" (or head) node $s$, a ``predicate\" edge $p$, and an ``object\" (or tail) node $o$ is called an $(s,p,o)$ triple \\cite{kg-ovewview}. The ability to represent data as triples in a graphical form has become particularly useful in the domains of bioinformatics and computational biology, where massive biological and biomedical datasets can be directly and intuitively represented as a network of relations and interactions \\cite{bio2rdf,umls,biokg,ckg,drkg,ogb,PharmKG,OpenBioLink}. However, despite the power of this graph-based format, much of the data far exceeds the size that can be easily analysed by humans without the use of computational tools. The domain of Knowledge Graph Embeddings aims to address this gap by producing low-dimension embeddings of nodes and edges in a graph that can be used to both summarise the graph data and predict new links \\cite{kge-survey,rml-review,kge-completion-rev,kg-ovewview}.\n\nSpecifically, all KGE models are trained to solve the Link Prediction (LP) Task, which consists of answering queries in the form $(s,p,?)$ or $(?,p,o)$, where $?$ represents the subject or object to be predicted \\cite{kge-survey,rml-review,kge-completion-rev,kg-ovewview}. It does this by learning embeddings for each node and edge that can be used to assign a plausibility score to every statement $(s,p,o)$ that should be high if $(s,p,o)$ occurs in the KG, and low if it does not \\cite{light-into-the-dark,kge-survey,rml-review,kge-completion-rev,kg-ovewview}. In other words, KGEs are trained to summarise the information contained in a KG in low-dimensional latent space in a way that distinguishes true facts from false statements \\cite{kge-survey,rml-review,kge-completion-rev,kg-ovewview}.\n\nThe literature around KGE models generally attributes ``latent semantics\" to the learned embeddings -- it assumes that the learned features represent a higher level of conceptual knowledge about the graph \\cite{kge-survey,rml-review,kge-completion-rev}. The underlying assumption in this presentation of KGE methods, which has remained largely unquestioned, is the assumption that KGEs have learned a higher-order semantic representation of the knowledge graph that necessarily extends beyond what could be learned by simply memorising common graph structures to replicate \\cite{kge-survey,rml-review,kge-completion-rev}. \n\nSimilarly, with the partial exception of some recent works targeted at specific parts of KGE model construction (see \\cite{neg-samp-analysis,loss-func-analysis,old-dog-new-tricks}), established KGE literature assumes that hyperparameter searching is necessary to determine at least some optimal model settings \\cite{light-into-the-dark}. Moreover, there is no established hypothesis that optimal hyperparameters can be predicted in a pre-hoc manner before running a full search \\cite{kge-survey,rml-review,kge-completion-rev,kg-ovewview}. This means, that, to date, essentially all hyperparameter selection is performed using some manner of hyperparameter search over a large range of possible combinations.\n\nWe summarise the above as three core assumptions that existing KGE literature makes:\n\\begin{enumerate}\n  \\item \\textbf{The Embedding Assumption}: that embeddings are necessary to solve, or at least best suited to solving, the Link Prediction task,\n  \\item \\textbf{The Latent Semantics Assumption}: that KGE models learn embedding semantics representing higher order conceptual knowledge, which they then apply to make predictions on KG data,\n  \\item \\textbf{The Hyperparameter Stochasticity Assumption}: that hyperparameters must be explicitly searched for, and particularly that optimal hyperparameters cannot be predicted in a pre-hoc manner.\n\\end{enumerate}\n\nWe highlight that no study known to the authors, save \\cite{hp-struct-basis} alone, has specifically questioned the validity of these assumptions on modern KGE models and KG learning approaches. Reference \\cite{hp-struct-basis} is notable for explicitly questioning Hyperparameter Stochasticity Assumption, and hypothesising that optimal hyperparameters are a deterministic function of global KG structure.\n\nIn this work, we produce a new analytic paradigm to analyse all three of these core assumptions in the context of KG learning. The core contribution of our work is a novel Neural Network (NN) called TWIG (Topologically-Weighted Intelligence Generation) that is able to:\n\\begin{enumerate}\n  \\item simulate the output of KGE models in terms of both the ranked list predictions and the overall predictive performance,\n  \\item perform this prediction using only graph structure and hyperparameter settings as input features; notably using no node or edge embeddings of any form,\n  \\item perform these predictions over the entire grid of searched hyperparameters with a single TWIG model, thereby achieving dramatic reduction in parameter use and computational and memory cost.\n\\end{enumerate}\n\nWe perform all of our experiments on the state-of-the-art ComplEx-N3 model \\cite{complex-n3} and the biological UMLS dataset \\cite{umls}, a dataset that despite its small size sees consistent and important use in the biomedical domain \\cite{light-into-the-dark}. While our analysis at the moment is limited by the use of a single model and dataset for our analysis, our novel TWIG model shows remarkably strong results in simulating the output of KGEs across all hyperparameter settings. We therefore postulate that further work in this area will be of immediate and direct benefit. We expect that such further work will deepen our understanding of the mechanisms by which KGEs work, expand our knowledge of KG structure-hyperparameter relations, and enable dramatic reductions in parameter use.\n\nFurthermore, the existence of a high-performance neural network such as TWIG that can replicate the results of KGEs while only using global features consisting of hyperparameter configurations and graph structure provides strong initial evidence of three core hypotheses, which are the major theoretical results of this work. These hypotheses are as follows: \n\\begin{enumerate}\n  \\item The Structural Learning Hypothesis: That KGEs do not learn latent semantics in embeddings, but rather only learn to implicitly summarize graph structure,\n  \\item The Hyperparameter Determinism Hypothesis: That optimal hyperparameter choice is a deterministic function of graph structure and the KGE model being used.\n  \\item The TWIG Hypothesis: That node / relationship embeddings are not necessarily needed to solve the Link Prediction (LP) task, but instead that learnable parameters could all be part of a single NN.\n\\end{enumerate}\n\nWe are able to provide initial evidence for all of these hypotheses for the ComplEx-N3 model and the UMLS dataset, and we propose that they will hold across other KGE models and KG datasets. We note, however, that while TWIG can simulate the output of KGEs, it is not currently able to solve the Link Prediction Task; as a result, there is less direct evidence for the TWIG Hypothesis as compared to the Structural Learning and Hyperparameter Determinism Hypotheses. Further exploration of these hypotheses is left to future work.\n\nWe further use the above hypotheses, and the graph-agnostic properties of TWIG, to propose \\textbf{The Structural Generalisation Hypothesis}. This hypothesis states that since simulated learning methods such as TWIG allow prediction of the outputs of KGEs without using embeddings, that these simulated learning methods can be extended to allow generalised learning of graphs across KGs. While we are unable to fully test and evaluate this hypothesis in this work, existing literature taken in tandem with our empirical results provides strong initial support at the theoretical level.\n\nThe remainder of this paper is structured as follows. Section 2 provides an overview of related works in the literature. Section 3 provides basic preliminaries and formal hypothesis formulations needed to robustly present our methods and results. Section 4 presents the methods for all of our experiments, and forms the bulk of our paper. Section 5 presents our results and discusses them in the context of the existing state-of-the-art. Finally, Section 6 concludes the paper, discusses the limitations of this work, and outlines the major future directions that remain open.\n\nAll code and datasets needed to reproduce the experiments in this paper are included at the link \\url{https://github.com/Jeffrey-Sardina/TWIG-release-1.0.git}.\n\n\\section{Related Works}\nTo the extent of the knowledge of the authors, no techniques currently exist that allow embedding-free learning of Knowledge Graphs nor embedding-free simulation of KGE models. Knowledge Graph Embeddings are by definition embedding-based \\cite{rml-review,kge-survey,kge-completion-rev,kg-ovewview}; existing GNN approaches such as GCN, GraphSage, CensNet, IDGL, and many others all create embedding vectors for nodes / edges \\cite{censnet,idgl,gnn-overview}. Similarly, only one work known to the authors (\\cite{hp-struct-basis}) has attempted to explicitly and methodologically question the Hyperparameter Stochasticity Assumption, suggesting that hyperparameter choice is in fact a deterministic function of graph structure. No work known to the authors questions either the Embedding Assumption or the Latent Semantics Assumption.\n\nSome work has been done in creating sub-node embeddings for KGEs, which results in a significant reduction of memory needed to run KGEs. This is exemplified in the recent NodePiece model, which uses anchor nodes and edges to tokenise embeddings for all other nodes and edges \\cite{nodepiece}. However, NodePiece remains an embedding-based method, with explicit embeddings for all anchors and implicit (tokenised) embeddings for all non-anchor nodes and edges \\cite{nodepiece}.\n\nThere has been some previous work in determining the relationship between optimal hyperparameters, KGE model choice, and graph structure \\cite{light-into-the-dark,old-dog-new-tricks,neg-samp-analysis,loss-func-analysis,kges-for-lp-compare}. In particular, \\cite{neg-samp-analysis} analysed optimal negative sampler choice for KGE models in terms of KGE model choice and graph structure. Reference \\cite{loss-func-analysis} found similar relations for optimal loss function choice, and \\cite{kges-for-lp-compare} analysed optimal KGE model choice for a given dataset. Two substantially broader studies \\cite{light-into-the-dark,old-dog-new-tricks} documented overall KGE model performance on a large variety of datasets; however, neither of these specifically analysed the impact of individual hyperparameters as a function of graph structure.\n\n\\section{Preliminaries}\n\\subsection{Literature Definitions}\n\\textbf{Knowledge Graphs.} A Knowledge Graph, $G = \\{E, R\\}$ is set of entities $E$ and a set of directed, labelled relations $R$ \\cite{kg-ovewview}. Each statement in a Knowledge Graph is the 3-element triple consisting of a subject, a predicate, and an object; this is written $(s, p, o)$, where $s \\in E, p \\in R, o \\in E$.\n\n\\textbf{Knowledge Graph Embedding.} Knowledge Graph Embedding (KGE) models convert a KG's nodes and edges to vector embeddings \\cite{rml-review,kge-survey,kge-completion-rev,kg-ovewview}. Formally, this process can be defined as $(s, p, o) \\rightarrow (e_s, e_p. e_o)$ where $s$, $p$, and $o$ represent the subject, predicate, and object in a triples and $e_s$, $e_p$, and $e_o$ their respective embeddings; $g$ and $e_g$ are defined analogously in the case that named graphs are embedded.\n\n\\textbf{Link Prediction Task.} The Link Prediction (LP) Task is to answer queries $(?, p, o)$ and/or $(s, p, ?)$ where $s \\in E, p \\in R, o \\in E$ and $?$ is the entity being predicted to complete the query triple \\cite{rml-review,kge-survey,kge-completion-rev,kg-ovewview}. KGE models solve this by learning to maximise the difference between the scores of `positive' triples observed in training and randomly generated (`negative') triples not in the training dataset, according to a model-specific scoring function \\cite{kge-survey,rml-review,kge-completion-rev,neg-samp-analysis}.\n\n\\textbf{KGE model.} A KGE model is an embedding-based model that solves the Link Prediction task. The output of these models is a rank-ordered list $l_E$ of all nodes $E$ that could answer the LP query $(?, p, o)$ or $(s, p, ?)$. $l_E$ is ordered such that nodes with the lowest rank (i.e. the rank closest to 1) are considered the best answers, and nodes with higher rank are considered less probable answers. As such, KGE models can be described as embedding based models that learn to rank.\n\n\\textbf{Mean Reciprocal Rank.} Given a ranked list of true triples versus all possible generated negatives (formed by randomly corrupting the subject or object) the Mean Reciprocal Rank (MRR) metric takes the mean of the reciprocal of all the ranks of the known true triples as a performance score. It is necessarily bounded on (0, 1], with higher values indicating better performance.\n\n\\subsection{Problem Specification}\nKGE models learn to minimise the rank of known-true triples and maximise that of all other triples \\cite{kge-survey,rml-review,kge-completion-rev,neg-samp-analysis}. The result of this is graph-specific embeddings -- the embedding found using one KGE model for one dataset cannot be applied directly to any other dataset \\cite{kge-survey,rml-review,kge-completion-rev,kg-ovewview}.\n\nWhile this approach has been successful -- being the universal foundation for all KGE methods known to the authors to-date \\cite{kge-survey,rml-review,kge-completion-rev,kg-ovewview,light-into-the-dark,old-dog-new-tricks} -- we propose an embedding-free learning paradigm that simulates the output of the link prediction task by learning to predict all ranks output by an existing KGE method. In doing this, we restrict our inputs to two types: local structural features of the query triple being predicted, and hyperparameters used by the original KGE model to learn that triple.\n\nAs such, this approach necessarily is about replicating KGE model behaviour using only structure and model settings, not latent features or any sort of graph semantics or logic. In other words, this is a \\textit{simulation} procedure, and we refer to it as ``Learning to Simulate\". Similarly, we refer to the task of learning to simulate KGEs as the ``KGE Simulation Task\", to distinguish it from the Link Prediction Task.\n\nWe note that successfully solving this task would provide strong initial evidence for our three core hypotheses; i.e. the Structural Learning Hypothesis, the Hyperparameter Determinism Hypothesis, and the TWIG Hypothesis.\n\n\\section{Methods}\n\\subsection{Dataset Choice}\nFor our study, we chose UMLS, a standard biomedical KG commonly used both in biological applications and as a benchmark dataset for KGEs \\cite{umls,light-into-the-dark}. In particular, we chose UMLS over the more standard FB15K-237 and WN18RR KGs for two reasons. First, it is directly applicable to the biomedical domain. Second, it is substantially smaller than either FB15K-237 or WN18RR, which allowed us to perform multiple replicated experiments on a large hyperparameter grid, something that would be computationally difficult on the other datasets even using powerful modern computational hardware \\cite{umls,light-into-the-dark}. \n\nThe overall structure of the UMLS dataset is given in Table \\ref{tab:umls}. Note that degree refers to total degree; i.e. the number of edges incident on a particular node, regardless of whether the relationship is an incoming edge or an outgoing edge.\n\n\\begin{table}\n    \\centering\n    \\begin{tabular}{l|l}\n        \\textbf{ Structural Feature}&\\textbf{Value}\\\\ \\hline\n         Num. nodes& 135\\\\\n         Num. relations& 46\\\\\n         Num. triples& 6,529\\\\\n         Min. degree& 4\\\\\n         Median degree& 71\\\\\n         Max. degree& 382\\\\\n    \\end{tabular}\n    \\caption{Overall structure features of the UMLS dataset}\n    \\label{tab:umls}\n\\end{table}\n\n\\subsection{Model Space Search}\nGiven that ComplEx-N3 (the ComplEx KGE model using the $L_3$ regulariser) is established as the de-facto state-of-the-art KGE model for many applications \\cite{complex-n3}, as well as remaining one of the strongest overall KGE models \\cite{baselines-strike-back-2,light-into-the-dark}, we performed all of our experiments on the ComplEx-N3 model. We trained different ComplEx-N3 models under a broad grid of hyperparameter values to determine relative performance in each case; the grid used is shown in Table \\ref{tab:hp-grid}. A technical description of all of these hyperparamters and their definitions can be found in \\cite{light-into-the-dark}.\n\nAll training was done on the training set, and evaluations of hyperparameter performance were done on the validation set. All experiments were run using the Adam optimiser for 100 epochs. \n\n\\begin{table}\n    \\centering\n    \\begin{tabular}{p{3cm}|p{5cm}}\n         \\textbf{Hyperparameter}& \\textbf{Values Searched}\\\\ \\hline\n         Negative Sampler& Basic, Bernoulli, Pseudo-Typed\\\\\n        \\#Negatives per Positive& 5, 25, 125\\\\\n         Loss Function& Margin Ranking, Binary Cross Entropy (wth Logits), Cross Entropy\\\\\n         Margin (if applicable)& 0.5, 1, 2\\\\\n         Learning Rate& 1e-2, 1e-4, 1e-6\\\\\n         Embedding dimension& 50, 100, 250\\\\\n         Regularisation Coefficient& 1e-2, 1e-4, 1e-6\\\\\n    \\end{tabular}\n    \\caption{The grid of hyperparameters used in the experiments}\n    \\label{tab:hp-grid}\n\\end{table}\n\nFor all hyperparameter settings, we recorded two outputs: the Mean Reciprocal Rank (MRR) score of the KGE model overall, as well as the ranked-list predictions for every triple in the validation set against its corruptions.\n\nWe repeated this procedure 4 times, to produce 4 sets of size-1215 grids of results. One of these grids was separated as a hold-out test-set; the remaining 3 were used as training sets, as described below.\n\n\\subsection{Data Modelling}\n\\subsubsection{Feature Selection}\nThe result of running the model space search was a grid of 1215 distinct hyperparameter combinations, as well as the individual ranked-list results and Mean Reciprocal Rank (MRR) scores for all those combinations. As our goal was to simulate the task of Knowledge Graph embedding, we framed our problem of constructing TWIG as predicting the rank that would be assigned to each individual triple in the UMLS validation set used to evaluate the KGEs.\n\nIn order to provide a valid test of our hypothesis, TWIG must take the form of a function $f(structure, hyperparameters) \\rightarrow ranked list$. We present this as a regression problem where the hyperparameter features are the values of the hyperparamters used for each experiments. For structure, we represented this as local structure about the triple whose score is being predicted. Noting that existing KGE literature demonstrates that KGEs only learn how to make predictions for a triple from the 1 or 2-hop distance around that triple \\cite{topological-imbalance,PoLo,kge-poisoning,kge-poisoning-2,gradient-rollback}, we limit the local structural features that are included to those that can be mined in the local 2-hop distance about the triple being predicted. Note that when computing structural values, we compute them \\textit{only as seen in the train set of the UMLS KG} so that there is no data leakage from the graph's validation or test sets.\n\nOverall, the full set of structural and hyperparameter features included are given in Table \\ref{tab:fts}. We note that the validation set used in our evaluation contains 1304 queries in total.\n\n\\begin{table}\n    \\centering\n    \\begin{tabular}{p{3cm}|p{5cm}}\n         \\textbf{Feature}&\\textbf{Meaning}\\\\ \\hline\n \\textit{Hyperparameter Features}&\\\\\n         Negative Sampler\n&The negative sampling strategy used\\\\\n         \\#Negatives per Positive\n&The number of negatives samples for each positive triples during training\\\\\n         Loss Function\n&The loss function used\\\\\n         Margin (if applicable)\n&The margin used in the loss function (if applicable)\\\\\n         Learning Rate\n&The learning rate for the Adam optimiser\\\\\n         Embedding dimension\n&The dimension of KGE model embeddings\\\\\n         Regularisation Coefficient&The coefficient multiplies to the regulariser\\\\\n          &\\\\\n         \\textit{Structural Features}&\\\\\n is\\_head&Whether the part of the triple being corrupted is the head (i.e. (?,p,o)) or the tail (i.e. (s,p,?))\\\\\n s\\_deg&The degree of the subject node in the training set\\\\\n o\\_deg&The degree of the object node in the training set\\\\\n p\\_freq&\n\nThe frequency of the predicate in the training set\\\\\n s\\_p\\_cofreq&The number of times the given subject and predicate co-occur in the training set\\\\\n o\\_p\\_cofreq&The number of times the given subject and predicate co-occur in the training set \\\\\n s\\_o\\_cofreq&The number of times the given subject and object co-occur in the training set\\\\\n s min deg neighbnour&The degree of the lowest-degree neighbour of the subject node in the training set\\\\\n s max deg neighbnour&The degree of the highest-degree neighbour of the subject node in the training set\\\\\n s mean deg neighbnour&The degree of the mean-degree neighbour of the subject node in the training set\\\\\n o min deg neighbnour&The degree of the lowest-degree neighbour of the object node in the training set\\\\\n o max deg neighbnour&The degree of the highest-degree neighbour of the object node in the training set\\\\\n o mean deg neighbnour&The degree of the mean-degree neighbour of the object node in the training set\\\\\n s num neighbnours&the total number of neighbours the subject node has in the training set\\\\\n o num neighbnours&the total number of neighbours the object node has in the training set\\\\\n s min freq rel&The frequency of the lowest-degree neighbour of the subject node in the training set\\\\\n s max freq rel&The frequency of the most-frequent-occurring edge incident on the subject node in the training set\\\\\n s min freq rel&The mean frequency of edges incident on the subject node in the training set\\\\\n o min freq rel&The frequency of the lowest-degree neighbour of the object node in the training set\\\\\n o min freq rel&The frequency of the most-frequent-occurring edge incident on the object node in the training set\\\\\n o min freq rel&The mean frequency of edges incident on the object node in the training set\\\\\n s num rels&The total number of relations incident on the subject node in the training set\\\\\n o num rels&The total number of relations incident on the object node in the training set\\\\\n    \\end{tabular}\n    \\caption{A summary of all input features used, and their definitions, in the TWIG model}\n    \\label{tab:fts}\n\\end{table}\n\n\\subsubsection{Determination of Signal}\nOnce our features were prepared, we then performed an analysis of what sources of signal we could use to learn on this data and simulate KGE using a single neural network. In particular, we found two critical sources of signal that could be very readily learned, and very easily distinguished from noise. These were:\n\\begin{enumerate}\n  \\item near-1 correlation of MRRs from KGE models run on the same hyperparameters but with different random seeds\n  \\item near-0 KL Divergence of the distribution of values in output ranked lists from KGE models run on the same hyperparameters but with different random seeds\n\\end{enumerate}\n\nWe will discuss both of these choices in turn. With respect to mining the high correlation of MRR across experiments run on the same hyperparameters but with different random seeds, we observed that the correlation of MRR values between our four rounds of hyperparameter validation were greater than 0.99 in all cases. This is shown in Table \\ref{tab:mrr-corr}. Since correlation itself is not a loss function, we instead follow the protocol common in most regression systems and used Mean Squared Error (MSE) loss between the predicted and true MRR values as a proxy metric to mine the extremely high correlation between MRRs. \n\nWe could not use correlation between ranked lists as a source of signal, however, because the correlation between ranked lists was exceedingly low, often near 0, indicating that it would not be useful as signal during learning. Figure \\ref{fig:rl-corr} shows the distribution of Pearson-correlated values for all combinations of ranked lists that used the same hyperparameters but different random seeds. Due to the tendency of these to be centred near zero, we concluded that they were not a reliable source of signal for learning.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=1\\linewidth]{ranked-list-corr.png}\n    \\caption{Distribution of the Pearson correlation values between all ranked lists using the same hyperparameter configurations.}\n    \\label{fig:rl-corr}\n\\end{figure}\n\nWe note that the KL Divergence of the distribution of values in output ranked lists from KGE models run on the different hyperparameters was substantially higher than those run on the same hyperparameter under different initialisations; see Table \\ref{tab:kl-div} for average KL Divergence values between experiments with all matching hyperparamters (calculated as the KL Divergence between histograms with 30 bins of the same width formed from the values in the ranked list). In contrast to this, taking the average KL Divergence using the same methods of all non-identical sets of hyperparameters, the average KL Divergence value was $0.3632$ -- substantially higher than those obtained under the same hyperparameters. This indicates that KL Divergence between ranked lists from experiments with the same hyperparamters is much lower than that expected between experiments with different hyperparameters, suggesting it is a strong source of signal for learning. Since KL Divergence itself is a loss function, we used KL Divergence between the distributions of the values in the predicted and true ranked lists as our second loss function during learning.\n\nDuring training, we used the same manner of calculation for the distribution of ranks in the ranked list: the KL Divergence between histograms with 30 bins of the same width formed from the values in the predicted and true ranked lists. However, since the exact counting-based binning operation is not differentiable, we replaced it with a \"soft histogram\" version that assigns values into bins using the differentiable Sigmoid function rather than the non-differentiable binary step function. A reference implementation of this function is provided with the rest of our code in our published codebase.\n\nFinally, we found that both of these sources of signal (MSE and KL Divergence) require a full ranked list, not a single output value, to be computed. In other words, all elements of the ranked list have to be predicted before loss is calculated. As a result, even though our input features are vectors, we can only calculate loss at the level of all aggregated predictions. To do this, we construct batches for each unique hyperparameter configuration (of 1215 total) and random seed (of 3 iterations total in the training set), resulting in 3645 batches in total. All predictions for a batch are then aggregated, used to compute the distribution of ranks and MRR, and then passed into our loss functions during training.\n\n\\begin{table}\n    \\centering\n    \\begin{tabular}{ccccl}\n         &  Exp run 1&  Exp run 2& Exp run 3&Exp run 4\\\\\n         Exp run 1&  1&  &  &\\\\\n         Exp run 2&  0.994&  1&  &\\\\\n         Exp run 3&  0.994&  0.995&  1&\\\\\n         Exp run 4& 0.9939& 0.9943& 0.9951&1\\\\\n    \\end{tabular}\n    \\caption{Pairwise correlations of the MRR scores for all 1215 hyperparameter combinations across 4 runs using different random seeds for for each run and hyperparameter combination}\n    \\label{tab:mrr-corr}\n\\end{table}\n\n\\begin{table}\n    \\centering\n    \\begin{tabular}{ccccc}\n         &  Exp run 1&  Exp run 2&  Exp run 3& Exp run 4\n\\\\\n         Exp run 1&  0&  &  & \n\\\\\n         Exp run 2&  0.0250&  0&  & \n\\\\\n         Exp run 3&  0.0250&  0.0245&  0& \n\\\\\n         Exp run 4&  0.0248&  0.0248&  0.0247& 0\\\\\n    \\end{tabular}\n    \\caption{Average KL Divergence values of the distributions of values in output ranked lists  for all 1215 hyperparameter combinations across 4 runs using different random seeds for for each run}\n    \\label{tab:kl-div}\n\\end{table}\n\n\\subsubsection{Interpretation of our Modelling Approach}\nOur choice to model the atomic unit of learning as a batch of inputs representing all triples being predicted has a few important theoretical properties. All parameters are updated based not on how a specific rank was predicted, but by how the list of ranks as a whole was predicted as a broader scale. We note that none of our loss terms enforce explicit order on this ranked list. This means that which triple is assigned which rank is left free under the condition that, at a global scale, the order-less set of ranks assigned to the set of triples still matches the expected distribution and has the expected MRR.\n\nAnother crucial property of the rank lists themselves is that ranked lists run on the same hyperparamters, but with different random seeds, correlate very poorly (see Figure \\ref{fig:rl-corr}). This indicates that different parts of a graph are learned differently based only on random initialisations, and that the same fact could be learned well or not purely due to chance. However, the near-1 correlation of MRRs with identical hyperparameters but across different random seeds (see Table \\ref{tab:mrr-corr}) indicates that overall learning is highly robust in th face of random initialisations. This effect is theoretically critical both for KG learning in general and for understanding the operation of KGE models in deployment. It means that any attempt to enforce an explicit hard order on ranked-list output would likely decrease performance. Instead, either a soft / partial order, or no explicit loss term to enforce ordering, are best suited here. While we have taken the no-explicit-ordering approach here, we leave analysis of a soft, partial-order based system to future work.\n\n\\subsection{Constructing TWIG}\nTWIG was constructed as a neural network made of exclusively Dense Layers that form three key components. After taking input (a vector of features describing hyperparameters and KG structure around the triple being predicted, as given in Table \\ref{tab:fts}) it splits this input into two parts: one describing the hyperparameters and one describing the structural elements. Both of these input feature sub-vectors are then passed through their respective learning components to produce hidden representations of the input data. These are the Hyperparameter Learning Component (on the left, in green) and the Structure Learning Component (on the right, in blue), respectively. The output of each of these components is then concatenated and passed into the third and final Integration Component (at the bottom, in black) that produces a hidden representation integrating the information learned from both the structural data and the hyperparameter data. The output of TWIG is a single value for each input vector, which represents the rank assigned to the triples query represented by the input. Note that the output is passed through the ReLU activation function and incremented by 1 because the output, which represents a predicted rank, is defined as a strictly positive value greater than or equal to 1.  \n\nFigure \\ref{fig:twig-nn} shows the neural architecture of TWIG in detail, including the number of Dense Layers in each component and the input and output sizes of each. ReLU is used as the activation function between all Dense Layers in the network.\n\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=1\\linewidth]{TWIG.drawio.png}\n    \\caption{The TWIG neural architecture, based off of three core components for learning hyperparameter representations (green), structure representations (blue) and for integrating those representations to produce output (black).}\n    \\label{fig:twig-nn}\n\\end{figure}\n\nFor training, we adopted a 2-tiered approach. We trained TWIG for 50 epochs using only KL Divergence between ranked lists as a loss function. After this, we froze the parameters in all layers save the final layer, and trained for another 100 epochs using both KL Divergence between ranked lists and Mean Squared Error (MSE) loss between predicted and true MRR scores as loss functions. As such, a total of 150 epochs were used for training.\n\n\\section{Results and Discussion}\nOur core result is this: \\textit{The fully-trained TWIG model achieves an R2 value of 86.18\\% for predicting MRR of a hyperparameter combination, and does this by predicting the entire ranked list using only localised graph features and hyperparameter setting information}. This R2 value means that TWIG is able to explain 86.18\\% of the variation in MRR seen across all different hyperparameter settings using KG structure and model configuration only as input, and corresponds to an overall correlation of 0.9371. While there are no existing baselines known to the authors to which we can compare, we can conclude that this outperforms the simplest average-MRR baseline, as such a function is constant and therefore has an R2 value of 0\\%. These results in themselves have huge implications, which we will address in turn: the Structural Learning Hypothesis, the Hyperparameter Determinism Hypothesis, and the TWIG Hypothesis, \n\n\\textbf{The Structural Learning Hypothesis} states that KGEs do not learn latent semantics in embeddings, but rather only learn to implicitly summarize graph structure. Our results here, showing that TWIG can simulate the output of ComplEx-N3 across hyperparameter settings, prove that using structure only, without any latent semantics of the KG, is enough to replicate almost entirely the predictions of KGEs run on the UMLS dataset. This indicates that KGEs on the UMLS dataset are not performing any significant learning that cannot be summarised by structure. We hypothesise that the Structural Learning Hypothesis will hold across other KGE models and datasets, but leave testing that hypothesis for future work.\n\n\\textbf{The Hyperparameter Determinism Hypothesis} states that optimal hyperparameter choice is a deterministic function of graph structure and the KGE model being used. Once again, we show that this hypothesis holds for the ComplEx-N3 KGE model and the UMLS dataset -- the extremely high correlation and R2 value seen indicate that the TWIG NN is such a function that can deterministically map hyperparameters to model performance. This means that, for the model and dataset tested, optimal (and indeed all) hyperparameters are necessarily a deterministic function of graph structure. We hypothesise that the Hyperparameter Determinism Hypothesis will hold across other KGE models and datasets, but leave testing that hypothesis for future work.\n\n\\textbf{The TWIG Hypothesis} states that node / relationship embeddings are not needed to solve the LP task. Since TWIG is able to construct a ranked list from localised graph structure, and since this ranked list has an MRR that matches with very high precision that of the ground-truth MRR, our data suggests that embeddings are not needed to simulate the output of ComplEx-N3 trained on UMLS, and further suggests that this simulation could feasibly extend to other KGE models and datasets. However, whether embedding-free (``twiggy'') methods can solve the Link Prediction Task in full, rather than just simulate the output of KGEs, remains to be tested. We hypothesise that twiggy, embedding-free LP is possible on basis of the success of our TWIG model in simulating KGEs. We further hypothesise that this will hold across KGE models and datasets, but leave testing this as a future direction. \n\nOverall, these results suggest that learning is driven not by latent semantics, but by summarisation of data structure. All 1215 experiments in the test set had a combined parameter cost of 29,322,000 parameters. TWIG, which uses only 2,590 parameters, recapitulated the results of all of those experiments -- in other words, it simulated their ranked list and MRR output with high accuracy while using 0.008832\\% of the parameters needed to originally produce the data. Thus, TWIG represents the outputs of KGE models in a highly compact manner.\n\nFinally, we propose \\textbf{The Structural Generalisation Hypothesis.} Given that that TWIG can lead to massive reductions in parameter use, and supposing that the above three hypotheses hold, we propose that TWIG can generalise not only over different hyperparameter settings, but also over different Knowledge Graph datasets. Since all KGs can be annotated by the same structural features, and since KG-specific embeddings are no longer needed, TWIG would in theory allow ranked-list and MRR computation on novel datasets from their structure alone. This suggests that TWIG could lead to a massive step forwards in the generalisability of graph models and in graph learning. Moreover, if specific embeddings neither contain higher-order semantics (the Structural Learning Hypothesis), then this method should be expected to match the performance of existing state-of-the-art KGE models, without the need for hyperparameter searching or KG-specific learning. We note that existing literature has already demonstrated that KGEs learn different regions of graph differently based on degree \\cite{topological-imbalance}, suggesting that the Structural Generalisation Hypothesis has a theoretical basis in existing literature as well.\n\n\\section{Conclusion and Future Work}\nIn this work, we propose three novel hypothesis: the Structural Learning Hypothesis, the Hyperparameter Determinism Hypothesis, and the TWIG Hypothesis. The core idea behind all three of these hypothesis is that latent semantics are neither needed, nor actually learned, in KGEs -- that learning and hyperparameter choice are instead driven entirely by graph structure. Our new TWIG model is able to simulate the output of KGE models across 1215 hyperparameter configuration with high fidelity (R2 = 0.8618\\%) while using only 0.008832\\% of the parameters.\n\nOur work here is limited primarily by the scope of data available -- our analysis was limited to the state-of-the-art ComplEx-N3 KGE model and the biomedical dataset UMLS. More work is needed to assess the validity of our findings on other KGE models and other datasets. However, non-withstanding these notable limitations, our work is the first of its kind known to the authors to take a ground-up, structure-based analysis of KGs and KGE models, to suggest hyperparameter determinism rather than stochasticity, and to provide evidence that embeddings may not be needed to solve the Link Prediction Task. The authors intend to follow up on this work with much more expansive studies to assess to what extent these findings are general to KG learning.\n\n\\section*{Acknowledgment}\nThe authors would like to thank Alok Debnath (ORCID 0000-0002-1270-369X) for his critical insights into the use of the Sigmoid function for the construction of a differentiable ``soft histogram\" used as a core component of TWIG, as well as for his feedback on the manuscript.\n\nThis research was conducted with the financial support of Science Foundation Ireland D-REAL CRT under Grant Agreement No. 18/CRT6225 at the ADAPT SFI Research Centre at Trinity College Dublin, together with sponsorship of Sonas Innovation Ireland. The ADAPT SFI Centre for Digital Content Technology is funded by Science Foundation Ireland through the SFI Research Centres Programme and is co-funded under the European Regional Development Fund (ERDF) through Grant \\# 13/RC/2106\\_P2.\n\n\\end{document}\n</paper 3>\n\nYour summary should follow these steps:\n- Title: Clearly state the main subject or topic of the summary.\n- Introduction: Describe the field and briefly introduce its history. Then introduce current progress and challenges.\n- Introduce the main content of each paper separately. Then summarize their commonalities and innovations.\n- Compare the results of the papers and discuss difference of the results.\n- Conclusion: Summarize the main findings and suggest future research directions.\n\n<keys>\nThe following are the key points to note:\n- If there are important data or mian equation in the given papers, remember to mention them in your summary using Markdown.\n- Use of tables to clearly compare different approaches is encouraged.\n- The first appearance of a professional term must be marked with the full English name and abbreviation.\n- Don't directly copy the papers, write the summary in your own words.\n- Do not include the titles of reference papers directly in your paper.\n</keys>\n\nTotal word count should be about 4000 words.",
    "paper": [
        "arXiv-2112.06567v2.tex",
        "arXiv-2203.09219v1.tex",
        "arXiv-2402.06097v1.tex"
    ],
    "group_id": "group_25",
    "response": "### Title: Analysis of Topological Imbalance and Hyperparameter Determinism in Knowledge Graph Embeddings for Biomedical Applications\n\n### Introduction\n\nKnowledge Graphs (KGs) and Knowledge Graph Embedding (KGE) models have gained significant traction in the biomedical domain due to their ability to represent complex biological interactions and relationships in a structured and intuitive manner. KGs are particularly useful in drug discovery and development, where they can be leveraged to predict new associations between genes, diseases, and drugs, thereby reducing the cognitive biases inherent in human decision-making processes. However, the adoption of KGE models in biomedical KGs has not been without challenges. One such challenge is the inherent structural imbalance in KGs, where certain entities are topologically overrepresented due to their high connectivity. Another challenge is the necessity of extensive hyperparameter tuning, which can be computationally expensive and time-consuming. This summary delves into three research papers that address these issues, providing insights into the impact of topological imbalance on KGE predictions and the deterministic nature of hyperparameter choice in KGE models.\n\nThe field of biomedical KGs and KGEs has seen rapid advancements in recent years, driven by the need to integrate and analyze vast amounts of heterogeneous data from various sources, including literature, databases, and experimental results. The ability of KGE models to produce low-dimensional embeddings of entities and relations within a KG has made them a promising tool for inferential analysis, such as predicting missing links between entities. Despite these advancements, there are still significant challenges in the field, including the bias introduced by structural imbalances in the KGs and the complexity of hyperparameter optimization for KGE models.\n\n### Main Content of Each Paper\n\n#### Paper 1: Implications of Topological Imbalance for Representation Learning on Biomedical Knowledge Graphs\n\nThis paper investigates the impact of structural imbalance in biomedical KGs on the predictions made by KGE models. The authors use the Hetionet dataset, a comprehensive biomedical KG that integrates 29 public data sources, to demonstrate that KGE models tend to overrate highly-connected entities, leading to biased predictions. The study employs the TransE model, one of the earliest and most capable KGE approaches, to analyze the relationship between the degree of an entity and the score assigned by the model to predict missing links. The authors also explore the impact of structural imbalance across different datasets and predictive tasks, including drug-target interaction (DTI), protein-protein interaction (PPI), and drug repurposing (DR). They find that the issue of overrating highly-connected entities is not specific to the TransE model but is prevalent across several KGE models, such as ComplEx, DistMult, and RotatE. The paper also includes a case study on the gene Polyubiquitin-C (UBC), which, despite having a very high degree, is ranked highly for all diseases regardless of its biological relevance. The authors conclude that the total volume of connections an entity has within the graph seems to matter more than any biological information encoded within the relations, highlighting the need for careful consideration of graph composition in relation to the analytical methods employed.\n\n#### Paper 2: Centrality Measures in Multi-layer Knowledge Graphs\n\nThis paper focuses on the impact of multiple layers within KGs on centrality measures, specifically degree and betweenness centrality, in the context of social network analysis. The authors use random graphs inspired by social networks, such as small-world and scale-free networks, to evaluate the robustness of these centrality measures when additional data layers are introduced. The study demonstrates that the addition of extra layers can significantly alter the centrality measures, particularly in small-world networks, which are less robust to such changes compared to scale-free networks. The authors also introduce error measures $\\epsilon$ and $\\epsilon_N$ to quantify the impact of these changes. They find that the degree centrality is highly influenced by the addition of new layers, while betweenness centrality is less affected but still shows significant changes. The paper suggests that further research is needed to understand the impact of different graph structures on the stability of centrality measures and proposes that interdisciplinary research could provide valuable insights into the behavior of real-world data within KGs.\n\n#### Paper 3: TWIG: Towards pre-hoc Hyperparameter Optimisation and Cross-Graph Generalisation via Simulated KGE Models\n\nThis paper introduces TWIG (Topologically-Weighted Intelligence Generation), a novel embedding-free paradigm for simulating the output of KGE models. TWIG is designed to predict the results of KGE models without the need for embeddings, using only graph structure and hyperparameter settings as input features. The authors perform their experiments on the UMLS dataset, a standard biomedical KG, and the ComplEx-N3 model, a state-of-the-art KGE approach. TWIG is able to predict the MRR scores and ranked list predictions of ComplEx-N3 across a broad grid of hyperparameter settings with high accuracy, using only 2,590 learnable parameters compared to the 29,322,000 parameters required by the original KGE model. The paper proposes three core hypotheses: the Structural Learning Hypothesis, which suggests that KGEs do not learn latent semantics in embeddings but only summarize graph structure; the Hyperparameter Determinism Hypothesis, which posits that optimal hyperparameter choice is a deterministic function of graph structure and the KGE model being used; and the TWIG Hypothesis, which suggests that node / relationship embeddings are not necessary to solve the Link Prediction (LP) task. The authors provide strong initial evidence for these hypotheses and propose that TWIG could lead to significant reductions in parameter use and computational costs, while also enabling cross-graph generalization.\n\n### Commonalities and Innovations\n\nAll three papers address the challenges of using KGE models in the biomedical domain, but they approach these challenges from different angles. The first paper focuses on the issue of structural imbalance, where highly-connected entities are overrated by KGE models, leading to biased predictions. The second paper investigates the impact of multiple layers on centrality measures in KGs, providing insights into the robustness of these measures when additional data is introduced. The third paper introduces a novel embedding-free paradigm for simulating KGE models, suggesting that embeddings may not be necessary for solving the LP task and that hyperparameter choice is a deterministic function of graph structure.\n\nThe common theme across these papers is the need for careful consideration of graph structure and the potential biases introduced by structural imbalances. The first paper highlights the importance of understanding the topological structure of KGs to ensure that predictions are biologically meaningful, while the second paper demonstrates the impact of additional layers on centrality measures, suggesting that the structure of the graph is critical for maintaining the integrity of these measures. The third paper takes a different approach by proposing an embedding-free method for simulating KGE models, which could potentially reduce computational costs and enable more efficient hyperparameter optimization.\n\n### Comparison of Results and Discussion\n\nThe results from the three papers are consistent in their findings that topological structure plays a significant role in the performance and output of KGE models. The first paper demonstrates that the degree of an entity has a strong influence on the scores assigned by KGE models, leading to biased predictions. The second paper shows that the addition of extra layers in KGs can significantly alter centrality measures, particularly in small-world networks. The third paper provides evidence that KGE models can be simulated using only graph structure and hyperparameter settings, suggesting that embeddings may not be necessary for solving the LP task.\n\nThe first paper's findings are particularly relevant for drug discovery and target prediction tasks, where the topological imbalance can lead to non-specific predictions. The authors suggest that practitioners should be mindful of these issues when interpreting model outputs and during KG composition. The second paper's results are applicable to a broader range of KGs and can inform the design of more robust and stable KGs. The third paper's TWIG model offers a promising approach to reducing computational costs and improving the generalizability of KGE models across different datasets and tasks.\n\n### Conclusion\n\nThe three papers collectively highlight the importance of understanding the topological structure of KGs and the potential biases introduced by structural imbalances. They also suggest that KGE models may not be as complex as previously thought, with TWIG demonstrating that predictions can be made using only graph structure and hyperparameter settings. The authors of the first paper emphasize the need for careful consideration of graph composition and the impact of structural imbalances on predictions. The second paper provides insights into the robustness of centrality measures when additional layers are introduced, suggesting that the structure of the graph is critical for maintaining the integrity of these measures. The third paper introduces TWIG, a novel embedding-free paradigm for simulating KGE models, which could potentially reduce computational costs and enable more efficient hyperparameter optimization.\n\nThe main findings from these papers suggest that KGE models are heavily influenced by the topological structure of KGs, and that embeddings may not be necessary for solving the LP task. The authors of the first paper recommend that practitioners should be aware of the topological imbalances in their KGs and should not rely solely on performance metrics when interpreting model outputs. The second paper suggests that further research is needed to understand the impact of different graph structures on the stability of centrality measures. The third paper proposes that twiggy, embedding-free methods could lead to significant reductions in parameter use and computational costs, while also enabling cross-graph generalization.\n\nFuture research directions could include expanding the scope of the studies to other KGE models and datasets, as well as exploring the potential of twiggy methods for solving the LP task in full. Additionally, further research could investigate the impact of different graph structures on the stability of centrality measures and the potential of TWIG for optimizing hyperparameters in a pre-hoc manner. Overall, these papers provide valuable insights into the challenges and potential solutions for using KGE models in the biomedical domain, and they pave the way for more efficient and accurate KG learning approaches."
}